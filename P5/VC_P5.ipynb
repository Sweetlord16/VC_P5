{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import math \n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde cámara, detección con yolov8 y modelo nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 dog, 205.1ms\n",
      "Speed: 21.8ms preprocess, 205.1ms inference, 23.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> dog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 158.6ms\n",
      "Speed: 2.0ms preprocess, 158.6ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 141.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.3ms preprocess, 141.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 145.0ms\n",
      "Speed: 2.0ms preprocess, 145.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 125.5ms\n",
      "Speed: 1.5ms preprocess, 125.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 124.4ms\n",
      "Speed: 0.9ms preprocess, 124.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 125.2ms\n",
      "Speed: 1.0ms preprocess, 125.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 132.4ms\n",
      "Speed: 1.0ms preprocess, 132.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 132.8ms\n",
      "Speed: 3.1ms preprocess, 132.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 202.7ms\n",
      "Speed: 2.5ms preprocess, 202.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 bench, 118.0ms\n",
      "Speed: 2.0ms preprocess, 118.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> bench\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 1 bench, 120.1ms\n",
      "Speed: 1.5ms preprocess, 120.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 121.5ms\n",
      "Speed: 1.0ms preprocess, 121.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> bench\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 3 persons, 1 bench, 145.9ms\n",
      "Speed: 1.5ms preprocess, 145.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 bench, 145.7ms\n",
      "Speed: 2.5ms preprocess, 145.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> bench\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> bench\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 1 bench, 134.4ms\n",
      "Speed: 1.6ms preprocess, 134.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 119.9ms\n",
      "Speed: 1.9ms preprocess, 119.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> bench\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 1 laptop, 122.4ms\n",
      "Speed: 2.6ms preprocess, 122.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 126.3ms\n",
      "Speed: 1.0ms preprocess, 126.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.78\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 3 persons, 133.0ms\n",
      "Speed: 2.0ms preprocess, 133.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 132.3ms\n",
      "Speed: 2.4ms preprocess, 132.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 136.7ms\n",
      "Speed: 2.0ms preprocess, 136.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 118.1ms\n",
      "Speed: 2.6ms preprocess, 118.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.96\n",
      "Class name --> person\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 121.7ms\n",
      "Speed: 2.5ms preprocess, 121.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 110.6ms\n",
      "Speed: 2.7ms preprocess, 110.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.96\n",
      "Class name --> person\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 135.3ms\n",
      "Speed: 4.0ms preprocess, 135.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 139.5ms\n",
      "Speed: 3.0ms preprocess, 139.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 139.5ms\n",
      "Speed: 1.0ms preprocess, 139.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 121.1ms\n",
      "Speed: 1.5ms preprocess, 121.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 176.3ms\n",
      "Speed: 2.6ms preprocess, 176.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 132.2ms\n",
      "Speed: 1.0ms preprocess, 132.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 134.7ms\n",
      "Speed: 2.3ms preprocess, 134.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 133.9ms\n",
      "Speed: 1.2ms preprocess, 133.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 137.4ms\n",
      "Speed: 2.1ms preprocess, 137.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 116.3ms\n",
      "Speed: 1.0ms preprocess, 116.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 121.2ms\n",
      "Speed: 1.8ms preprocess, 121.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 130.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms preprocess, 130.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 140.8ms\n",
      "Speed: 2.5ms preprocess, 140.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 134.9ms\n",
      "Speed: 2.0ms preprocess, 134.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 126.1ms\n",
      "Speed: 1.0ms preprocess, 126.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "\n",
    "# Captura desde lawebcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen válida\n",
    "    if ret:  \n",
    "        # Perform inference on an image\n",
    "        results = model(img, stream=True)\n",
    "        \n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confidence --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador numérico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de caracteres tras instalar pytesseract y tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytesseract'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Eric\\Desktop\\vc-5\\P5\\VC_P5.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/P5/VC_P5.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Tesseract\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/P5/VC_P5.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/P5/VC_P5.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytesseract\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/P5/VC_P5.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Previamente debes descargar los ejecutables\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/P5/VC_P5.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Si la ruta de Tesseract no está en el PATH, ruta al ejecutable\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/P5/VC_P5.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m pytesseract\u001b[39m.\u001b[39mpytesseract\u001b[39m.\u001b[39mtesseract_cmd \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:/Program Files/Tesseract-OCR/tesseract\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytesseract'"
     ]
    }
   ],
   "source": [
    "# Tesseract\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Previamente debes descargar los ejecutables\n",
    "# Si la ruta de Tesseract no está en el PATH, ruta al ejecutable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "# Lenguajes disponibles\n",
    "print(pytesseract.get_languages(config=''))\n",
    "\n",
    "#Cargo imagen y ocnvierto a RGB\n",
    "img = cv2.imread('toy.tif') \n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#Aplica reconocedor a imagen cargada\n",
    "print(pytesseract.image_to_string(img_rgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento decaracteres tras instalar easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[49, 85], [617, 85], [617, 147], [49, 147]], 'Hasta el infinito y más allá', 0.6744628105513019)]\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "\n",
    "#Carga del modelo de lengua\n",
    "reader = easyocr.Reader(['es'], gpu=False) \n",
    "\n",
    "#Reconocimiento de una imagen\n",
    "result = reader.readtext('toy.tif')\n",
    "print(result)\n",
    "\n",
    "#Con restricción de caracteres reconocibles\n",
    "#result = reader.readtext('toy.tif', allowlist ='0123456789')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eric\\Desktop\\vc-5\\P5\n",
      "c:\\Users\\Eric\\anaconda3\\envs\\VC_P1\\python311.zip\n",
      "c:\\Users\\Eric\\anaconda3\\envs\\VC_P1\\DLLs\n",
      "c:\\Users\\Eric\\anaconda3\\envs\\VC_P1\\Lib\n",
      "c:\\Users\\Eric\\anaconda3\\envs\\VC_P1\n",
      "\n",
      "C:\\Users\\Eric\\AppData\\Roaming\\Python\\Python311\\site-packages\n",
      "c:\\Users\\Eric\\anaconda3\\envs\\VC_P1\\Lib\\site-packages\n",
      "c:\\Users\\Eric\\anaconda3\\envs\\VC_P1\\Lib\\site-packages\\win32\n",
      "c:\\Users\\Eric\\anaconda3\\envs\\VC_P1\\Lib\\site-packages\\win32\\lib\n",
      "c:\\Users\\Eric\\anaconda3\\envs\\VC_P1\\Lib\\site-packages\\Pythonwin\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "for path in sys.path:\n",
    "    print(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba yolo con imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x640 4 persons, 426.5ms\n",
      "Speed: 46.7ms preprocess, 426.5ms inference, 39.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "# Carga la imagen que deseas procesar\n",
    "image_path = 'images.png'  # Reemplaza 'tu_imagen.jpg' por la ruta de tu imagen\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Realiza inferencia en la imagen\n",
    "results = model(img)\n",
    "\n",
    "# Para cada detección\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "\n",
    "    for box in boxes:\n",
    "        # Contenedor\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)  # Convierte a valores enteros\n",
    "\n",
    "        # Confianza\n",
    "        confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "        print(\"Confidence --->\", confidence)\n",
    "\n",
    "        # Clase\n",
    "        cls = int(box.cls[0])\n",
    "        print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "        # Convierte el identificador numérico de la clase en un color RGB\n",
    "        escala = int((cls / len(classNames)) * 255 * 3)\n",
    "        if escala >= 255 * 2:\n",
    "            R = 255\n",
    "            G = 255\n",
    "            B = escala - 255 * 2\n",
    "        else:\n",
    "            if escala >= 255:\n",
    "                R = 255\n",
    "                G = escala - 255\n",
    "                B = 0\n",
    "            else:\n",
    "                R = escala\n",
    "                G = 0\n",
    "                B = 0\n",
    "\n",
    "        # Dibuja el contenedor y la clase\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "        cv2.putText(img, classNames[cls], [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "# Muestra la imagen con las detecciones\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 256x640 2 cars, 65.0ms\n",
      "Speed: 0.0ms preprocess, 65.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.94\n",
      "Class name --> car\n",
      "Confidence ---> 0.34\n",
      "Class name --> car\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "from ultralytics import YOLO  # Asegúrate de importar el módulo YOLO correcto\n",
    "\n",
    "# Carga del modelo\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "# Carga la imagen que deseas procesar\n",
    "image_path = 'prueba.jpg'  # Reemplaza 'tu_imagen.jpg' por la ruta de tu imagen\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Realiza inferencia en la imagen\n",
    "results = model(img)\n",
    "\n",
    "# Para cada detección\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "\n",
    "    for box in boxes:\n",
    "        # Contenedor\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)  # Convierte a valores enteros\n",
    "\n",
    "        # Confianza\n",
    "        confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "        print(\"Confidence --->\", confidence)\n",
    "\n",
    "        # Clase\n",
    "        cls = int(box.cls[0])\n",
    "        print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "        # Convierte el identificador numérico de la clase en un color RGB\n",
    "        escala = int((cls / len(classNames)) * 255 * 3)\n",
    "        if escala >= 255 * 2:\n",
    "            R = 255\n",
    "            G = 255\n",
    "            B = escala - 255 * 2\n",
    "        else:\n",
    "            if escala >= 255:\n",
    "                R = 255\n",
    "                G = escala - 255\n",
    "                B = 0\n",
    "            else:\n",
    "                R = escala\n",
    "                G = 0\n",
    "                B = 0\n",
    "\n",
    "        # Dibuja el contenedor y la clase\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "        cv2.putText(img, classNames[cls], (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Obtén la ROI\n",
    "        roi = img[y1:y2, x1:x2]\n",
    "\n",
    "        # Convierte ROI a escala de grises\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Aplica umbral para encontrar contornos\n",
    "        _, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Encuentra contornos en la ROI\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Dibuja los contornos en la ROI\n",
    "        cv2.drawContours(roi, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Muestra la imagen con las detecciones y los contornos\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 256x640 2 cars, 86.3ms\n",
      "Speed: 4.5ms preprocess, 86.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.94\n",
      "Class name --> car\n",
      "Confidence ---> 0.34\n",
      "Class name --> car\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "from ultralytics import YOLO  # Asegúrate de importar el módulo YOLO correcto\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Función para verificar si un contorno tiene forma rectangular aproximada\n",
    "def is_approximately_rectangular(contour, epsilon=0.009):\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, epsilon * perimeter, True)\n",
    "    return len(approx) == 4\n",
    "\n",
    "# Carga del modelo YOLO\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "# Carga la imagen que deseas procesar\n",
    "image_path = 'prueba.jpg'  # Reemplaza 'tu_imagen.jpg' por la ruta de tu imagen\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Realiza inferencia en la imagen\n",
    "results = model(img)\n",
    "\n",
    "# Para cada detección\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "\n",
    "    for box in boxes:\n",
    "        # Contenedor\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)  # Convierte a valores enteros\n",
    "\n",
    "        # Confianza\n",
    "        confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "        print(\"Confidence --->\", confidence)\n",
    "\n",
    "        # Clase\n",
    "        cls = int(box.cls[0])\n",
    "        print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "        # Convierte el identificador numérico de la clase en un color RGB\n",
    "        escala = int((cls / len(classNames)) * 255 * 3)\n",
    "        if escala >= 255 * 2:\n",
    "            R = 255\n",
    "            G = 255\n",
    "            B = escala - 255 * 2\n",
    "        else:\n",
    "            if escala >= 255:\n",
    "                R = 255\n",
    "                G = escala - 255\n",
    "                B = 0\n",
    "            else:\n",
    "                R = escala\n",
    "                G = 0\n",
    "                B = 0\n",
    "\n",
    "        # Dibuja el contenedor y la clase\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "        cv2.putText(img, classNames[cls], (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Obtén la ROI\n",
    "        roi = img[y1:y2, x1:x2]\n",
    "\n",
    "        # Convierte ROI a escala de grises\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Aplica umbral para encontrar contornos\n",
    "        _, thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Encuentra contornos en la ROI\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Umbral de área para considerar como contorno grande (ajusta este valor según tus necesidades)\n",
    "        area_threshold = 1000\n",
    "\n",
    "        # Filtra los contornos que tienen forma rectangular aproximada y un área grande\n",
    "        filtered_contours = [contour for contour in contours if is_approximately_rectangular(contour) and cv2.contourArea(contour) > area_threshold]\n",
    "\n",
    "        # Dibuja los contornos filtrados en la ROI\n",
    "        cv2.drawContours(roi, filtered_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "        # Dibuja los contornos filtrados en la ROI\n",
    "        cv2.drawContours(roi, filtered_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Muestra la imagen con las detecciones y los contornos filtrados\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset\\\\train\\\\images\\\\0802HFP_jpg.rf.30755e346cf1455361344eeeceb55cb1.jpg', 'dataset\\\\train\\\\images\\\\0802HFP_jpg.rf.30cd9ca231b6667068ad26b808dd99da.jpg', 'dataset\\\\train\\\\images\\\\0802HFP_jpg.rf.ba381edbab2dcddf24f9739d99ae26d4.jpg', 'dataset\\\\train\\\\images\\\\1159FPG_jpg.rf.165f7f6df48b376a9863eab1befe71bf.jpg', 'dataset\\\\train\\\\images\\\\1159FPG_jpg.rf.3ff8b432d3fb4ab2537c7f6ec80ce560.jpg', 'dataset\\\\train\\\\images\\\\1159FPG_jpg.rf.8ac0d77c1a7d6f3b8f208fe9ec6f887f.jpg', 'dataset\\\\train\\\\images\\\\1319FSX_jpg.rf.42cac49225e519a2c8e5d1ef1bc1a9df.jpg', 'dataset\\\\train\\\\images\\\\1319FSX_jpg.rf.8aa60298e9d1b1a0ec29e0189c61bf40.jpg', 'dataset\\\\train\\\\images\\\\1319FSX_jpg.rf.f37800d74affae5e5dc10a94693dbfbf.jpg', 'dataset\\\\train\\\\images\\\\15989862207427_jpg.rf.8f731f82cf1639282dc1a5c81fd7d483.jpg', 'dataset\\\\train\\\\images\\\\15989862207427_jpg.rf.8ff0c28508f614a0427c9a7bf48136db.jpg', 'dataset\\\\train\\\\images\\\\15989862207427_jpg.rf.d4400cbe860cbdc49c9f7a7ac785a91c.jpg', 'dataset\\\\train\\\\images\\\\1637067480508_jpg.rf.49922346df4dbbe9f88c7ac5abaead22.jpg', 'dataset\\\\train\\\\images\\\\1637067480508_jpg.rf.81614cec62651fd757f938c9293738b5.jpg', 'dataset\\\\train\\\\images\\\\1637067480508_jpg.rf.e5c02fa0c2eb431dc8343b5ec703364e.jpg', 'dataset\\\\train\\\\images\\\\2711LKN_jpg.rf.9d59545c3a3188695ec37613ae290ee5.jpg', 'dataset\\\\train\\\\images\\\\2711LKN_jpg.rf.a034e77579ff63c99d4a46495303c37b.jpg', 'dataset\\\\train\\\\images\\\\2711LKN_jpg.rf.a958f1f2817824fd4fa83f39806e09b1.jpg', 'dataset\\\\train\\\\images\\\\2942HFB_jpg.rf.8263fa536f5d315f40e3807591092bba.jpg', 'dataset\\\\train\\\\images\\\\2942HFB_jpg.rf.cd3eeddbc3fa7d636c5db16700f285b6.jpg', 'dataset\\\\train\\\\images\\\\2942HFB_jpg.rf.fbf11cef15a1099115a1a06d5e151d04.jpg', 'dataset\\\\train\\\\images\\\\3838KWB_jpg.rf.ace411bd6e092f78b250cdf0c0a71bfa.jpg', 'dataset\\\\train\\\\images\\\\3838KWB_jpg.rf.b01806a282c2631288a4d62a189e2135.jpg', 'dataset\\\\train\\\\images\\\\3838KWB_jpg.rf.e9f960b1ac9e2f957be2a50e29317099.jpg', 'dataset\\\\train\\\\images\\\\4078BVX_jpg.rf.4358dea669efd28b780f048f930d293d.jpg', 'dataset\\\\train\\\\images\\\\4078BVX_jpg.rf.ad45943dcf4ffac6044159efa348f466.jpg', 'dataset\\\\train\\\\images\\\\4078BVX_jpg.rf.d6848a6462560959c8368f9616feeb0f.jpg', 'dataset\\\\train\\\\images\\\\4950KZK_jpg.rf.14c74f9c463e6b15d8a111f95a18936a.jpg', 'dataset\\\\train\\\\images\\\\4950KZK_jpg.rf.5673172dd504e94a89c92fa148cadf0b.jpg', 'dataset\\\\train\\\\images\\\\4950KZK_jpg.rf.f51cf698836c629817570298b4e504dc.jpg', 'dataset\\\\train\\\\images\\\\4_jpg.rf.5fc6f3248156631d9e8f89b9c56f0c42.jpg', 'dataset\\\\train\\\\images\\\\4_jpg.rf.85c872bff5dff7e2d5d7a976d3cdd996.jpg', 'dataset\\\\train\\\\images\\\\4_jpg.rf.861c1294fa47fb2e07ece975981cfafd.jpg', 'dataset\\\\train\\\\images\\\\5921LMH_jpg.rf.0e2838ecb1dca96304e5b7efd4a7d372.jpg', 'dataset\\\\train\\\\images\\\\5921LMH_jpg.rf.bb888f2d8ccfa2e85da9a516e9c4a6e1.jpg', 'dataset\\\\train\\\\images\\\\5921LMH_jpg.rf.e51d2d2ccab8e372e88d4187cf03c71c.jpg', 'dataset\\\\train\\\\images\\\\5_jpg.rf.436d0c6cae5ebe1ed5d3cd07ba8a4207.jpg', 'dataset\\\\train\\\\images\\\\5_jpg.rf.48b4f45d14bd9236cd6f56729a6227bd.jpg', 'dataset\\\\train\\\\images\\\\5_jpg.rf.6fb58f888ec516ad776a197c0a1bf834.jpg', 'dataset\\\\train\\\\images\\\\6299JJL_jpg.rf.4be7aa1ef9a1ff678177f06833155eb6.jpg', 'dataset\\\\train\\\\images\\\\6299JJL_jpg.rf.983005f219cf60ed438ce6b07c81d734.jpg', 'dataset\\\\train\\\\images\\\\6299JJL_jpg.rf.cf894416237da38468835f4b12c00e07.jpg', 'dataset\\\\train\\\\images\\\\7270GVF_jpg.rf.2f9bf27a5966e86bfe14bcf8a16499ca.jpg', 'dataset\\\\train\\\\images\\\\7270GVF_jpg.rf.5d1bcbea314ce2ec8aad08dc98ace54d.jpg', 'dataset\\\\train\\\\images\\\\7270GVF_jpg.rf.efc9c982fbcc073d6b1dee7abe2e3aa4.jpg', 'dataset\\\\train\\\\images\\\\7_jpg.rf.ad23a58c142fc4c2c48abb60aaaaa9d0.jpg', 'dataset\\\\train\\\\images\\\\7_jpg.rf.ce895c85153035661ab005e7a4a5fd64.jpg', 'dataset\\\\train\\\\images\\\\7_jpg.rf.e6fadae9459c52dbe6abc39219555f23.jpg', 'dataset\\\\train\\\\images\\\\8_jpg.rf.c7fc155d7467fbd25c19db3d786dde60.jpg', 'dataset\\\\train\\\\images\\\\8_jpg.rf.da898b55d6724bbc6b312f9f083525a7.jpg', 'dataset\\\\train\\\\images\\\\8_jpg.rf.fb8e579f8b21d0b22263ca547a65d587.jpg', 'dataset\\\\train\\\\images\\\\CNP2309AW_jpg.rf.53d9c136d9bc859208cf802c2ebfe298.jpg', 'dataset\\\\train\\\\images\\\\CNP2309AW_jpg.rf.9bec9d57c9a31f1e658271854930ff39.jpg', 'dataset\\\\train\\\\images\\\\CNP2309AW_jpg.rf.c5ad418aecb109cc482240301c11ee1f.jpg', 'dataset\\\\train\\\\images\\\\Coches-mas-vendidos-Espana-2018_jpg.rf.24d660a205abf48d0b7e4e9f4a60cfff.jpg', 'dataset\\\\train\\\\images\\\\Coches-mas-vendidos-Espana-2018_jpg.rf.6c00c102018789f58d2b39a6ffb04c27.jpg', 'dataset\\\\train\\\\images\\\\Coches-mas-vendidos-Espana-2018_jpg.rf.d48fdee824b50d0ae4e0cc0a8806f088.jpg', 'dataset\\\\train\\\\images\\\\como-saber-que-ano-es-tu-coche-matricula_jpg.rf.2ba5ea0c6c9a67ee65e76c3ab6ed6715.jpg', 'dataset\\\\train\\\\images\\\\como-saber-que-ano-es-tu-coche-matricula_jpg.rf.c1d8ca3020ddbe6d2aaceedb3b2d06e1.jpg', 'dataset\\\\train\\\\images\\\\como-saber-que-ano-es-tu-coche-matricula_jpg.rf.fadd2cf0742a6930335a8d1f5beed428.jpg', 'dataset\\\\train\\\\images\\\\GC4370BV_jpg.rf.087798a45f907d690e0f5dc40480c4e6.jpg', 'dataset\\\\train\\\\images\\\\GC4370BV_jpg.rf.184189be68c7a463054c2b401507681a.jpg', 'dataset\\\\train\\\\images\\\\GC4370BV_jpg.rf.3a6ed1475edc4eaa2cbe882732c5b661.jpg', 'dataset\\\\train\\\\images\\\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-21_jpg.rf.431f7c473fc93b38322437342e36c981.jpg', 'dataset\\\\train\\\\images\\\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-21_jpg.rf.7e1ccd659e5eb877f1440c90ce3f959b.jpg', 'dataset\\\\train\\\\images\\\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-21_jpg.rf.a1d838443b180e60bac901e5b102c431.jpg', 'dataset\\\\train\\\\images\\\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-23_jpg.rf.044cc425696fe0300f9dad44d15bb60b.jpg', 'dataset\\\\train\\\\images\\\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-23_jpg.rf.68edadc0fa4dee14c8b327d5afe0b04a.jpg', 'dataset\\\\train\\\\images\\\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-23_jpg.rf.e45b2dd2933a08a8be70c4a54dbe44e4.jpg', 'dataset\\\\train\\\\images\\\\imagen8709_NM8710_MG7782316_jpeg.rf.277c597582ce042f109644bf66809412.jpg', 'dataset\\\\train\\\\images\\\\imagen8709_NM8710_MG7782316_jpeg.rf.407a648876013574378ca47fce8015a2.jpg', 'dataset\\\\train\\\\images\\\\imagen8709_NM8710_MG7782316_jpeg.rf.f81c0778a607649aad3a4b305623e265.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0072_jpg.rf.34b2bb62a501ab338685447d3c68bd09.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0072_jpg.rf.95da6158ffcddfabfc06e145a8008c78.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0072_jpg.rf.b76cef7fa7ec48a181bf99691499c678.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0073_jpg.rf.0c068170f9507c09e530fd295e2cea4d.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0073_jpg.rf.3ece7d8276881bbc9bfa62d16c2af881.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0073_jpg.rf.8371b0101c848c9b0c21c685d2c4b19a.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0074_jpg.rf.1f3d876ab0f942527cb5c3fa89b989db.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0074_jpg.rf.3088df95f698bbe2507eecf09c861d6d.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0074_jpg.rf.a107f0225f0435bd6db6696473a62a68.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0075_jpg.rf.4d13313f7f5b63d851ffada218ceaf9c.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0075_jpg.rf.bef08f980a918e4e4bd7a617d9572a0e.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0075_jpg.rf.d557eba8614d0c38f91cce99f212f9c2.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0080_jpg.rf.0233e97acddee76592e352bc37597d45.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0080_jpg.rf.31d57a83873315a0d405b9913e295bcd.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0080_jpg.rf.e0517b356f76fe17f7f33a99091584e3.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0081_jpg.rf.09a2ca6de61f5766ac970622c815ca7a.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0081_jpg.rf.1b296393ed8cc16603aa8a5ccd734e0b.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0081_jpg.rf.92da88db8b7bc0f28d5af086a86f77fd.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0082_jpg.rf.9c69abdfcd2f1babec0b58dabbe152bc.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0082_jpg.rf.a5bd4dabb38066a15a226250c563537a.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0082_jpg.rf.bfd88d74a244d8f7c3771d3d0948b596.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0083_jpg.rf.1a662b2ec9fd179e72d4c9ce770606a0.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0083_jpg.rf.325ff8dda4d4d13911f35d48114fd61d.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0083_jpg.rf.5ad35ccf4359060eee3f3e2831bd6a13.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0084_jpg.rf.2110e367ca827de881608ee363ae8844.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0084_jpg.rf.906fcc04d722cd9fab48ac286ff1428e.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0084_jpg.rf.9ca0fc6ec5c4859db3776ada54fd13e1.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0085_jpg.rf.3010ce7b0607ddef41d8ce4e58404ce8.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0085_jpg.rf.44dde9d6c859f1e358dac7fd46c7e9ba.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0085_jpg.rf.88dcf8c57e8f4bd5e7b56f946a6d0fb4.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0087_jpg.rf.1a65417a75b9f0a594a77bc35e68d137.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0087_jpg.rf.1f8fb433b7fdf35d5f191c1adea12f91.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0087_jpg.rf.801438e2c2a71e0e13c4fcbd80b779da.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0089_jpg.rf.6ce0405ebbf63479da5092c53eae03df.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0089_jpg.rf.a0022d050cd17787a90435667f6653b5.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0089_jpg.rf.fe92b4c209c31e407564c2c4cb1e47c2.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0090_jpg.rf.20d5fbc5f7ebdb5b4983153220aba64e.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0090_jpg.rf.3c25857482ce0688bf9f3145dab18b6a.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0090_jpg.rf.5f90e1629d676fefb6e9083b927d6de9.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0091_jpg.rf.35055fac41928adae110ab3ffd7b57ed.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0091_jpg.rf.60e57b96aa9318d08e715b9d7fe030fd.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0091_jpg.rf.b71b31acad1382b3124a9e6a1d9b09c4.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0092_jpg.rf.1234a42b229d75e6dbc17765941b9fad.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0092_jpg.rf.6f5828d11cdc9dceeb881bfe6b444757.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0092_jpg.rf.af1ce2c09ca232b360454a95b865e7ee.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0093_jpg.rf.86614547b32b0011485e050b67147ac9.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0093_jpg.rf.87b99c400680414547c012e79b033d7a.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0093_jpg.rf.b5866f8c0a1c7303664f8d80887ca4a6.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0095_jpg.rf.7a51ab4d1b3c95b8a075bc27d0548ce8.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0095_jpg.rf.a267cb6d3a17a0c91aa4702f813d4ab3.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0095_jpg.rf.bfc19821e2bd61a2f7bbf36381d24f2f.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0097_jpg.rf.3df87d2a08218a2ebbe7d21de8ec36f3.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0097_jpg.rf.4faf74aed255bc5205aecff82c52be06.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0097_jpg.rf.60aa1a9c76c09776fcb014f56efaf6ce.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0098_jpg.rf.50da97366a7a6fdc55c95bc1a85a80c4.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0098_jpg.rf.c774c29ec8bd4dd0a1558dc1a10626e3.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0098_jpg.rf.d4fe3fcd598e59a0358a58cce6f7fe97.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0099_jpg.rf.10b15f847d76e3bd1992104f85cb24f3.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0099_jpg.rf.94a74bbee7e69e2f50e540de6b2c07e6.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0099_jpg.rf.bcefe6e80d6eebc0f942d6984747a6a9.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114082327_jpg.rf.09892426bf5c509388525021427295ba.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114082327_jpg.rf.2249e78a66aea4ae20a24eda0f6fddac.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114082327_jpg.rf.27586eb58b7fe3efb8981a4ee8add907.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114082335_jpg.rf.28c13772bd71293604fb85db771e539d.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114082335_jpg.rf.566905736354bdf78588da2a484bc50a.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114082335_jpg.rf.5a244ed122cbb79176e1e9e00755eebd.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113754_jpg.rf.39695d2ef7c3513a13dbf16f8f0cd21a.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113754_jpg.rf.81432bb0887f0e55178576619bebdc91.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113754_jpg.rf.c87d0803603a9c1214d95e1881b93dc4.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113800_jpg.rf.3320ce783eb112d29f2dc27cb885d32e.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113800_jpg.rf.3dcf64dd71615d60a31c0c69392c7063.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113800_jpg.rf.60de8157fa5febb3e3de4c1400ed0ae6.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113823_jpg.rf.363441cf2af652724ee834d84a261ca4.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113823_jpg.rf.c9c09481c938daec3927d297d9dbb238.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113823_jpg.rf.f5d7a3cdae71671c7ceab413223f6c40.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113830_jpg.rf.a6ceff41f7238ab464a5e4d92e06be9b.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113830_jpg.rf.aa8e55333e20947e80269cdbc9019bae.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113830_jpg.rf.ae27a6e9c9b9f95e877997a7ded71c86.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113836_jpg.rf.17cdbe34fc49ec2a1f134ba421f629a8.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113836_jpg.rf.5e788a48c394be4c5dd5ee5f837c2204.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113836_jpg.rf.d99b3ef31c2bdfcd3b4a56372f7edfdb.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113843_jpg.rf.0135feafda88d3ce99d4def160c5f721.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113843_jpg.rf.86f7db77bc14fc64512b40e21435ad19.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113843_jpg.rf.d1611fc8dd9aab94d9112814367c23ac.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113902_jpg.rf.179c550ee618273d77b318b5535f1c18.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113902_jpg.rf.5f9f16744fb230fdde8492bd7ada43f9.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113902_jpg.rf.924a8e1607e456f36e87ccd1dfa16ef1.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113915_jpg.rf.28f2fddf5f22c11fddd171924b7bc6af.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113915_jpg.rf.2f8db902964710008f6e80b1d3180f83.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113915_jpg.rf.f1e359d45efc12005a28a8b94ed68336.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113931_jpg.rf.0308ae86f3e3aba24b6d96c7f1ab595c.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113931_jpg.rf.59dc39a3a2e594c750e66ae984b054d1.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113931_jpg.rf.ba3e01854029dfa6722abba62f01d026.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113935_jpg.rf.259170ff884f8d91ad2c55e60764b21d.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113935_jpg.rf.56704d5e3312518611dc9d49055ebd32.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113935_jpg.rf.a49c369564f5a74b5a64c8c76e96f10d.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114114128_jpg.rf.46b3db19cfc1486146168bbfb4b2c2ec.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114114128_jpg.rf.d0eef2bee747e560350cc3111bbecfc7.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114114128_jpg.rf.fc3a1a13374e87d526f168655a73dfeb.jpg', 'dataset\\\\train\\\\images\\\\prueba-peugeot-308-hybrid-phev-2_mid6359518109bdc_jpg.rf.0fa81518363f1aa124f81c119a0ac29c.jpg', 'dataset\\\\train\\\\images\\\\prueba-peugeot-308-hybrid-phev-2_mid6359518109bdc_jpg.rf.b6948cde30a2caacd138e6dbfecfe226.jpg', 'dataset\\\\train\\\\images\\\\prueba-peugeot-308-hybrid-phev-2_mid6359518109bdc_jpg.rf.c36d4cba2f3cad2cb17ee9ebe9617c3c.jpg']\n",
      "dataset\\train\\images\\0802HFP_jpg.rf.30755e346cf1455361344eeeceb55cb1.jpg\n",
      "dataset\\train\\images\\0802HFP_jpg.rf.30cd9ca231b6667068ad26b808dd99da.jpg\n",
      "dataset\\train\\images\\0802HFP_jpg.rf.ba381edbab2dcddf24f9739d99ae26d4.jpg\n",
      "dataset\\train\\images\\1159FPG_jpg.rf.165f7f6df48b376a9863eab1befe71bf.jpg\n",
      "dataset\\train\\images\\1159FPG_jpg.rf.3ff8b432d3fb4ab2537c7f6ec80ce560.jpg\n",
      "dataset\\train\\images\\1159FPG_jpg.rf.8ac0d77c1a7d6f3b8f208fe9ec6f887f.jpg\n",
      "dataset\\train\\images\\1319FSX_jpg.rf.42cac49225e519a2c8e5d1ef1bc1a9df.jpg\n",
      "dataset\\train\\images\\1319FSX_jpg.rf.8aa60298e9d1b1a0ec29e0189c61bf40.jpg\n",
      "dataset\\train\\images\\1319FSX_jpg.rf.f37800d74affae5e5dc10a94693dbfbf.jpg\n",
      "dataset\\train\\images\\15989862207427_jpg.rf.8f731f82cf1639282dc1a5c81fd7d483.jpg\n",
      "dataset\\train\\images\\15989862207427_jpg.rf.8ff0c28508f614a0427c9a7bf48136db.jpg\n",
      "dataset\\train\\images\\15989862207427_jpg.rf.d4400cbe860cbdc49c9f7a7ac785a91c.jpg\n",
      "dataset\\train\\images\\1637067480508_jpg.rf.49922346df4dbbe9f88c7ac5abaead22.jpg\n",
      "dataset\\train\\images\\1637067480508_jpg.rf.81614cec62651fd757f938c9293738b5.jpg\n",
      "dataset\\train\\images\\1637067480508_jpg.rf.e5c02fa0c2eb431dc8343b5ec703364e.jpg\n",
      "dataset\\train\\images\\2711LKN_jpg.rf.9d59545c3a3188695ec37613ae290ee5.jpg\n",
      "dataset\\train\\images\\2711LKN_jpg.rf.a034e77579ff63c99d4a46495303c37b.jpg\n",
      "dataset\\train\\images\\2711LKN_jpg.rf.a958f1f2817824fd4fa83f39806e09b1.jpg\n",
      "dataset\\train\\images\\2942HFB_jpg.rf.8263fa536f5d315f40e3807591092bba.jpg\n",
      "dataset\\train\\images\\2942HFB_jpg.rf.cd3eeddbc3fa7d636c5db16700f285b6.jpg\n",
      "dataset\\train\\images\\2942HFB_jpg.rf.fbf11cef15a1099115a1a06d5e151d04.jpg\n",
      "dataset\\train\\images\\3838KWB_jpg.rf.ace411bd6e092f78b250cdf0c0a71bfa.jpg\n",
      "dataset\\train\\images\\3838KWB_jpg.rf.b01806a282c2631288a4d62a189e2135.jpg\n",
      "dataset\\train\\images\\3838KWB_jpg.rf.e9f960b1ac9e2f957be2a50e29317099.jpg\n",
      "dataset\\train\\images\\4078BVX_jpg.rf.4358dea669efd28b780f048f930d293d.jpg\n",
      "dataset\\train\\images\\4078BVX_jpg.rf.ad45943dcf4ffac6044159efa348f466.jpg\n",
      "dataset\\train\\images\\4078BVX_jpg.rf.d6848a6462560959c8368f9616feeb0f.jpg\n",
      "dataset\\train\\images\\4950KZK_jpg.rf.14c74f9c463e6b15d8a111f95a18936a.jpg\n",
      "dataset\\train\\images\\4950KZK_jpg.rf.5673172dd504e94a89c92fa148cadf0b.jpg\n",
      "dataset\\train\\images\\4950KZK_jpg.rf.f51cf698836c629817570298b4e504dc.jpg\n",
      "dataset\\train\\images\\4_jpg.rf.5fc6f3248156631d9e8f89b9c56f0c42.jpg\n",
      "dataset\\train\\images\\4_jpg.rf.85c872bff5dff7e2d5d7a976d3cdd996.jpg\n",
      "dataset\\train\\images\\4_jpg.rf.861c1294fa47fb2e07ece975981cfafd.jpg\n",
      "dataset\\train\\images\\5921LMH_jpg.rf.0e2838ecb1dca96304e5b7efd4a7d372.jpg\n",
      "dataset\\train\\images\\5921LMH_jpg.rf.bb888f2d8ccfa2e85da9a516e9c4a6e1.jpg\n",
      "dataset\\train\\images\\5921LMH_jpg.rf.e51d2d2ccab8e372e88d4187cf03c71c.jpg\n",
      "dataset\\train\\images\\5_jpg.rf.436d0c6cae5ebe1ed5d3cd07ba8a4207.jpg\n",
      "dataset\\train\\images\\5_jpg.rf.48b4f45d14bd9236cd6f56729a6227bd.jpg\n",
      "dataset\\train\\images\\5_jpg.rf.6fb58f888ec516ad776a197c0a1bf834.jpg\n",
      "dataset\\train\\images\\6299JJL_jpg.rf.4be7aa1ef9a1ff678177f06833155eb6.jpg\n",
      "dataset\\train\\images\\6299JJL_jpg.rf.983005f219cf60ed438ce6b07c81d734.jpg\n",
      "dataset\\train\\images\\6299JJL_jpg.rf.cf894416237da38468835f4b12c00e07.jpg\n",
      "dataset\\train\\images\\7270GVF_jpg.rf.2f9bf27a5966e86bfe14bcf8a16499ca.jpg\n",
      "dataset\\train\\images\\7270GVF_jpg.rf.5d1bcbea314ce2ec8aad08dc98ace54d.jpg\n",
      "dataset\\train\\images\\7270GVF_jpg.rf.efc9c982fbcc073d6b1dee7abe2e3aa4.jpg\n",
      "dataset\\train\\images\\7_jpg.rf.ad23a58c142fc4c2c48abb60aaaaa9d0.jpg\n",
      "dataset\\train\\images\\7_jpg.rf.ce895c85153035661ab005e7a4a5fd64.jpg\n",
      "dataset\\train\\images\\7_jpg.rf.e6fadae9459c52dbe6abc39219555f23.jpg\n",
      "dataset\\train\\images\\8_jpg.rf.c7fc155d7467fbd25c19db3d786dde60.jpg\n",
      "dataset\\train\\images\\8_jpg.rf.da898b55d6724bbc6b312f9f083525a7.jpg\n",
      "dataset\\train\\images\\8_jpg.rf.fb8e579f8b21d0b22263ca547a65d587.jpg\n",
      "dataset\\train\\images\\CNP2309AW_jpg.rf.53d9c136d9bc859208cf802c2ebfe298.jpg\n",
      "dataset\\train\\images\\CNP2309AW_jpg.rf.9bec9d57c9a31f1e658271854930ff39.jpg\n",
      "dataset\\train\\images\\CNP2309AW_jpg.rf.c5ad418aecb109cc482240301c11ee1f.jpg\n",
      "dataset\\train\\images\\Coches-mas-vendidos-Espana-2018_jpg.rf.24d660a205abf48d0b7e4e9f4a60cfff.jpg\n",
      "dataset\\train\\images\\Coches-mas-vendidos-Espana-2018_jpg.rf.6c00c102018789f58d2b39a6ffb04c27.jpg\n",
      "dataset\\train\\images\\Coches-mas-vendidos-Espana-2018_jpg.rf.d48fdee824b50d0ae4e0cc0a8806f088.jpg\n",
      "dataset\\train\\images\\como-saber-que-ano-es-tu-coche-matricula_jpg.rf.2ba5ea0c6c9a67ee65e76c3ab6ed6715.jpg\n",
      "dataset\\train\\images\\como-saber-que-ano-es-tu-coche-matricula_jpg.rf.c1d8ca3020ddbe6d2aaceedb3b2d06e1.jpg\n",
      "dataset\\train\\images\\como-saber-que-ano-es-tu-coche-matricula_jpg.rf.fadd2cf0742a6930335a8d1f5beed428.jpg\n",
      "dataset\\train\\images\\GC4370BV_jpg.rf.087798a45f907d690e0f5dc40480c4e6.jpg\n",
      "dataset\\train\\images\\GC4370BV_jpg.rf.184189be68c7a463054c2b401507681a.jpg\n",
      "dataset\\train\\images\\GC4370BV_jpg.rf.3a6ed1475edc4eaa2cbe882732c5b661.jpg\n",
      "dataset\\train\\images\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-21_jpg.rf.431f7c473fc93b38322437342e36c981.jpg\n",
      "dataset\\train\\images\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-21_jpg.rf.7e1ccd659e5eb877f1440c90ce3f959b.jpg\n",
      "dataset\\train\\images\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-21_jpg.rf.a1d838443b180e60bac901e5b102c431.jpg\n",
      "dataset\\train\\images\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-23_jpg.rf.044cc425696fe0300f9dad44d15bb60b.jpg\n",
      "dataset\\train\\images\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-23_jpg.rf.68edadc0fa4dee14c8b327d5afe0b04a.jpg\n",
      "dataset\\train\\images\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-23_jpg.rf.e45b2dd2933a08a8be70c4a54dbe44e4.jpg\n",
      "dataset\\train\\images\\imagen8709_NM8710_MG7782316_jpeg.rf.277c597582ce042f109644bf66809412.jpg\n",
      "dataset\\train\\images\\imagen8709_NM8710_MG7782316_jpeg.rf.407a648876013574378ca47fce8015a2.jpg\n",
      "dataset\\train\\images\\imagen8709_NM8710_MG7782316_jpeg.rf.f81c0778a607649aad3a4b305623e265.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0072_jpg.rf.34b2bb62a501ab338685447d3c68bd09.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0072_jpg.rf.95da6158ffcddfabfc06e145a8008c78.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0072_jpg.rf.b76cef7fa7ec48a181bf99691499c678.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0073_jpg.rf.0c068170f9507c09e530fd295e2cea4d.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0073_jpg.rf.3ece7d8276881bbc9bfa62d16c2af881.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0073_jpg.rf.8371b0101c848c9b0c21c685d2c4b19a.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0074_jpg.rf.1f3d876ab0f942527cb5c3fa89b989db.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0074_jpg.rf.3088df95f698bbe2507eecf09c861d6d.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0074_jpg.rf.a107f0225f0435bd6db6696473a62a68.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0075_jpg.rf.4d13313f7f5b63d851ffada218ceaf9c.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0075_jpg.rf.bef08f980a918e4e4bd7a617d9572a0e.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0075_jpg.rf.d557eba8614d0c38f91cce99f212f9c2.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0080_jpg.rf.0233e97acddee76592e352bc37597d45.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0080_jpg.rf.31d57a83873315a0d405b9913e295bcd.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0080_jpg.rf.e0517b356f76fe17f7f33a99091584e3.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0081_jpg.rf.09a2ca6de61f5766ac970622c815ca7a.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0081_jpg.rf.1b296393ed8cc16603aa8a5ccd734e0b.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0081_jpg.rf.92da88db8b7bc0f28d5af086a86f77fd.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0082_jpg.rf.9c69abdfcd2f1babec0b58dabbe152bc.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0082_jpg.rf.a5bd4dabb38066a15a226250c563537a.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0082_jpg.rf.bfd88d74a244d8f7c3771d3d0948b596.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0083_jpg.rf.1a662b2ec9fd179e72d4c9ce770606a0.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0083_jpg.rf.325ff8dda4d4d13911f35d48114fd61d.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0083_jpg.rf.5ad35ccf4359060eee3f3e2831bd6a13.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0084_jpg.rf.2110e367ca827de881608ee363ae8844.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0084_jpg.rf.906fcc04d722cd9fab48ac286ff1428e.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0084_jpg.rf.9ca0fc6ec5c4859db3776ada54fd13e1.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0085_jpg.rf.3010ce7b0607ddef41d8ce4e58404ce8.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0085_jpg.rf.44dde9d6c859f1e358dac7fd46c7e9ba.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0085_jpg.rf.88dcf8c57e8f4bd5e7b56f946a6d0fb4.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0087_jpg.rf.1a65417a75b9f0a594a77bc35e68d137.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0087_jpg.rf.1f8fb433b7fdf35d5f191c1adea12f91.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0087_jpg.rf.801438e2c2a71e0e13c4fcbd80b779da.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0089_jpg.rf.6ce0405ebbf63479da5092c53eae03df.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0089_jpg.rf.a0022d050cd17787a90435667f6653b5.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0089_jpg.rf.fe92b4c209c31e407564c2c4cb1e47c2.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0090_jpg.rf.20d5fbc5f7ebdb5b4983153220aba64e.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0090_jpg.rf.3c25857482ce0688bf9f3145dab18b6a.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0090_jpg.rf.5f90e1629d676fefb6e9083b927d6de9.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0091_jpg.rf.35055fac41928adae110ab3ffd7b57ed.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0091_jpg.rf.60e57b96aa9318d08e715b9d7fe030fd.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0091_jpg.rf.b71b31acad1382b3124a9e6a1d9b09c4.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0092_jpg.rf.1234a42b229d75e6dbc17765941b9fad.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0092_jpg.rf.6f5828d11cdc9dceeb881bfe6b444757.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0092_jpg.rf.af1ce2c09ca232b360454a95b865e7ee.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0093_jpg.rf.86614547b32b0011485e050b67147ac9.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0093_jpg.rf.87b99c400680414547c012e79b033d7a.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0093_jpg.rf.b5866f8c0a1c7303664f8d80887ca4a6.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0095_jpg.rf.7a51ab4d1b3c95b8a075bc27d0548ce8.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0095_jpg.rf.a267cb6d3a17a0c91aa4702f813d4ab3.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0095_jpg.rf.bfc19821e2bd61a2f7bbf36381d24f2f.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0097_jpg.rf.3df87d2a08218a2ebbe7d21de8ec36f3.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0097_jpg.rf.4faf74aed255bc5205aecff82c52be06.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0097_jpg.rf.60aa1a9c76c09776fcb014f56efaf6ce.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0098_jpg.rf.50da97366a7a6fdc55c95bc1a85a80c4.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0098_jpg.rf.c774c29ec8bd4dd0a1558dc1a10626e3.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0098_jpg.rf.d4fe3fcd598e59a0358a58cce6f7fe97.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0099_jpg.rf.10b15f847d76e3bd1992104f85cb24f3.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0099_jpg.rf.94a74bbee7e69e2f50e540de6b2c07e6.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0099_jpg.rf.bcefe6e80d6eebc0f942d6984747a6a9.jpg\n",
      "dataset\\train\\images\\IMG20221114082327_jpg.rf.09892426bf5c509388525021427295ba.jpg\n",
      "dataset\\train\\images\\IMG20221114082327_jpg.rf.2249e78a66aea4ae20a24eda0f6fddac.jpg\n",
      "dataset\\train\\images\\IMG20221114082327_jpg.rf.27586eb58b7fe3efb8981a4ee8add907.jpg\n",
      "dataset\\train\\images\\IMG20221114082335_jpg.rf.28c13772bd71293604fb85db771e539d.jpg\n",
      "dataset\\train\\images\\IMG20221114082335_jpg.rf.566905736354bdf78588da2a484bc50a.jpg\n",
      "dataset\\train\\images\\IMG20221114082335_jpg.rf.5a244ed122cbb79176e1e9e00755eebd.jpg\n",
      "dataset\\train\\images\\IMG20221114113754_jpg.rf.39695d2ef7c3513a13dbf16f8f0cd21a.jpg\n",
      "dataset\\train\\images\\IMG20221114113754_jpg.rf.81432bb0887f0e55178576619bebdc91.jpg\n",
      "dataset\\train\\images\\IMG20221114113754_jpg.rf.c87d0803603a9c1214d95e1881b93dc4.jpg\n",
      "dataset\\train\\images\\IMG20221114113800_jpg.rf.3320ce783eb112d29f2dc27cb885d32e.jpg\n",
      "dataset\\train\\images\\IMG20221114113800_jpg.rf.3dcf64dd71615d60a31c0c69392c7063.jpg\n",
      "dataset\\train\\images\\IMG20221114113800_jpg.rf.60de8157fa5febb3e3de4c1400ed0ae6.jpg\n",
      "dataset\\train\\images\\IMG20221114113823_jpg.rf.363441cf2af652724ee834d84a261ca4.jpg\n",
      "dataset\\train\\images\\IMG20221114113823_jpg.rf.c9c09481c938daec3927d297d9dbb238.jpg\n",
      "dataset\\train\\images\\IMG20221114113823_jpg.rf.f5d7a3cdae71671c7ceab413223f6c40.jpg\n",
      "dataset\\train\\images\\IMG20221114113830_jpg.rf.a6ceff41f7238ab464a5e4d92e06be9b.jpg\n",
      "dataset\\train\\images\\IMG20221114113830_jpg.rf.aa8e55333e20947e80269cdbc9019bae.jpg\n",
      "dataset\\train\\images\\IMG20221114113830_jpg.rf.ae27a6e9c9b9f95e877997a7ded71c86.jpg\n",
      "dataset\\train\\images\\IMG20221114113836_jpg.rf.17cdbe34fc49ec2a1f134ba421f629a8.jpg\n",
      "dataset\\train\\images\\IMG20221114113836_jpg.rf.5e788a48c394be4c5dd5ee5f837c2204.jpg\n",
      "dataset\\train\\images\\IMG20221114113836_jpg.rf.d99b3ef31c2bdfcd3b4a56372f7edfdb.jpg\n",
      "dataset\\train\\images\\IMG20221114113843_jpg.rf.0135feafda88d3ce99d4def160c5f721.jpg\n",
      "dataset\\train\\images\\IMG20221114113843_jpg.rf.86f7db77bc14fc64512b40e21435ad19.jpg\n",
      "dataset\\train\\images\\IMG20221114113843_jpg.rf.d1611fc8dd9aab94d9112814367c23ac.jpg\n",
      "dataset\\train\\images\\IMG20221114113902_jpg.rf.179c550ee618273d77b318b5535f1c18.jpg\n",
      "dataset\\train\\images\\IMG20221114113902_jpg.rf.5f9f16744fb230fdde8492bd7ada43f9.jpg\n",
      "dataset\\train\\images\\IMG20221114113902_jpg.rf.924a8e1607e456f36e87ccd1dfa16ef1.jpg\n",
      "dataset\\train\\images\\IMG20221114113915_jpg.rf.28f2fddf5f22c11fddd171924b7bc6af.jpg\n",
      "dataset\\train\\images\\IMG20221114113915_jpg.rf.2f8db902964710008f6e80b1d3180f83.jpg\n",
      "dataset\\train\\images\\IMG20221114113915_jpg.rf.f1e359d45efc12005a28a8b94ed68336.jpg\n",
      "dataset\\train\\images\\IMG20221114113931_jpg.rf.0308ae86f3e3aba24b6d96c7f1ab595c.jpg\n",
      "dataset\\train\\images\\IMG20221114113931_jpg.rf.59dc39a3a2e594c750e66ae984b054d1.jpg\n",
      "dataset\\train\\images\\IMG20221114113931_jpg.rf.ba3e01854029dfa6722abba62f01d026.jpg\n",
      "dataset\\train\\images\\IMG20221114113935_jpg.rf.259170ff884f8d91ad2c55e60764b21d.jpg\n",
      "dataset\\train\\images\\IMG20221114113935_jpg.rf.56704d5e3312518611dc9d49055ebd32.jpg\n",
      "dataset\\train\\images\\IMG20221114113935_jpg.rf.a49c369564f5a74b5a64c8c76e96f10d.jpg\n",
      "dataset\\train\\images\\IMG20221114114128_jpg.rf.46b3db19cfc1486146168bbfb4b2c2ec.jpg\n",
      "dataset\\train\\images\\IMG20221114114128_jpg.rf.d0eef2bee747e560350cc3111bbecfc7.jpg\n",
      "dataset\\train\\images\\IMG20221114114128_jpg.rf.fc3a1a13374e87d526f168655a73dfeb.jpg\n",
      "dataset\\train\\images\\prueba-peugeot-308-hybrid-phev-2_mid6359518109bdc_jpg.rf.0fa81518363f1aa124f81c119a0ac29c.jpg\n",
      "dataset\\train\\images\\prueba-peugeot-308-hybrid-phev-2_mid6359518109bdc_jpg.rf.b6948cde30a2caacd138e6dbfecfe226.jpg\n",
      "dataset\\train\\images\\prueba-peugeot-308-hybrid-phev-2_mid6359518109bdc_jpg.rf.c36d4cba2f3cad2cb17ee9ebe9617c3c.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Directorio base donde se encuentra la carpeta \"dataset\"\n",
    "base_dir = ''\n",
    "\n",
    "# Ruta completa de la carpeta \"train\" dentro de la estructura\n",
    "train_dir = os.path.join(base_dir, 'dataset', 'train', 'images')\n",
    "\n",
    "# Crear una lista para almacenar los nombres de los archivos que cumplan el patrón\n",
    "file_list = []\n",
    "\n",
    "# Iterar a través de los archivos en la carpeta \"train\"\n",
    "for root, dirs, files in os.walk(train_dir):\n",
    "    for filename in files:\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):\n",
    "            # Comprobar si el archivo es una imagen (puedes agregar más extensiones si es necesario)\n",
    "            file_list.append(os.path.join(root, filename))\n",
    "print(file_list)\n",
    "# Imprimir la lista de archivos que cumplen el patrón\n",
    "for file_path in file_list:\n",
    "    print(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba con dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 train, 162.6ms\n",
      "Speed: 8.1ms preprocess, 162.6ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.3\n",
      "Class name --> train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 oven, 155.1ms\n",
      "Speed: 8.8ms preprocess, 155.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.46\n",
      "Class name --> oven\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 1 oven, 169.9ms\n",
      "Speed: 9.6ms preprocess, 169.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.38\n",
      "Class name --> oven\n",
      "Confidence ---> 0.29\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 truck, 207.6ms\n",
      "Speed: 11.1ms preprocess, 207.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.64\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 truck, 179.9ms\n",
      "Speed: 2.6ms preprocess, 179.9ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.71\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 truck, 200.2ms\n",
      "Speed: 0.0ms preprocess, 200.2ms inference, 8.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.74\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 1 bus, 214.4ms\n",
      "Speed: 8.7ms preprocess, 214.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.34\n",
      "Class name --> bus\n",
      "Confidence ---> 0.32\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 bus, 1 truck, 289.4ms\n",
      "Speed: 10.0ms preprocess, 289.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.37\n",
      "Class name --> truck\n",
      "Confidence ---> 0.31\n",
      "Class name --> bus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 bus, 1 truck, 208.1ms\n",
      "Speed: 8.0ms preprocess, 208.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.54\n",
      "Class name --> bus\n",
      "Confidence ---> 0.43\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 truck, 180.1ms\n",
      "Speed: 7.8ms preprocess, 180.1ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.83\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 truck, 170.0ms\n",
      "Speed: 0.0ms preprocess, 170.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.74\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 truck, 169.2ms\n",
      "Speed: 10.4ms preprocess, 169.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.79\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 188.0ms\n",
      "Speed: 10.1ms preprocess, 188.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 remote, 195.7ms\n",
      "Speed: 9.7ms preprocess, 195.7ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.7\n",
      "Class name --> remote\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 189.8ms\n",
      "Speed: 0.0ms preprocess, 189.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.4\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 cars, 1 truck, 194.3ms\n",
      "Speed: 5.4ms preprocess, 194.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.76\n",
      "Class name --> car\n",
      "Confidence ---> 0.63\n",
      "Class name --> car\n",
      "Confidence ---> 0.38\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 cars, 1 truck, 239.8ms\n",
      "Speed: 0.0ms preprocess, 239.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.7\n",
      "Class name --> car\n",
      "Confidence ---> 0.65\n",
      "Class name --> car\n",
      "Confidence ---> 0.52\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 cars, 1 truck, 199.7ms\n",
      "Speed: 12.0ms preprocess, 199.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.8\n",
      "Class name --> car\n",
      "Confidence ---> 0.67\n",
      "Class name --> car\n",
      "Confidence ---> 0.39\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 190.4ms\n",
      "Speed: 9.6ms preprocess, 190.4ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.73\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 1 truck, 162.9ms\n",
      "Speed: 9.4ms preprocess, 162.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.58\n",
      "Class name --> truck\n",
      "Confidence ---> 0.47\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 1 truck, 124.2ms\n",
      "Speed: 0.0ms preprocess, 124.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.44\n",
      "Class name --> truck\n",
      "Confidence ---> 0.31\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 1 bus, 190.9ms\n",
      "Speed: 1.3ms preprocess, 190.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 118.4ms\n",
      "Speed: 0.0ms preprocess, 118.4ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.57\n",
      "Class name --> bus\n",
      "Confidence ---> 0.38\n",
      "Class name --> car\n",
      "Confidence ---> 0.37\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 cars, 1 truck, 124.1ms\n",
      "Speed: 5.6ms preprocess, 124.1ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 1 motorcycle, 1 parking meter, 128.3ms\n",
      "Speed: 8.7ms preprocess, 128.3ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.48\n",
      "Class name --> car\n",
      "Confidence ---> 0.47\n",
      "Class name --> car\n",
      "Confidence ---> 0.33\n",
      "Class name --> truck\n",
      "Confidence ---> 0.55\n",
      "Class name --> car\n",
      "Confidence ---> 0.35\n",
      "Class name --> motorbike\n",
      "Confidence ---> 0.32\n",
      "Class name --> parking meter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 1 backpack, 122.2ms\n",
      "Speed: 8.3ms preprocess, 122.2ms inference, 7.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 cars, 1 motorcycle, 130.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.59\n",
      "Class name --> car\n",
      "Confidence ---> 0.28\n",
      "Class name --> backpack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.5ms preprocess, 130.2ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.54\n",
      "Class name --> car\n",
      "Confidence ---> 0.27\n",
      "Class name --> motorbike\n",
      "Confidence ---> 0.26\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 bus, 246.0ms\n",
      "Speed: 3.7ms preprocess, 246.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 bus, 115.7ms\n",
      "Speed: 4.2ms preprocess, 115.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.87\n",
      "Class name --> bus\n",
      "Confidence ---> 0.87\n",
      "Class name --> bus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 bus, 176.6ms\n",
      "Speed: 4.6ms preprocess, 176.6ms inference, 8.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.85\n",
      "Class name --> bus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 3 cars, 149.2ms\n",
      "Speed: 8.2ms preprocess, 149.2ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.9\n",
      "Class name --> car\n",
      "Confidence ---> 0.77\n",
      "Class name --> car\n",
      "Confidence ---> 0.69\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 cars, 195.5ms\n",
      "Speed: 4.5ms preprocess, 195.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.9\n",
      "Class name --> car\n",
      "Confidence ---> 0.87\n",
      "Class name --> car\n",
      "Confidence ---> 0.48\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 cars, 188.3ms\n",
      "Speed: 0.0ms preprocess, 188.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.91\n",
      "Class name --> car\n",
      "Confidence ---> 0.86\n",
      "Class name --> car\n",
      "Confidence ---> 0.39\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 cars, 1 truck, 199.8ms\n",
      "Speed: 9.5ms preprocess, 199.8ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.86\n",
      "Class name --> car\n",
      "Confidence ---> 0.7\n",
      "Class name --> car\n",
      "Confidence ---> 0.57\n",
      "Class name --> car\n",
      "Confidence ---> 0.45\n",
      "Class name --> truck\n",
      "Confidence ---> 0.3\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 cars, 1 truck, 208.6ms\n",
      "Speed: 2.0ms preprocess, 208.6ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.71\n",
      "Class name --> car\n",
      "Confidence ---> 0.67\n",
      "Class name --> car\n",
      "Confidence ---> 0.41\n",
      "Class name --> car\n",
      "Confidence ---> 0.39\n",
      "Class name --> car\n",
      "Confidence ---> 0.29\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 cars, 1 truck, 191.0ms\n",
      "Speed: 8.6ms preprocess, 191.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.79\n",
      "Class name --> car\n",
      "Confidence ---> 0.76\n",
      "Class name --> car\n",
      "Confidence ---> 0.64\n",
      "Class name --> car\n",
      "Confidence ---> 0.35\n",
      "Class name --> car\n",
      "Confidence ---> 0.29\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 cars, 1 bus, 192.0ms\n",
      "Speed: 9.6ms preprocess, 192.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.9\n",
      "Class name --> car\n",
      "Confidence ---> 0.79\n",
      "Class name --> car\n",
      "Confidence ---> 0.34\n",
      "Class name --> bus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 cars, 1 bus, 190.1ms\n",
      "Speed: 10.5ms preprocess, 190.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.94\n",
      "Class name --> car\n",
      "Confidence ---> 0.63\n",
      "Class name --> car\n",
      "Confidence ---> 0.44\n",
      "Class name --> bus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 cars, 204.2ms\n",
      "Speed: 4.1ms preprocess, 204.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.92\n",
      "Class name --> car\n",
      "Confidence ---> 0.79\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 cars, 1 bus, 191.7ms\n",
      "Speed: 8.0ms preprocess, 191.7ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.87\n",
      "Class name --> car\n",
      "Confidence ---> 0.81\n",
      "Class name --> car\n",
      "Confidence ---> 0.77\n",
      "Class name --> car\n",
      "Confidence ---> 0.58\n",
      "Class name --> car\n",
      "Confidence ---> 0.46\n",
      "Class name --> bus\n",
      "Confidence ---> 0.29\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 cars, 1 truck, 160.5ms\n",
      "Speed: 9.5ms preprocess, 160.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.86\n",
      "Class name --> car\n",
      "Confidence ---> 0.85\n",
      "Class name --> car\n",
      "Confidence ---> 0.77\n",
      "Class name --> car\n",
      "Confidence ---> 0.57\n",
      "Class name --> car\n",
      "Confidence ---> 0.42\n",
      "Class name --> truck\n",
      "Confidence ---> 0.35\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 cars, 1 truck, 195.0ms\n",
      "Speed: 5.2ms preprocess, 195.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.84\n",
      "Class name --> car\n",
      "Confidence ---> 0.81\n",
      "Class name --> car\n",
      "Confidence ---> 0.79\n",
      "Class name --> car\n",
      "Confidence ---> 0.6\n",
      "Class name --> car\n",
      "Confidence ---> 0.49\n",
      "Class name --> car\n",
      "Confidence ---> 0.41\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 car, 172.3ms\n",
      "Speed: 7.4ms preprocess, 172.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.54\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 cars, 128.2ms\n",
      "Speed: 5.0ms preprocess, 128.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.52\n",
      "Class name --> car\n",
      "Confidence ---> 0.36\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 cars, 190.4ms\n",
      "Speed: 14.6ms preprocess, 190.4ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.46\n",
      "Class name --> car\n",
      "Confidence ---> 0.36\n",
      "Class name --> car\n",
      "Confidence ---> 0.29\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 142.8ms\n",
      "Speed: 3.8ms preprocess, 142.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.6\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 156.3ms\n",
      "Speed: 11.8ms preprocess, 156.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.68\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 1 truck, 175.0ms\n",
      "Speed: 5.0ms preprocess, 175.0ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.64\n",
      "Class name --> car\n",
      "Confidence ---> 0.64\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 persons, 4 cars, 159.8ms\n",
      "Speed: 5.0ms preprocess, 159.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.92\n",
      "Class name --> car\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> car\n",
      "Confidence ---> 0.72\n",
      "Class name --> car\n",
      "Confidence ---> 0.66\n",
      "Class name --> car\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 persons, 4 cars, 147.0ms\n",
      "Speed: 4.6ms preprocess, 147.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.9\n",
      "Class name --> car\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.82\n",
      "Class name --> car\n",
      "Confidence ---> 0.77\n",
      "Class name --> car\n",
      "Confidence ---> 0.7\n",
      "Class name --> car\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 persons, 4 cars, 199.9ms\n",
      "Speed: 5.1ms preprocess, 199.9ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 persons, 2 cars, 160.3ms\n",
      "Speed: 5.0ms preprocess, 160.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.95\n",
      "Class name --> car\n",
      "Confidence ---> 0.9\n",
      "Class name --> car\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.81\n",
      "Class name --> car\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> car\n",
      "Confidence ---> 0.83\n",
      "Class name --> car\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> car\n",
      "Confidence ---> 0.33\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 persons, 2 cars, 152.1ms\n",
      "Speed: 6.6ms preprocess, 152.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.86\n",
      "Class name --> car\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 7 persons, 4 cars, 182.9ms\n",
      "Speed: 8.9ms preprocess, 182.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.8\n",
      "Class name --> car\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> car\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> car\n",
      "Confidence ---> 0.35\n",
      "Class name --> car\n",
      "Confidence ---> 0.33\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 car, 1 truck, 493.7ms\n",
      "Speed: 5.5ms preprocess, 493.7ms inference, 6.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.41\n",
      "Class name --> car\n",
      "Confidence ---> 0.38\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 truck, 496.9ms\n",
      "Speed: 7.2ms preprocess, 496.9ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.52\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 bus, 1 truck, 258.2ms\n",
      "Speed: 17.6ms preprocess, 258.2ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.41\n",
      "Class name --> truck\n",
      "Confidence ---> 0.4\n",
      "Class name --> bus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 1 truck, 448.8ms\n",
      "Speed: 9.8ms preprocess, 448.8ms inference, 7.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.37\n",
      "Class name --> car\n",
      "Confidence ---> 0.3\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 265.6ms\n",
      "Speed: 4.9ms preprocess, 265.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.39\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 train, 206.7ms\n",
      "Speed: 6.7ms preprocess, 206.7ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.35\n",
      "Class name --> train\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "from ultralytics import YOLO  # Asegúrate de importar el módulo YOLO correcto\n",
    "\n",
    "import os\n",
    "\n",
    "# Directorio base donde se encuentra la carpeta \"dataset\"\n",
    "base_dir = ''\n",
    "\n",
    "# Ruta completa de la carpeta \"train\" dentro de la estructura\n",
    "train_dir = os.path.join(base_dir, 'dataset', 'train', 'images')\n",
    "\n",
    "# Crear una lista para almacenar los nombres de los archivos de imágenes\n",
    "image_files = []\n",
    "\n",
    "# Iterar a través de los archivos en la carpeta \"train\"\n",
    "for root, dirs, files in os.walk(train_dir):\n",
    "    for filename in files:\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):\n",
    "            # Comprobar si el archivo es una imagen (puedes agregar más extensiones si es necesario)\n",
    "            image_files.append(os.path.join(root, filename))\n",
    "\n",
    "# Carga del modelo YOLO\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "# Iterar a través de la lista de archivos de imágenes\n",
    "for image_path in image_files:\n",
    "    # Carga la imagen que deseas procesar\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Realiza inferencia en la imagen\n",
    "    results = model(img)\n",
    "\n",
    "    # Para cada detección\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            # Contenedor\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)  # Convierte a valores enteros\n",
    "\n",
    "            # Confianza\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "            print(\"Confidence --->\", confidence)\n",
    "\n",
    "            # Clase\n",
    "            cls = int(box.cls[0])\n",
    "            print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "            # Convierte el identificador numérico de la clase en un color RGB\n",
    "            escala = int((cls / len(classNames)) * 255 * 3)\n",
    "            if escala >= 255 * 2:\n",
    "                R = 255\n",
    "                G = 255\n",
    "                B = escala - 255 * 2\n",
    "            else:\n",
    "                if escala >= 255:\n",
    "                    R = 255\n",
    "                    G = escala - 255\n",
    "                    B = 0\n",
    "                else:\n",
    "                    R = escala\n",
    "                    G = 0\n",
    "                    B = 0\n",
    "\n",
    "            # Dibuja el contenedor y la clase\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "            cv2.putText(img, classNames[cls], (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "            # Obtén la ROI\n",
    "            roi = img[y1:y2, x1:x2]\n",
    "\n",
    "            # Convierte ROI a escala de grises\n",
    "            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Aplica umbral para encontrar contornos\n",
    "            _, thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            # Encuentra contornos en la ROI\n",
    "            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Umbral de área para considerar como contorno grande (ajusta este valor según tus necesidades)\n",
    "            area_threshold = 1000\n",
    "\n",
    "            # Filtra los contornos que tienen forma rectangular aproximada y un área grande\n",
    "            filtered_contours = [contour for contour in contours if is_approximately_rectangular(contour) and cv2.contourArea(contour) > area_threshold]\n",
    "\n",
    "            # Dibuja los contornos filtrados en la ROI\n",
    "            cv2.drawContours(roi, filtered_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Muestra la imagen con las detecciones y los contornos filtrados\n",
    "    cv2.imshow('Image', img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "# Cierra todas las ventanas de visualización\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Ultralytics YOLOv8.0.205  Python-3.11.5 torch-2.1.0+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=config.yaml, epochs=100, patience=15, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train6\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train6', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Eric\\Desktop\\vc-5\\P5\\dataset\\train\\labels... 174 images, 0 backgrounds, 0 corrupt: 100%|██████████| 174/174 [00:00<00:00, 1187.49it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Eric\\Desktop\\vc-5\\P5\\dataset\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Eric\\Desktop\\vc-5\\P5\\dataset\\valid\\labels... 16 images, 0 backgrounds, 0 corrupt: 100%|██████████| 16/16 [00:00<00:00, 1228.56it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Eric\\Desktop\\vc-5\\P5\\dataset\\valid\\labels.cache\n",
      "Plotting labels to runs\\detect\\train6\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train6\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100         0G      4.039      6.315      4.522         19        640: 100%|██████████| 11/11 [02:02<00:00, 11.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100         0G      3.924      5.467      4.298         26        640: 100%|██████████| 11/11 [01:29<00:00,  8.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100         0G      3.816      5.032      4.141         20        640: 100%|██████████| 11/11 [01:28<00:00,  8.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.77s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/100         0G      3.518       4.59      3.966         23        640: 100%|██████████| 11/11 [01:28<00:00,  8.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.75s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/100         0G      3.605       4.24      3.723         27        640: 100%|██████████| 11/11 [01:28<00:00,  8.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.62s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/100         0G      3.342      3.803      3.579         24        640: 100%|██████████| 11/11 [01:28<00:00,  8.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/100         0G      3.229      3.689      3.374         25        640: 100%|██████████| 11/11 [01:31<00:00,  8.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.96s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/100         0G      3.045      3.247      3.207         16        640: 100%|██████████| 11/11 [01:29<00:00,  8.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/100         0G      2.825      3.067      3.115         25        640: 100%|██████████| 11/11 [01:29<00:00,  8.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/100         0G      2.747      3.008       3.03         29        640: 100%|██████████| 11/11 [01:28<00:00,  8.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19    0.00158      0.158     0.0559     0.0169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/100         0G      2.909      3.029      3.086         23        640: 100%|██████████| 11/11 [01:17<00:00,  7.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19      0.194      0.105     0.0716     0.0111\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/100         0G      2.721      2.859      2.859         23        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "                   all         16         19      0.319      0.368      0.225     0.0648\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/100         0G       2.61      2.669      2.875         15        640: 100%|██████████| 11/11 [01:20<00:00,  7.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "                   all         16         19      0.343      0.211      0.105     0.0192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/100         0G      2.657      2.552      2.734         17        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19        0.2      0.158      0.111     0.0362\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/100         0G      2.445      2.374      2.623         18        640: 100%|██████████| 11/11 [01:20<00:00,  7.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "                   all         16         19    0.00592      0.632      0.011    0.00392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/100         0G      2.484      2.259      2.595         20        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "                   all         16         19     0.0691     0.0526     0.0334     0.0138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/100         0G      2.363      2.085      2.623         30        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.26s/it]\n",
      "                   all         16         19       0.46      0.137      0.268      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/100         0G      2.324      2.141      2.496         25        640: 100%|██████████| 11/11 [01:20<00:00,  7.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.55s/it]\n",
      "                   all         16         19      0.334      0.421      0.261     0.0969\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/100         0G      2.186       1.97      2.365         29        640: 100%|██████████| 11/11 [01:23<00:00,  7.59s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\n",
      "                   all         16         19      0.296      0.368      0.274     0.0928\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/100         0G      2.066       1.94      2.377         24        640: 100%|██████████| 11/11 [01:20<00:00,  7.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "                   all         16         19      0.485      0.421      0.393      0.143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/100         0G      2.119      1.923      2.351         26        640: 100%|██████████| 11/11 [01:21<00:00,  7.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "                   all         16         19      0.278      0.526      0.301      0.111\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/100         0G      2.061      1.839      2.349         18        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "                   all         16         19      0.322      0.474        0.4      0.189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/100         0G      2.163      1.847      2.413         26        640: 100%|██████████| 11/11 [01:20<00:00,  7.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19       0.45      0.526      0.408      0.206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/100         0G      2.117      1.741      2.325         18        640: 100%|██████████| 11/11 [01:20<00:00,  7.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "                   all         16         19      0.348      0.526      0.349     0.0933\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/100         0G      2.139       1.83      2.294         20        640: 100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "                   all         16         19      0.101      0.368     0.0798     0.0325\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/100         0G       1.96      1.756      2.314         16        640: 100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "                   all         16         19      0.405      0.632      0.443      0.177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/100         0G       1.97        1.7       2.27         30        640: 100%|██████████| 11/11 [01:20<00:00,  7.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "                   all         16         19      0.244      0.474      0.225      0.107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/100         0G      1.877      1.553      2.185         28        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "                   all         16         19      0.164      0.474      0.126     0.0313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/100         0G      1.958       1.65      2.291         16        640: 100%|██████████| 11/11 [01:20<00:00,  7.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n",
      "                   all         16         19      0.419      0.579      0.512      0.236\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/100         0G      1.776      1.496      2.107         29        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19      0.445      0.632      0.548      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/100         0G      1.808      1.455      2.068         22        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "                   all         16         19      0.556      0.684      0.546      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/100         0G       1.91      1.419      2.101         25        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19      0.335      0.579      0.433      0.153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/100         0G      1.889      1.542      2.153         27        640: 100%|██████████| 11/11 [01:19<00:00,  7.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.26s/it]\n",
      "                   all         16         19      0.633      0.526      0.546       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/100         0G      1.762      1.431      2.073         25        640: 100%|██████████| 11/11 [01:20<00:00,  7.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\n",
      "                   all         16         19       0.55      0.789      0.711      0.328\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/100         0G      1.738      1.383      2.021         32        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.30s/it]\n",
      "                   all         16         19      0.637      0.632      0.639      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/100         0G      1.697      1.432      2.045         12        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "                   all         16         19      0.662      0.474       0.58      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/100         0G      1.705      1.394      1.987         31        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.33s/it]\n",
      "                   all         16         19      0.508      0.684      0.655      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/100         0G      1.797      1.409      2.058         20        640: 100%|██████████| 11/11 [01:19<00:00,  7.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.33s/it]\n",
      "                   all         16         19      0.761      0.737      0.776      0.378\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/100         0G       1.71      1.256      1.937         25        640: 100%|██████████| 11/11 [01:20<00:00,  7.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "                   all         16         19      0.607      0.652      0.741      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/100         0G      1.648      1.301      1.916         20        640: 100%|██████████| 11/11 [01:23<00:00,  7.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\n",
      "                   all         16         19      0.636      0.737      0.744       0.35\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/100         0G      1.588      1.276      1.908         17        640: 100%|██████████| 11/11 [01:22<00:00,  7.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.49s/it]\n",
      "                   all         16         19      0.605      0.632       0.64      0.301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/100         0G      1.607      1.215      1.924         28        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "                   all         16         19      0.704      0.684      0.784      0.388\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/100         0G      1.543      1.195       1.82         32        640: 100%|██████████| 11/11 [01:20<00:00,  7.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "                   all         16         19       0.51      0.789      0.687      0.273\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/100         0G      1.598      1.283      1.919         20        640: 100%|██████████| 11/11 [01:21<00:00,  7.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "                   all         16         19      0.873      0.737      0.872      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/100         0G      1.695      1.225      1.927         25        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19      0.789      0.737      0.808      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/100         0G       1.56      1.181      1.853         23        640: 100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n",
      "                   all         16         19      0.647      0.842      0.744      0.357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/100         0G        1.6      1.173      1.863         21        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "                   all         16         19      0.874      0.842      0.813      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/100         0G      1.531      1.143      1.831         26        640: 100%|██████████| 11/11 [01:20<00:00,  7.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\n",
      "                   all         16         19      0.816      0.699      0.793       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/100         0G       1.54      1.175      1.817         19        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "                   all         16         19      0.653      0.737      0.689      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/100         0G      1.539      1.171      1.826         22        640: 100%|██████████| 11/11 [01:20<00:00,  7.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "                   all         16         19      0.573      0.842      0.708      0.375\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/100         0G      1.488      1.126      1.801         18        640: 100%|██████████| 11/11 [01:20<00:00,  7.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "                   all         16         19      0.622      0.789      0.695      0.297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/100         0G      1.557      1.108      1.848         25        640: 100%|██████████| 11/11 [01:20<00:00,  7.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.26s/it]\n",
      "                   all         16         19      0.782      0.789      0.788      0.351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/100         0G      1.461      1.078      1.741         26        640: 100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n",
      "                   all         16         19      0.755      0.737      0.811      0.407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/100         0G      1.514      1.118      1.741         24        640: 100%|██████████| 11/11 [01:20<00:00,  7.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.26s/it]\n",
      "                   all         16         19      0.773      0.737      0.786      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/100         0G       1.54      1.131      1.863         24        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "                   all         16         19      0.812       0.68      0.729      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/100         0G      1.524      1.136        1.8         23        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "                   all         16         19      0.687      0.737      0.737      0.355\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/100         0G      1.368      1.022      1.733         23        640: 100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "                   all         16         19      0.825      0.789       0.84      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/100         0G      1.477      1.127      1.845         21        640: 100%|██████████| 11/11 [01:20<00:00,  7.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "                   all         16         19      0.933      0.736      0.836      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/100         0G      1.545      1.068      1.774         28        640: 100%|██████████| 11/11 [01:20<00:00,  7.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.30s/it]\n",
      "                   all         16         19      0.731      0.859      0.862      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     60/100         0G       1.45      1.035      1.731         28        640: 100%|██████████| 11/11 [01:20<00:00,  7.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.47s/it]\n",
      "                   all         16         19      0.861      0.895      0.912      0.578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     61/100         0G      1.395     0.9921       1.68         26        640: 100%|██████████| 11/11 [01:21<00:00,  7.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "                   all         16         19      0.953      0.789      0.899      0.484\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     62/100         0G      1.391      1.026      1.706         17        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.38s/it]\n",
      "                   all         16         19      0.866      0.789      0.891      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     63/100         0G      1.389     0.9821      1.695         19        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "                   all         16         19      0.811      0.895      0.855      0.474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     64/100         0G      1.443      1.011      1.714         24        640: 100%|██████████| 11/11 [01:19<00:00,  7.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "                   all         16         19      0.923      0.684      0.813       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     65/100         0G      1.476     0.9925      1.738         21        640: 100%|██████████| 11/11 [01:19<00:00,  7.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n",
      "                   all         16         19      0.857      0.789      0.847      0.469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     66/100         0G      1.381     0.9845      1.678         21        640: 100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19      0.753      0.842      0.828      0.424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     67/100         0G      1.498     0.9765      1.698         26        640: 100%|██████████| 11/11 [01:21<00:00,  7.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19      0.801      0.789      0.812      0.457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     68/100         0G      1.471       1.03      1.701         24        640: 100%|██████████| 11/11 [01:20<00:00,  7.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\n",
      "                   all         16         19        0.9      0.684      0.826      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     69/100         0G      1.353     0.9627      1.636         21        640: 100%|██████████| 11/11 [01:20<00:00,  7.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.33s/it]\n",
      "                   all         16         19      0.873      0.725      0.829      0.393\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     70/100         0G      1.384     0.9411      1.686         26        640: 100%|██████████| 11/11 [01:21<00:00,  7.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "                   all         16         19          1      0.777      0.897      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     71/100         0G      1.419      1.026      1.652         34        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "                   all         16         19      0.834      0.789      0.861      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     72/100         0G      1.413     0.9776      1.698         18        640: 100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\n",
      "                   all         16         19      0.989      0.842      0.913      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     73/100         0G      1.391     0.8984      1.713         22        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "                   all         16         19          1      0.782      0.907      0.485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     74/100         0G      1.458     0.9471      1.646         18        640: 100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.30s/it]\n",
      "                   all         16         19      0.815      0.789      0.873      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     75/100         0G      1.515     0.9776      1.729         20        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "                   all         16         19      0.787      0.842      0.869      0.478\n",
      "Stopping training early as no improvement observed in last 15 epochs. Best results observed at epoch 60, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=15) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "75 epochs completed in 1.792 hours.\n",
      "Optimizer stripped from runs\\detect\\train6\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from runs\\detect\\train6\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating runs\\detect\\train6\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.205  Python-3.11.5 torch-2.1.0+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.62s/it]\n",
      "                   all         16         19      0.861      0.895      0.912      0.578\n",
      "Speed: 3.2ms preprocess, 149.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "\n",
    "# Use the model\n",
    "results = model.train(data=\"config.yaml\", epochs=100, patience=15)  # train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 160.2ms\n",
      "Speed: 4.5ms preprocess, 160.2ms inference, 0.5ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 180.4ms\n",
      "Speed: 10.1ms preprocess, 180.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 134.5ms\n",
      "Speed: 7.0ms preprocess, 134.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 110.4ms\n",
      "Speed: 3.5ms preprocess, 110.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 47.9ms\n",
      "Speed: 0.5ms preprocess, 47.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 95.2ms\n",
      "Speed: 0.0ms preprocess, 95.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.9ms\n",
      "Speed: 3.3ms preprocess, 91.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.8ms\n",
      "Speed: 0.5ms preprocess, 91.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 39.7ms\n",
      "Speed: 1.9ms preprocess, 39.7ms inference, 8.2ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 89.7ms\n",
      "Speed: 1.9ms preprocess, 89.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 40.7ms\n",
      "Speed: 1.2ms preprocess, 40.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 92.6ms\n",
      "Speed: 1.0ms preprocess, 92.6ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 39.7ms\n",
      "Speed: 0.0ms preprocess, 39.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 84.9ms\n",
      "Speed: 5.3ms preprocess, 84.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 43.3ms\n",
      "Speed: 1.0ms preprocess, 43.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 87.1ms\n",
      "Speed: 1.5ms preprocess, 87.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 39.0ms\n",
      "Speed: 6.6ms preprocess, 39.0ms inference, 4.5ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 91.2ms\n",
      "Speed: 0.0ms preprocess, 91.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 42.1ms\n",
      "Speed: 5.7ms preprocess, 42.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 92.9ms\n",
      "Speed: 0.0ms preprocess, 92.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 41.7ms\n",
      "Speed: 6.1ms preprocess, 41.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 90.4ms\n",
      "Speed: 0.0ms preprocess, 90.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 104.2ms\n",
      "Speed: 0.0ms preprocess, 104.2ms inference, 4.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 89.2ms\n",
      "Speed: 0.0ms preprocess, 89.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.9ms\n",
      "Speed: 0.0ms preprocess, 92.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.0ms\n",
      "Speed: 0.0ms preprocess, 85.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.9ms\n",
      "Speed: 3.0ms preprocess, 81.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.4ms\n",
      "Speed: 0.0ms preprocess, 91.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 96x640 (no detections), 71.9ms\n",
      "Speed: 2.9ms preprocess, 71.9ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 640)\n",
      "0: 384x640 1 matricula, 83.7ms\n",
      "Speed: 2.2ms preprocess, 83.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.9ms\n",
      "Speed: 4.3ms preprocess, 88.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.4ms\n",
      "Speed: 0.9ms preprocess, 86.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.1ms\n",
      "Speed: 0.0ms preprocess, 84.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.5ms\n",
      "Speed: 4.0ms preprocess, 86.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.4ms\n",
      "Speed: 1.7ms preprocess, 81.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.1ms\n",
      "Speed: 0.0ms preprocess, 81.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.5ms\n",
      "Speed: 0.0ms preprocess, 88.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.1ms\n",
      "Speed: 8.1ms preprocess, 86.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.0ms\n",
      "Speed: 3.6ms preprocess, 95.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.0ms\n",
      "Speed: 0.0ms preprocess, 95.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.9ms\n",
      "Speed: 0.0ms preprocess, 90.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.2ms\n",
      "Speed: 5.6ms preprocess, 85.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.3ms\n",
      "Speed: 0.0ms preprocess, 84.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.8ms\n",
      "Speed: 1.4ms preprocess, 86.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.6ms\n",
      "Speed: 0.0ms preprocess, 89.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 93.8ms\n",
      "Speed: 0.0ms preprocess, 93.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.2ms\n",
      "Speed: 1.0ms preprocess, 89.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.5ms\n",
      "Speed: 1.3ms preprocess, 80.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.6ms\n",
      "Speed: 0.0ms preprocess, 83.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.2ms\n",
      "Speed: 0.0ms preprocess, 86.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.3ms\n",
      "Speed: 0.0ms preprocess, 84.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.3ms\n",
      "Speed: 2.6ms preprocess, 82.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.0ms\n",
      "Speed: 4.7ms preprocess, 85.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.1ms\n",
      "Speed: 0.0ms preprocess, 86.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.6ms\n",
      "Speed: 2.0ms preprocess, 81.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.1ms\n",
      "Speed: 0.0ms preprocess, 84.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.3ms\n",
      "Speed: 0.0ms preprocess, 88.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.1ms\n",
      "Speed: 0.0ms preprocess, 86.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.9ms\n",
      "Speed: 6.0ms preprocess, 84.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.5ms\n",
      "Speed: 5.8ms preprocess, 84.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 79.3ms\n",
      "Speed: 7.1ms preprocess, 79.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.2ms\n",
      "Speed: 0.0ms preprocess, 82.2ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.0ms\n",
      "Speed: 2.3ms preprocess, 83.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.4ms\n",
      "Speed: 1.5ms preprocess, 88.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.7ms\n",
      "Speed: 0.0ms preprocess, 89.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.8ms\n",
      "Speed: 0.0ms preprocess, 81.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.6ms\n",
      "Speed: 3.7ms preprocess, 88.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.8ms\n",
      "Speed: 1.8ms preprocess, 83.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.7ms\n",
      "Speed: 0.0ms preprocess, 85.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.0ms\n",
      "Speed: 4.6ms preprocess, 80.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.1ms\n",
      "Speed: 4.7ms preprocess, 80.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.0ms\n",
      "Speed: 2.3ms preprocess, 80.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.4ms\n",
      "Speed: 0.0ms preprocess, 88.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.9ms\n",
      "Speed: 2.3ms preprocess, 81.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 78.5ms\n",
      "Speed: 1.0ms preprocess, 78.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.6ms\n",
      "Speed: 0.9ms preprocess, 86.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.9ms\n",
      "Speed: 2.5ms preprocess, 83.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.1ms\n",
      "Speed: 0.0ms preprocess, 80.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.9ms\n",
      "Speed: 0.0ms preprocess, 84.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.7ms\n",
      "Speed: 0.0ms preprocess, 87.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.0ms\n",
      "Speed: 0.8ms preprocess, 82.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.2ms\n",
      "Speed: 0.0ms preprocess, 91.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.0ms\n",
      "Speed: 0.0ms preprocess, 83.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.9ms\n",
      "Speed: 2.0ms preprocess, 87.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.7ms\n",
      "Speed: 1.2ms preprocess, 82.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.2ms\n",
      "Speed: 0.0ms preprocess, 88.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.4ms\n",
      "Speed: 1.3ms preprocess, 80.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.3ms\n",
      "Speed: 5.3ms preprocess, 83.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.0ms\n",
      "Speed: 0.0ms preprocess, 88.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.6ms\n",
      "Speed: 1.0ms preprocess, 81.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.3ms\n",
      "Speed: 2.2ms preprocess, 91.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 100.8ms\n",
      "Speed: 0.8ms preprocess, 100.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 117.7ms\n",
      "Speed: 1.8ms preprocess, 117.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 96.8ms\n",
      "Speed: 4.8ms preprocess, 96.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 97.1ms\n",
      "Speed: 0.0ms preprocess, 97.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 108.5ms\n",
      "Speed: 5.0ms preprocess, 108.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 96.6ms\n",
      "Speed: 2.5ms preprocess, 96.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.8ms\n",
      "Speed: 1.6ms preprocess, 84.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.8ms\n",
      "Speed: 5.2ms preprocess, 84.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.9ms\n",
      "Speed: 0.0ms preprocess, 90.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.7ms\n",
      "Speed: 2.5ms preprocess, 82.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 103.2ms\n",
      "Speed: 82.1ms preprocess, 103.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.1ms\n",
      "Speed: 4.5ms preprocess, 84.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.0ms\n",
      "Speed: 1.4ms preprocess, 88.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.9ms\n",
      "Speed: 3.9ms preprocess, 84.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.0ms\n",
      "Speed: 1.3ms preprocess, 80.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.2ms\n",
      "Speed: 2.2ms preprocess, 86.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.5ms\n",
      "Speed: 0.0ms preprocess, 88.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.2ms\n",
      "Speed: 2.6ms preprocess, 85.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.8ms\n",
      "Speed: 0.0ms preprocess, 88.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.3ms\n",
      "Speed: 3.1ms preprocess, 86.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 78.6ms\n",
      "Speed: 4.5ms preprocess, 78.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.7ms\n",
      "Speed: 0.0ms preprocess, 91.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.6ms\n",
      "Speed: 0.5ms preprocess, 81.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.6ms\n",
      "Speed: 0.6ms preprocess, 85.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.3ms\n",
      "Speed: 2.8ms preprocess, 87.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.8ms\n",
      "Speed: 0.0ms preprocess, 86.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.0ms\n",
      "Speed: 0.0ms preprocess, 88.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.9ms\n",
      "Speed: 6.4ms preprocess, 85.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.5ms\n",
      "Speed: 1.5ms preprocess, 80.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 78.6ms\n",
      "Speed: 4.5ms preprocess, 78.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.8ms\n",
      "Speed: 0.0ms preprocess, 90.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.7ms\n",
      "Speed: 2.2ms preprocess, 82.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.3ms\n",
      "Speed: 0.0ms preprocess, 86.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.1ms\n",
      "Speed: 5.3ms preprocess, 80.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.7ms\n",
      "Speed: 1.5ms preprocess, 86.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.5ms\n",
      "Speed: 1.7ms preprocess, 83.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.4ms\n",
      "Speed: 0.0ms preprocess, 86.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.0ms\n",
      "Speed: 2.2ms preprocess, 80.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.3ms\n",
      "Speed: 0.0ms preprocess, 90.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.0ms\n",
      "Speed: 5.3ms preprocess, 85.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.8ms\n",
      "Speed: 1.8ms preprocess, 83.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.2ms\n",
      "Speed: 0.0ms preprocess, 88.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 256x640 (no detections), 66.7ms\n",
      "Speed: 0.5ms preprocess, 66.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 1 matricula, 79.8ms\n",
      "Speed: 4.5ms preprocess, 79.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 320x640 (no detections), 118.2ms\n",
      "Speed: 1.0ms preprocess, 118.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "0: 384x640 1 matricula, 82.6ms\n",
      "Speed: 0.6ms preprocess, 82.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 114.0ms\n",
      "Speed: 0.0ms preprocess, 114.0ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 51.5ms\n",
      "Speed: 1.2ms preprocess, 51.5ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 121.8ms\n",
      "Speed: 6.6ms preprocess, 121.8ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 55.9ms\n",
      "Speed: 0.0ms preprocess, 55.9ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 59.6ms\n",
      "Speed: 0.0ms preprocess, 59.6ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 88.1ms\n",
      "Speed: 4.6ms preprocess, 88.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 44.8ms\n",
      "Speed: 0.0ms preprocess, 44.8ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 50.1ms\n",
      "Speed: 0.0ms preprocess, 50.1ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 80.7ms\n",
      "Speed: 0.7ms preprocess, 80.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 42.6ms\n",
      "Speed: 1.4ms preprocess, 42.6ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 47.9ms\n",
      "Speed: 0.6ms preprocess, 47.9ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 85.8ms\n",
      "Speed: 8.7ms preprocess, 85.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 49.9ms\n",
      "Speed: 1.5ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.5ms\n",
      "Speed: 0.5ms preprocess, 84.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 47.2ms\n",
      "Speed: 4.1ms preprocess, 47.2ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.9ms\n",
      "Speed: 8.6ms preprocess, 84.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 43.1ms\n",
      "Speed: 1.0ms preprocess, 43.1ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 87.2ms\n",
      "Speed: 0.0ms preprocess, 87.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 59.3ms\n",
      "Speed: 0.0ms preprocess, 59.3ms inference, 0.5ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 81.7ms\n",
      "Speed: 1.5ms preprocess, 81.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 46.4ms\n",
      "Speed: 0.0ms preprocess, 46.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 80.7ms\n",
      "Speed: 5.2ms preprocess, 80.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 48.4ms\n",
      "Speed: 0.0ms preprocess, 48.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 86.9ms\n",
      "Speed: 2.3ms preprocess, 86.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 50.7ms\n",
      "Speed: 0.0ms preprocess, 50.7ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.8ms\n",
      "Speed: 4.0ms preprocess, 84.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 50.6ms\n",
      "Speed: 0.0ms preprocess, 50.6ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 88.2ms\n",
      "Speed: 0.0ms preprocess, 88.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 41.9ms\n",
      "Speed: 1.7ms preprocess, 41.9ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 81.1ms\n",
      "Speed: 0.8ms preprocess, 81.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 50.1ms\n",
      "Speed: 7.1ms preprocess, 50.1ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 90.7ms\n",
      "Speed: 0.0ms preprocess, 90.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 44.6ms\n",
      "Speed: 6.0ms preprocess, 44.6ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 59.8ms\n",
      "Speed: 0.0ms preprocess, 59.8ms inference, 1.1ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 84.0ms\n",
      "Speed: 4.6ms preprocess, 84.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 49.6ms\n",
      "Speed: 0.0ms preprocess, 49.6ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 55.8ms\n",
      "Speed: 5.6ms preprocess, 55.8ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 90.0ms\n",
      "Speed: 3.0ms preprocess, 90.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 49.8ms\n",
      "Speed: 0.0ms preprocess, 49.8ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 93.0ms\n",
      "Speed: 0.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 50.7ms\n",
      "Speed: 0.0ms preprocess, 50.7ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 93.1ms\n",
      "Speed: 0.0ms preprocess, 93.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.9ms\n",
      "Speed: 0.0ms preprocess, 45.9ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 87.1ms\n",
      "Speed: 0.0ms preprocess, 87.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 51.4ms\n",
      "Speed: 0.0ms preprocess, 51.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.2ms\n",
      "Speed: 1.6ms preprocess, 84.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 48.6ms\n",
      "Speed: 1.7ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 82.9ms\n",
      "Speed: 1.7ms preprocess, 82.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.1ms\n",
      "Speed: 0.0ms preprocess, 45.1ms inference, 5.1ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 50.9ms\n",
      "Speed: 1.5ms preprocess, 50.9ms inference, 3.6ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 85.7ms\n",
      "Speed: 0.5ms preprocess, 85.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 51.9ms\n",
      "Speed: 0.0ms preprocess, 51.9ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 48.3ms\n",
      "Speed: 1.0ms preprocess, 48.3ms inference, 5.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 92.9ms\n",
      "Speed: 0.0ms preprocess, 92.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 49.4ms\n",
      "Speed: 0.0ms preprocess, 49.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 48.1ms\n",
      "Speed: 0.0ms preprocess, 48.1ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 83.1ms\n",
      "Speed: 0.0ms preprocess, 83.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 44.6ms\n",
      "Speed: 5.3ms preprocess, 44.6ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 79.6ms\n",
      "Speed: 3.2ms preprocess, 79.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 50.3ms\n",
      "Speed: 4.6ms preprocess, 50.3ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 90.9ms\n",
      "Speed: 0.0ms preprocess, 90.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 44.7ms\n",
      "Speed: 5.1ms preprocess, 44.7ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.9ms\n",
      "Speed: 5.1ms preprocess, 84.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 54.7ms\n",
      "Speed: 6.6ms preprocess, 54.7ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 91.6ms\n",
      "Speed: 0.0ms preprocess, 91.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 55.2ms\n",
      "Speed: 0.0ms preprocess, 55.2ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 85.9ms\n",
      "Speed: 1.3ms preprocess, 85.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 60.1ms\n",
      "Speed: 0.0ms preprocess, 60.1ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 95.0ms\n",
      "Speed: 1.5ms preprocess, 95.0ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 82.4ms\n",
      "Speed: 0.5ms preprocess, 82.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 49.9ms\n",
      "Speed: 0.0ms preprocess, 49.9ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 60.2ms\n",
      "Speed: 0.0ms preprocess, 60.2ms inference, 0.5ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 86.2ms\n",
      "Speed: 2.2ms preprocess, 86.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 50.1ms\n",
      "Speed: 1.1ms preprocess, 50.1ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 58.7ms\n",
      "Speed: 0.0ms preprocess, 58.7ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 95.0ms\n",
      "Speed: 0.0ms preprocess, 95.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 48.7ms\n",
      "Speed: 1.4ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 80.4ms\n",
      "Speed: 3.2ms preprocess, 80.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.4ms\n",
      "Speed: 4.5ms preprocess, 87.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.9ms\n",
      "Speed: 7.1ms preprocess, 84.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 44.0ms\n",
      "Speed: 2.6ms preprocess, 44.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 87.9ms\n",
      "Speed: 0.0ms preprocess, 87.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 94.3ms\n",
      "Speed: 0.0ms preprocess, 94.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.3ms\n",
      "Speed: 0.0ms preprocess, 88.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.2ms\n",
      "Speed: 1.5ms preprocess, 85.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.4ms\n",
      "Speed: 5.3ms preprocess, 85.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.8ms\n",
      "Speed: 4.1ms preprocess, 81.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.7ms\n",
      "Speed: 1.5ms preprocess, 81.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.1ms\n",
      "Speed: 5.4ms preprocess, 84.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.5ms\n",
      "Speed: 9.5ms preprocess, 83.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.6ms\n",
      "Speed: 0.0ms preprocess, 87.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.1ms\n",
      "Speed: 0.0ms preprocess, 90.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 79.9ms\n",
      "Speed: 4.5ms preprocess, 79.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.4ms\n",
      "Speed: 3.3ms preprocess, 85.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.0ms\n",
      "Speed: 0.0ms preprocess, 90.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 55.0ms\n",
      "Speed: 2.4ms preprocess, 55.0ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 80.1ms\n",
      "Speed: 0.5ms preprocess, 80.1ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 55.4ms\n",
      "Speed: 0.0ms preprocess, 55.4ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 95.7ms\n",
      "Speed: 0.0ms preprocess, 95.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 43.7ms\n",
      "Speed: 1.5ms preprocess, 43.7ms inference, 5.1ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.8ms\n",
      "Speed: 1.1ms preprocess, 84.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 125.3ms\n",
      "Speed: 0.5ms preprocess, 125.3ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 81.9ms\n",
      "Speed: 4.6ms preprocess, 81.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 50.5ms\n",
      "Speed: 0.0ms preprocess, 50.5ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 224x640 (no detections), 122.9ms\n",
      "Speed: 0.0ms preprocess, 122.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 88.7ms\n",
      "Speed: 6.3ms preprocess, 88.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 41.7ms\n",
      "Speed: 0.0ms preprocess, 41.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "0: 160x640 (no detections), 47.5ms\n",
      "Speed: 1.1ms preprocess, 47.5ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 90.6ms\n",
      "Speed: 0.0ms preprocess, 90.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 48.5ms\n",
      "Speed: 2.2ms preprocess, 48.5ms inference, 1.7ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 48.1ms\n",
      "Speed: 0.0ms preprocess, 48.1ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 83.4ms\n",
      "Speed: 1.6ms preprocess, 83.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 50.4ms\n",
      "Speed: 0.0ms preprocess, 50.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 90.9ms\n",
      "Speed: 0.0ms preprocess, 90.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 57.4ms\n",
      "Speed: 0.0ms preprocess, 57.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 91.0ms\n",
      "Speed: 0.0ms preprocess, 91.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.9ms\n",
      "Speed: 7.0ms preprocess, 45.9ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 90.3ms\n",
      "Speed: 0.0ms preprocess, 90.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 50.0ms\n",
      "Speed: 0.0ms preprocess, 50.0ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 92.4ms\n",
      "Speed: 0.0ms preprocess, 92.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 93.3ms\n",
      "Speed: 7.0ms preprocess, 93.3ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 80.2ms\n",
      "Speed: 2.2ms preprocess, 80.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 49.2ms\n",
      "Speed: 0.0ms preprocess, 49.2ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 87.9ms\n",
      "Speed: 0.5ms preprocess, 87.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 48.5ms\n",
      "Speed: 0.0ms preprocess, 48.5ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 87.7ms\n",
      "Speed: 0.0ms preprocess, 87.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 49.6ms\n",
      "Speed: 0.5ms preprocess, 49.6ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 91.3ms\n",
      "Speed: 0.5ms preprocess, 91.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 49.0ms\n",
      "Speed: 0.0ms preprocess, 49.0ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.6ms\n",
      "Speed: 3.2ms preprocess, 84.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 47.3ms\n",
      "Speed: 3.9ms preprocess, 47.3ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 89.3ms\n",
      "Speed: 0.0ms preprocess, 89.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 49.2ms\n",
      "Speed: 4.5ms preprocess, 49.2ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 88.8ms\n",
      "Speed: 0.0ms preprocess, 88.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 37.3ms\n",
      "Speed: 0.0ms preprocess, 37.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 84.6ms\n",
      "Speed: 1.2ms preprocess, 84.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 41.7ms\n",
      "Speed: 8.2ms preprocess, 41.7ms inference, 7.6ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 83.5ms\n",
      "Speed: 7.3ms preprocess, 83.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 49.3ms\n",
      "Speed: 0.0ms preprocess, 49.3ms inference, 0.5ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 83.4ms\n",
      "Speed: 3.6ms preprocess, 83.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 39.0ms\n",
      "Speed: 6.6ms preprocess, 39.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 83.6ms\n",
      "Speed: 1.2ms preprocess, 83.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 44.2ms\n",
      "Speed: 0.0ms preprocess, 44.2ms inference, 5.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 48.0ms\n",
      "Speed: 0.0ms preprocess, 48.0ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 86.6ms\n",
      "Speed: 1.5ms preprocess, 86.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 51.7ms\n",
      "Speed: 0.0ms preprocess, 51.7ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.1ms\n",
      "Speed: 4.4ms preprocess, 84.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 52.9ms\n",
      "Speed: 0.0ms preprocess, 52.9ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 89.3ms\n",
      "Speed: 1.1ms preprocess, 89.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 45.7ms\n",
      "Speed: 0.0ms preprocess, 45.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 92.3ms\n",
      "Speed: 0.0ms preprocess, 92.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 39.3ms\n",
      "Speed: 0.0ms preprocess, 39.3ms inference, 5.1ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "0: 160x640 (no detections), 45.8ms\n",
      "Speed: 1.0ms preprocess, 45.8ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 82.0ms\n",
      "Speed: 6.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 50.4ms\n",
      "Speed: 0.0ms preprocess, 50.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 78.5ms\n",
      "Speed: 4.6ms preprocess, 78.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 38.2ms\n",
      "Speed: 1.7ms preprocess, 38.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 81.3ms\n",
      "Speed: 2.1ms preprocess, 81.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 49.7ms\n",
      "Speed: 0.0ms preprocess, 49.7ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 90.1ms\n",
      "Speed: 0.0ms preprocess, 90.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 43.7ms\n",
      "Speed: 1.0ms preprocess, 43.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 88.7ms\n",
      "Speed: 4.6ms preprocess, 88.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 61.7ms\n",
      "Speed: 0.0ms preprocess, 61.7ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 224x640 (no detections), 117.3ms\n",
      "Speed: 0.0ms preprocess, 117.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 84.4ms\n",
      "Speed: 0.0ms preprocess, 84.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 61.7ms\n",
      "Speed: 5.0ms preprocess, 61.7ms inference, 0.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 160x640 (no detections), 51.1ms\n",
      "Speed: 0.0ms preprocess, 51.1ms inference, 0.8ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 61.7ms\n",
      "Speed: 1.9ms preprocess, 61.7ms inference, 0.8ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 3 matriculas, 118.9ms\n",
      "Speed: 2.3ms preprocess, 118.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 58.0ms\n",
      "Speed: 3.9ms preprocess, 58.0ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 59.3ms\n",
      "Speed: 1.8ms preprocess, 59.3ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 98.6ms\n",
      "Speed: 0.3ms preprocess, 98.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 54.8ms\n",
      "Speed: 0.0ms preprocess, 54.8ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 60.3ms\n",
      "Speed: 0.0ms preprocess, 60.3ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 128x640 (no detections), 47.9ms\n",
      "Speed: 0.0ms preprocess, 47.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 3 matriculas, 88.4ms\n",
      "Speed: 1.7ms preprocess, 88.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 54.3ms\n",
      "Speed: 4.1ms preprocess, 54.3ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 57.8ms\n",
      "Speed: 1.9ms preprocess, 57.8ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 224x640 (no detections), 59.5ms\n",
      "Speed: 1.4ms preprocess, 59.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 3 matriculas, 84.5ms\n",
      "Speed: 7.1ms preprocess, 84.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 49.8ms\n",
      "Speed: 5.1ms preprocess, 49.8ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 60.0ms\n",
      "Speed: 5.2ms preprocess, 60.0ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 88.0ms\n",
      "Speed: 0.7ms preprocess, 88.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 58.6ms\n",
      "Speed: 0.0ms preprocess, 58.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 83.5ms\n",
      "Speed: 2.3ms preprocess, 83.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 58.9ms\n",
      "Speed: 0.0ms preprocess, 58.9ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 63.1ms\n",
      "Speed: 1.5ms preprocess, 63.1ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 89.7ms\n",
      "Speed: 0.0ms preprocess, 89.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 135.0ms\n",
      "Speed: 0.0ms preprocess, 135.0ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 224x640 (no detections), 89.8ms\n",
      "Speed: 5.2ms preprocess, 89.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 186.9ms\n",
      "Speed: 9.9ms preprocess, 186.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 89.9ms\n",
      "Speed: 5.0ms preprocess, 89.9ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 139.6ms\n",
      "Speed: 0.0ms preprocess, 139.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 116.2ms\n",
      "Speed: 3.0ms preprocess, 116.2ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 224x640 (no detections), 151.4ms\n",
      "Speed: 2.2ms preprocess, 151.4ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 189.9ms\n",
      "Speed: 5.2ms preprocess, 189.9ms inference, 0.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 166.8ms\n",
      "Speed: 1.6ms preprocess, 166.8ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 303.4ms\n",
      "Speed: 4.0ms preprocess, 303.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 138.0ms\n",
      "Speed: 2.7ms preprocess, 138.0ms inference, 8.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 316.4ms\n",
      "Speed: 5.5ms preprocess, 316.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 143.5ms\n",
      "Speed: 2.9ms preprocess, 143.5ms inference, 1.1ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 305.9ms\n",
      "Speed: 4.0ms preprocess, 305.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 121.9ms\n",
      "Speed: 3.0ms preprocess, 121.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 264.9ms\n",
      "Speed: 4.4ms preprocess, 264.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 118.7ms\n",
      "Speed: 2.6ms preprocess, 118.7ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 219.6ms\n",
      "Speed: 4.3ms preprocess, 219.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 129.3ms\n",
      "Speed: 2.5ms preprocess, 129.3ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 237.8ms\n",
      "Speed: 7.7ms preprocess, 237.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 143.0ms\n",
      "Speed: 3.0ms preprocess, 143.0ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 243.7ms\n",
      "Speed: 7.7ms preprocess, 243.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 138.7ms\n",
      "Speed: 3.0ms preprocess, 138.7ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 264.2ms\n",
      "Speed: 7.0ms preprocess, 264.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 122.6ms\n",
      "Speed: 3.0ms preprocess, 122.6ms inference, 1.7ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 259.8ms\n",
      "Speed: 4.1ms preprocess, 259.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 125.0ms\n",
      "Speed: 2.5ms preprocess, 125.0ms inference, 1.5ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 264.5ms\n",
      "Speed: 8.4ms preprocess, 264.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 170.3ms\n",
      "Speed: 2.7ms preprocess, 170.3ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 260.0ms\n",
      "Speed: 4.0ms preprocess, 260.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 141.9ms\n",
      "Speed: 2.7ms preprocess, 141.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 255.9ms\n",
      "Speed: 7.1ms preprocess, 255.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 153.1ms\n",
      "Speed: 4.7ms preprocess, 153.1ms inference, 1.1ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 258.8ms\n",
      "Speed: 4.0ms preprocess, 258.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 153.7ms\n",
      "Speed: 2.8ms preprocess, 153.7ms inference, 1.8ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 239.8ms\n",
      "Speed: 5.1ms preprocess, 239.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 137.9ms\n",
      "Speed: 1.5ms preprocess, 137.9ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 231.6ms\n",
      "Speed: 5.3ms preprocess, 231.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 184.1ms\n",
      "Speed: 2.9ms preprocess, 184.1ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 256.4ms\n",
      "Speed: 6.4ms preprocess, 256.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 179.6ms\n",
      "Speed: 3.1ms preprocess, 179.6ms inference, 2.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 261.1ms\n",
      "Speed: 4.0ms preprocess, 261.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 141.4ms\n",
      "Speed: 1.5ms preprocess, 141.4ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 264.0ms\n",
      "Speed: 5.1ms preprocess, 264.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 151.9ms\n",
      "Speed: 2.8ms preprocess, 151.9ms inference, 0.7ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 231.7ms\n",
      "Speed: 5.0ms preprocess, 231.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 172.2ms\n",
      "Speed: 4.6ms preprocess, 172.2ms inference, 1.5ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 455.8ms\n",
      "Speed: 6.7ms preprocess, 455.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 172.0ms\n",
      "Speed: 4.3ms preprocess, 172.0ms inference, 2.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 261.3ms\n",
      "Speed: 5.7ms preprocess, 261.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 152.1ms\n",
      "Speed: 3.5ms preprocess, 152.1ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 266.4ms\n",
      "Speed: 6.2ms preprocess, 266.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 147.1ms\n",
      "Speed: 4.6ms preprocess, 147.1ms inference, 2.6ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 251.8ms\n",
      "Speed: 6.6ms preprocess, 251.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 149.0ms\n",
      "Speed: 4.0ms preprocess, 149.0ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 160x640 (no detections), 60.6ms\n",
      "Speed: 1.1ms preprocess, 60.6ms inference, 0.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 268.0ms\n",
      "Speed: 7.8ms preprocess, 268.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 53.3ms\n",
      "Speed: 1.6ms preprocess, 53.3ms inference, 1.1ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 118.8ms\n",
      "Speed: 2.8ms preprocess, 118.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 70.1ms\n",
      "Speed: 2.5ms preprocess, 70.1ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 107.9ms\n",
      "Speed: 2.0ms preprocess, 107.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 73.1ms\n",
      "Speed: 2.2ms preprocess, 73.1ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 120.0ms\n",
      "Speed: 3.4ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 68.5ms\n",
      "Speed: 1.3ms preprocess, 68.5ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 117.1ms\n",
      "Speed: 3.2ms preprocess, 117.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 82.3ms\n",
      "Speed: 1.9ms preprocess, 82.3ms inference, 1.6ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 170.1ms\n",
      "Speed: 2.9ms preprocess, 170.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 76.7ms\n",
      "Speed: 1.7ms preprocess, 76.7ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 125.1ms\n",
      "Speed: 3.0ms preprocess, 125.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 71.4ms\n",
      "Speed: 2.0ms preprocess, 71.4ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 123.9ms\n",
      "Speed: 3.5ms preprocess, 123.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 84.6ms\n",
      "Speed: 1.9ms preprocess, 84.6ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 124.3ms\n",
      "Speed: 3.3ms preprocess, 124.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 75.2ms\n",
      "Speed: 1.9ms preprocess, 75.2ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 256x640 (no detections), 94.6ms\n",
      "Speed: 2.2ms preprocess, 94.6ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 2 matriculas, 130.8ms\n",
      "Speed: 3.7ms preprocess, 130.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 256x640 (no detections), 94.2ms\n",
      "Speed: 1.5ms preprocess, 94.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 1 matricula, 123.6ms\n",
      "Speed: 3.3ms preprocess, 123.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 74.1ms\n",
      "Speed: 1.6ms preprocess, 74.1ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 126.7ms\n",
      "Speed: 3.7ms preprocess, 126.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 83.4ms\n",
      "Speed: 2.1ms preprocess, 83.4ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 224x640 (no detections), 97.1ms\n",
      "Speed: 1.6ms preprocess, 97.1ms inference, 0.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 145.8ms\n",
      "Speed: 3.7ms preprocess, 145.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 93.8ms\n",
      "Speed: 2.4ms preprocess, 93.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 386.6ms\n",
      "Speed: 4.3ms preprocess, 386.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 83.3ms\n",
      "Speed: 2.0ms preprocess, 83.3ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 128x640 (no detections), 60.4ms\n",
      "Speed: 2.1ms preprocess, 60.4ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 2 matriculas, 135.0ms\n",
      "Speed: 4.2ms preprocess, 135.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 82.8ms\n",
      "Speed: 2.1ms preprocess, 82.8ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 160x640 (no detections), 74.3ms\n",
      "Speed: 1.5ms preprocess, 74.3ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 117.5ms\n",
      "Speed: 3.4ms preprocess, 117.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 81.3ms\n",
      "Speed: 0.8ms preprocess, 81.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 160x640 (no detections), 71.7ms\n",
      "Speed: 1.5ms preprocess, 71.7ms inference, 0.7ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 122.1ms\n",
      "Speed: 3.5ms preprocess, 122.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 118.5ms\n",
      "Speed: 3.2ms preprocess, 118.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 80.5ms\n",
      "Speed: 2.0ms preprocess, 80.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 167.8ms\n",
      "Speed: 6.3ms preprocess, 167.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 117.9ms\n",
      "Speed: 5.0ms preprocess, 117.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 79.2ms\n",
      "Speed: 1.0ms preprocess, 79.2ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 122.8ms\n",
      "Speed: 3.2ms preprocess, 122.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 256x640 (no detections), 83.7ms\n",
      "Speed: 2.0ms preprocess, 83.7ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 1 matricula, 113.9ms\n",
      "Speed: 3.6ms preprocess, 113.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 256x640 (no detections), 98.5ms\n",
      "Speed: 1.0ms preprocess, 98.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 1 matricula, 113.9ms\n",
      "Speed: 2.5ms preprocess, 113.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 77.2ms\n",
      "Speed: 3.2ms preprocess, 77.2ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 121.5ms\n",
      "Speed: 2.5ms preprocess, 121.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 84.8ms\n",
      "Speed: 2.0ms preprocess, 84.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 122.5ms\n",
      "Speed: 4.1ms preprocess, 122.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 256x640 (no detections), 95.0ms\n",
      "Speed: 2.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 1 matricula, 120.0ms\n",
      "Speed: 2.8ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 256x640 (no detections), 96.2ms\n",
      "Speed: 2.0ms preprocess, 96.2ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 288x640 (no detections), 218.8ms\n",
      "Speed: 2.0ms preprocess, 218.8ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "0: 384x640 2 matriculas, 123.8ms\n",
      "Speed: 3.1ms preprocess, 123.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 84.2ms\n",
      "Speed: 2.2ms preprocess, 84.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 125.9ms\n",
      "Speed: 2.0ms preprocess, 125.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 89.5ms\n",
      "Speed: 1.0ms preprocess, 89.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 125.9ms\n",
      "Speed: 3.0ms preprocess, 125.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 135.3ms\n",
      "Speed: 3.6ms preprocess, 135.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.0ms\n",
      "Speed: 3.0ms preprocess, 126.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 448x640 (no detections), 288.1ms\n",
      "Speed: 4.0ms preprocess, 288.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "0: 384x640 1 matricula, 119.3ms\n",
      "Speed: 4.6ms preprocess, 119.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.3ms\n",
      "Speed: 4.5ms preprocess, 122.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 165.5ms\n",
      "Speed: 3.7ms preprocess, 165.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 132.4ms\n",
      "Speed: 2.7ms preprocess, 132.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.7ms\n",
      "Speed: 3.2ms preprocess, 122.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 119.5ms\n",
      "Speed: 3.0ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.0ms\n",
      "Speed: 2.5ms preprocess, 123.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 115.9ms\n",
      "Speed: 2.6ms preprocess, 115.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 118.5ms\n",
      "Speed: 4.1ms preprocess, 118.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.6ms\n",
      "Speed: 3.0ms preprocess, 122.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.6ms\n",
      "Speed: 3.0ms preprocess, 123.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 119.8ms\n",
      "Speed: 3.1ms preprocess, 119.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.5ms\n",
      "Speed: 3.1ms preprocess, 121.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 113.6ms\n",
      "Speed: 2.4ms preprocess, 113.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 116.5ms\n",
      "Speed: 2.7ms preprocess, 116.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 115.6ms\n",
      "Speed: 3.8ms preprocess, 115.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 112.1ms\n",
      "Speed: 3.3ms preprocess, 112.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 118.0ms\n",
      "Speed: 4.1ms preprocess, 118.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import easyocr\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Carga de los modelos\n",
    "# Carga del modelo YOLO\n",
    "car_model = YOLO('yolov8n.pt')\n",
    "\n",
    "license_plate_model = YOLO('best.pt')\n",
    "\n",
    "# Captura de video desde un archivo\n",
    "cap = cv2.VideoCapture('prueba.mp4')  # Reemplaza 'tu_video.mp4' con el nombre de tu archivo de video\n",
    "\n",
    "# Inicializa el lector de OCR de EasyOCR\n",
    "reader = easyocr.Reader(lang_list=['en'])  # Ajusta los idiomas según tus necesidades\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Realiza detección de vehículos en el frame\n",
    "    car_results = license_plate_model(frame, stream=True)\n",
    "\n",
    "    for r in car_results:\n",
    "        car_boxes = r.boxes\n",
    "\n",
    "        for car_box in car_boxes:\n",
    "            x1, y1, x2, y2 = car_box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Dibuja el bounding box del vehículo\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "            # Realiza detección de matrículas en el área del vehículo\n",
    "            license_plate_crop = frame[y1:y2, x1:x2]\n",
    "            license_plate_results = license_plate_model(license_plate_crop, stream=True)\n",
    "\n",
    "            for lp_result in license_plate_results:\n",
    "                lp_boxes = lp_result.boxes\n",
    "\n",
    "                for lp_box in lp_boxes:\n",
    "                    x1_lp, y1_lp, x2_lp, y2_lp = lp_box.xyxy[0]\n",
    "                    x1_lp, y1_lp, x2_lp, y2_lp = int(x1_lp), int(y1_lp), int(x2_lp), int(y2_lp)\n",
    "\n",
    "                    # Dibuja el bounding box de la matrícula\n",
    "                    cv2.rectangle(frame, (x1 + x1_lp, y1 + y1_lp), (x1 + x2_lp, y1 + y2_lp), (0, 0, 255), 2)\n",
    "\n",
    "                    # Realiza OCR en la matrícula con EasyOCR\n",
    "                    license_plate_crop = frame[y1 + y1_lp:y1 + y2_lp, x1 + x1_lp:x1 + x2_lp]\n",
    "                    gray_plate = cv2.cvtColor(license_plate_crop, cv2.COLOR_BGR2GRAY)\n",
    "                    results = reader.readtext(gray_plate)\n",
    "\n",
    "                    if results:\n",
    "                        license_plate_text = results[0][1]\n",
    "\n",
    "                        # Muestra el texto de la matrícula en la ventana\n",
    "                        cv2.putText(frame, license_plate_text, (x1 + x1_lp, y1 + y1_lp - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "    # Muestra el frame con las detecciones en una ventana\n",
    "    cv2.imshow('Video con Detecciones', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import easyocr\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 256x640 1 matricula, 72.5ms\n",
      "Speed: 4.0ms preprocess, 72.5ms inference, 5.6ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 1 matricula, 65.7ms\n",
      "Speed: 1.3ms preprocess, 65.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'matricula'}\n",
      "orig_img: array([[[153, 147, 147],\n",
      "        [177, 170, 170],\n",
      "        [192, 185, 185],\n",
      "        ...,\n",
      "        [ 58,  56,  54],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[150, 145, 144],\n",
      "        [160, 153, 153],\n",
      "        [211, 204, 204],\n",
      "        ...,\n",
      "        [ 72,  69,  66],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[154, 149, 148],\n",
      "        [137, 130, 130],\n",
      "        [187, 180, 180],\n",
      "        ...,\n",
      "        [133, 130, 127],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 29,  28,  25],\n",
      "        [ 27,  26,  23],\n",
      "        [ 26,  25,  22],\n",
      "        ...,\n",
      "        [194, 192, 191],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[ 25,  24,  21],\n",
      "        [ 25,  24,  21],\n",
      "        [ 25,  24,  21],\n",
      "        ...,\n",
      "        [195, 193, 192],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[ 24,  23,  20],\n",
      "        [ 24,  23,  20],\n",
      "        [ 24,  23,  20],\n",
      "        ...,\n",
      "        [195, 193, 192],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8)\n",
      "orig_shape: (248, 636)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: None\n",
      "speed: {'preprocess': 1.3301372528076172, 'inference': 65.69838523864746, 'postprocess': 0.0}]\n",
      "Confidence ---> 0.3\n",
      "Class name --> matricula\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"matricula\"]\n",
    "\n",
    "# Lee la imagen desde un archivo\n",
    "img = cv2.imread('mssulove.png')\n",
    "\n",
    "# Perform inference on the image\n",
    "results = model(img) \n",
    "print(model(img))\n",
    "# Para cada detección\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "\n",
    "    for box in boxes:\n",
    "        # Contenedor\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "\n",
    "        # Confianza\n",
    "        confidence = math.ceil((box.conf[0]*100))/100\n",
    "        print(\"Confidence --->\",confidence)\n",
    "\n",
    "        # Clase\n",
    "        cls = int(box.cls[0])\n",
    "        print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "        # Convierte identificador numérico de clase a un color RGB\n",
    "        escala = int((cls / len(classNames)) * 255 * 3)\n",
    "        if escala >= 255*2:\n",
    "            R = 255\n",
    "            G = 255\n",
    "            B = escala - 255*2\n",
    "        else:\n",
    "            if escala >= 255:\n",
    "                R = 255\n",
    "                G = escala - 255\n",
    "                B = 0\n",
    "            else:\n",
    "                R = escala\n",
    "                G = 0\n",
    "                B = 0\n",
    "\n",
    "        # Dibuja el contenedor y clase\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "        cv2.putText(img, classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "# Muestra la imagen con las detecciones\n",
    "cv2.imshow('Imagen con Detecciones', img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Destruye la ventana\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('yolov7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54711ba1bddc392d48ca20e80feaa9b2e23d43069aa8b98ed16355091034ff6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
