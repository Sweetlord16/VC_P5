{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import math \n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde cámara, detección con yolov8 y modelo nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 dog, 205.1ms\n",
      "Speed: 21.8ms preprocess, 205.1ms inference, 23.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> dog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 158.6ms\n",
      "Speed: 2.0ms preprocess, 158.6ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 141.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.3ms preprocess, 141.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 145.0ms\n",
      "Speed: 2.0ms preprocess, 145.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 125.5ms\n",
      "Speed: 1.5ms preprocess, 125.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 124.4ms\n",
      "Speed: 0.9ms preprocess, 124.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 125.2ms\n",
      "Speed: 1.0ms preprocess, 125.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 132.4ms\n",
      "Speed: 1.0ms preprocess, 132.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 132.8ms\n",
      "Speed: 3.1ms preprocess, 132.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 202.7ms\n",
      "Speed: 2.5ms preprocess, 202.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 bench, 118.0ms\n",
      "Speed: 2.0ms preprocess, 118.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> bench\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 1 bench, 120.1ms\n",
      "Speed: 1.5ms preprocess, 120.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 121.5ms\n",
      "Speed: 1.0ms preprocess, 121.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> bench\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 3 persons, 1 bench, 145.9ms\n",
      "Speed: 1.5ms preprocess, 145.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 bench, 145.7ms\n",
      "Speed: 2.5ms preprocess, 145.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> bench\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> bench\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 1 bench, 134.4ms\n",
      "Speed: 1.6ms preprocess, 134.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 119.9ms\n",
      "Speed: 1.9ms preprocess, 119.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> bench\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 1 laptop, 122.4ms\n",
      "Speed: 2.6ms preprocess, 122.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 126.3ms\n",
      "Speed: 1.0ms preprocess, 126.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.78\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 3 persons, 133.0ms\n",
      "Speed: 2.0ms preprocess, 133.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 132.3ms\n",
      "Speed: 2.4ms preprocess, 132.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 136.7ms\n",
      "Speed: 2.0ms preprocess, 136.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 118.1ms\n",
      "Speed: 2.6ms preprocess, 118.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.96\n",
      "Class name --> person\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 121.7ms\n",
      "Speed: 2.5ms preprocess, 121.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 110.6ms\n",
      "Speed: 2.7ms preprocess, 110.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.96\n",
      "Class name --> person\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.95\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 135.3ms\n",
      "Speed: 4.0ms preprocess, 135.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 139.5ms\n",
      "Speed: 3.0ms preprocess, 139.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 139.5ms\n",
      "Speed: 1.0ms preprocess, 139.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 121.1ms\n",
      "Speed: 1.5ms preprocess, 121.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 176.3ms\n",
      "Speed: 2.6ms preprocess, 176.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 132.2ms\n",
      "Speed: 1.0ms preprocess, 132.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.94\n",
      "Class name --> person\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 134.7ms\n",
      "Speed: 2.3ms preprocess, 134.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 133.9ms\n",
      "Speed: 1.2ms preprocess, 133.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 137.4ms\n",
      "Speed: 2.1ms preprocess, 137.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 116.3ms\n",
      "Speed: 1.0ms preprocess, 116.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 121.2ms\n",
      "Speed: 1.8ms preprocess, 121.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 130.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms preprocess, 130.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 140.8ms\n",
      "Speed: 2.5ms preprocess, 140.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 134.9ms\n",
      "Speed: 2.0ms preprocess, 134.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 126.1ms\n",
      "Speed: 1.0ms preprocess, 126.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "\n",
    "# Captura desde lawebcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen válida\n",
    "    if ret:  \n",
    "        # Perform inference on an image\n",
    "        results = model(img, stream=True)\n",
    "        \n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confidence --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador numérico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de caracteres tras instalar pytesseract y tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytesseract'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Eric\\Desktop\\vc-5\\P5\\VC_P5.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/P5/VC_P5.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Tesseract\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/P5/VC_P5.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/P5/VC_P5.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytesseract\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/P5/VC_P5.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Previamente debes descargar los ejecutables\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/P5/VC_P5.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Si la ruta de Tesseract no está en el PATH, ruta al ejecutable\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/P5/VC_P5.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m pytesseract\u001b[39m.\u001b[39mpytesseract\u001b[39m.\u001b[39mtesseract_cmd \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:/Program Files/Tesseract-OCR/tesseract\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytesseract'"
     ]
    }
   ],
   "source": [
    "# Tesseract\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Previamente debes descargar los ejecutables\n",
    "# Si la ruta de Tesseract no está en el PATH, ruta al ejecutable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "# Lenguajes disponibles\n",
    "print(pytesseract.get_languages(config=''))\n",
    "\n",
    "#Cargo imagen y ocnvierto a RGB\n",
    "img = cv2.imread('toy.tif') \n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#Aplica reconocedor a imagen cargada\n",
    "print(pytesseract.image_to_string(img_rgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento decaracteres tras instalar easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[49, 85], [617, 85], [617, 147], [49, 147]], 'Hasta el infinito y más allá', 0.6744628105513019)]\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "\n",
    "#Carga del modelo de lengua\n",
    "reader = easyocr.Reader(['es'], gpu=False) \n",
    "\n",
    "#Reconocimiento de una imagen\n",
    "result = reader.readtext('toy.tif')\n",
    "print(result)\n",
    "\n",
    "#Con restricción de caracteres reconocibles\n",
    "#result = reader.readtext('toy.tif', allowlist ='0123456789')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eric\\Desktop\\vc-5\\P5\n",
      "c:\\Users\\Eric\\anaconda3\\envs\\VC_P1\\python311.zip\n",
      "c:\\Users\\Eric\\anaconda3\\envs\\VC_P1\\DLLs\n",
      "c:\\Users\\Eric\\anaconda3\\envs\\VC_P1\\Lib\n",
      "c:\\Users\\Eric\\anaconda3\\envs\\VC_P1\n",
      "\n",
      "C:\\Users\\Eric\\AppData\\Roaming\\Python\\Python311\\site-packages\n",
      "c:\\Users\\Eric\\anaconda3\\envs\\VC_P1\\Lib\\site-packages\n",
      "c:\\Users\\Eric\\anaconda3\\envs\\VC_P1\\Lib\\site-packages\\win32\n",
      "c:\\Users\\Eric\\anaconda3\\envs\\VC_P1\\Lib\\site-packages\\win32\\lib\n",
      "c:\\Users\\Eric\\anaconda3\\envs\\VC_P1\\Lib\\site-packages\\Pythonwin\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "for path in sys.path:\n",
    "    print(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba yolo con imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x640 4 persons, 426.5ms\n",
      "Speed: 46.7ms preprocess, 426.5ms inference, 39.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "# Carga la imagen que deseas procesar\n",
    "image_path = 'images.png'  # Reemplaza 'tu_imagen.jpg' por la ruta de tu imagen\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Realiza inferencia en la imagen\n",
    "results = model(img)\n",
    "\n",
    "# Para cada detección\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "\n",
    "    for box in boxes:\n",
    "        # Contenedor\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)  # Convierte a valores enteros\n",
    "\n",
    "        # Confianza\n",
    "        confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "        print(\"Confidence --->\", confidence)\n",
    "\n",
    "        # Clase\n",
    "        cls = int(box.cls[0])\n",
    "        print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "        # Convierte el identificador numérico de la clase en un color RGB\n",
    "        escala = int((cls / len(classNames)) * 255 * 3)\n",
    "        if escala >= 255 * 2:\n",
    "            R = 255\n",
    "            G = 255\n",
    "            B = escala - 255 * 2\n",
    "        else:\n",
    "            if escala >= 255:\n",
    "                R = 255\n",
    "                G = escala - 255\n",
    "                B = 0\n",
    "            else:\n",
    "                R = escala\n",
    "                G = 0\n",
    "                B = 0\n",
    "\n",
    "        # Dibuja el contenedor y la clase\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "        cv2.putText(img, classNames[cls], [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "# Muestra la imagen con las detecciones\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método 1: Solo falta el ocr, no mezcles el codigo de abajo con lo q vayas a hacer,\n",
    "Crea un bloque nuevo copia y pega y empieza desde ahí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 256x640 2 cars, 59.2ms\n",
      "Speed: 0.0ms preprocess, 59.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.94\n",
      "Class name --> car\n",
      "Confidence ---> 0.34\n",
      "Class name --> car\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "from ultralytics import YOLO  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Función para verificar si un contorno tiene forma rectangular aproximada\n",
    "def is_approximately_rectangular(contour, epsilon=0.009):\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, epsilon * perimeter, True)\n",
    "    return len(approx) == 4\n",
    "\n",
    "# Carga del modelo YOLO\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "# Carga la imagen que deseas procesar\n",
    "image_path = 'prueba.jpg'  \n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Realiza inferencia en la imagen\n",
    "results = model(img)\n",
    "\n",
    "# Para cada detección\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "\n",
    "    for box in boxes:\n",
    "        # Contenedor\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)  # Convierte a valores enteros\n",
    "\n",
    "        # Confianza\n",
    "        confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "        print(\"Confidence --->\", confidence)\n",
    "\n",
    "        # Clase\n",
    "        cls = int(box.cls[0])\n",
    "        print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "        # Convierte el identificador numérico de la clase en un color RGB\n",
    "        escala = int((cls / len(classNames)) * 255 * 3)\n",
    "        if escala >= 255 * 2:\n",
    "            R = 255\n",
    "            G = 255\n",
    "            B = escala - 255 * 2\n",
    "        else:\n",
    "            if escala >= 255:\n",
    "                R = 255\n",
    "                G = escala - 255\n",
    "                B = 0\n",
    "            else:\n",
    "                R = escala\n",
    "                G = 0\n",
    "                B = 0\n",
    "\n",
    "        # Dibuja el contenedor y la clase\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "        cv2.putText(img, classNames[cls], (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Obtén la ROI\n",
    "        roi = img[y1:y2, x1:x2]\n",
    "\n",
    "        # Convierte ROI a escala de grises\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Aplica umbral para encontrar contornos\n",
    "        _, thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Encuentra contornos en la ROI\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Umbral de área para considerar como contorno grande (ajusta este valor según tus necesidades)\n",
    "        area_threshold = 1000\n",
    "\n",
    "        # Filtra los contornos que tienen forma rectangular aproximada y un área grande\n",
    "        filtered_contours = [contour for contour in contours if is_approximately_rectangular(contour) and cv2.contourArea(contour) > area_threshold]\n",
    "\n",
    "        # Dibuja los contornos filtrados en la ROI\n",
    "        cv2.drawContours(roi, filtered_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "        # Dibuja los contornos filtrados en la ROI\n",
    "        cv2.drawContours(roi, filtered_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Muestra la imagen con las detecciones y los contornos filtrados\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset\\\\train\\\\images\\\\0802HFP_jpg.rf.30755e346cf1455361344eeeceb55cb1.jpg', 'dataset\\\\train\\\\images\\\\0802HFP_jpg.rf.30cd9ca231b6667068ad26b808dd99da.jpg', 'dataset\\\\train\\\\images\\\\0802HFP_jpg.rf.ba381edbab2dcddf24f9739d99ae26d4.jpg', 'dataset\\\\train\\\\images\\\\1159FPG_jpg.rf.165f7f6df48b376a9863eab1befe71bf.jpg', 'dataset\\\\train\\\\images\\\\1159FPG_jpg.rf.3ff8b432d3fb4ab2537c7f6ec80ce560.jpg', 'dataset\\\\train\\\\images\\\\1159FPG_jpg.rf.8ac0d77c1a7d6f3b8f208fe9ec6f887f.jpg', 'dataset\\\\train\\\\images\\\\1319FSX_jpg.rf.42cac49225e519a2c8e5d1ef1bc1a9df.jpg', 'dataset\\\\train\\\\images\\\\1319FSX_jpg.rf.8aa60298e9d1b1a0ec29e0189c61bf40.jpg', 'dataset\\\\train\\\\images\\\\1319FSX_jpg.rf.f37800d74affae5e5dc10a94693dbfbf.jpg', 'dataset\\\\train\\\\images\\\\15989862207427_jpg.rf.8f731f82cf1639282dc1a5c81fd7d483.jpg', 'dataset\\\\train\\\\images\\\\15989862207427_jpg.rf.8ff0c28508f614a0427c9a7bf48136db.jpg', 'dataset\\\\train\\\\images\\\\15989862207427_jpg.rf.d4400cbe860cbdc49c9f7a7ac785a91c.jpg', 'dataset\\\\train\\\\images\\\\1637067480508_jpg.rf.49922346df4dbbe9f88c7ac5abaead22.jpg', 'dataset\\\\train\\\\images\\\\1637067480508_jpg.rf.81614cec62651fd757f938c9293738b5.jpg', 'dataset\\\\train\\\\images\\\\1637067480508_jpg.rf.e5c02fa0c2eb431dc8343b5ec703364e.jpg', 'dataset\\\\train\\\\images\\\\2711LKN_jpg.rf.9d59545c3a3188695ec37613ae290ee5.jpg', 'dataset\\\\train\\\\images\\\\2711LKN_jpg.rf.a034e77579ff63c99d4a46495303c37b.jpg', 'dataset\\\\train\\\\images\\\\2711LKN_jpg.rf.a958f1f2817824fd4fa83f39806e09b1.jpg', 'dataset\\\\train\\\\images\\\\2942HFB_jpg.rf.8263fa536f5d315f40e3807591092bba.jpg', 'dataset\\\\train\\\\images\\\\2942HFB_jpg.rf.cd3eeddbc3fa7d636c5db16700f285b6.jpg', 'dataset\\\\train\\\\images\\\\2942HFB_jpg.rf.fbf11cef15a1099115a1a06d5e151d04.jpg', 'dataset\\\\train\\\\images\\\\3838KWB_jpg.rf.ace411bd6e092f78b250cdf0c0a71bfa.jpg', 'dataset\\\\train\\\\images\\\\3838KWB_jpg.rf.b01806a282c2631288a4d62a189e2135.jpg', 'dataset\\\\train\\\\images\\\\3838KWB_jpg.rf.e9f960b1ac9e2f957be2a50e29317099.jpg', 'dataset\\\\train\\\\images\\\\4078BVX_jpg.rf.4358dea669efd28b780f048f930d293d.jpg', 'dataset\\\\train\\\\images\\\\4078BVX_jpg.rf.ad45943dcf4ffac6044159efa348f466.jpg', 'dataset\\\\train\\\\images\\\\4078BVX_jpg.rf.d6848a6462560959c8368f9616feeb0f.jpg', 'dataset\\\\train\\\\images\\\\4950KZK_jpg.rf.14c74f9c463e6b15d8a111f95a18936a.jpg', 'dataset\\\\train\\\\images\\\\4950KZK_jpg.rf.5673172dd504e94a89c92fa148cadf0b.jpg', 'dataset\\\\train\\\\images\\\\4950KZK_jpg.rf.f51cf698836c629817570298b4e504dc.jpg', 'dataset\\\\train\\\\images\\\\4_jpg.rf.5fc6f3248156631d9e8f89b9c56f0c42.jpg', 'dataset\\\\train\\\\images\\\\4_jpg.rf.85c872bff5dff7e2d5d7a976d3cdd996.jpg', 'dataset\\\\train\\\\images\\\\4_jpg.rf.861c1294fa47fb2e07ece975981cfafd.jpg', 'dataset\\\\train\\\\images\\\\5921LMH_jpg.rf.0e2838ecb1dca96304e5b7efd4a7d372.jpg', 'dataset\\\\train\\\\images\\\\5921LMH_jpg.rf.bb888f2d8ccfa2e85da9a516e9c4a6e1.jpg', 'dataset\\\\train\\\\images\\\\5921LMH_jpg.rf.e51d2d2ccab8e372e88d4187cf03c71c.jpg', 'dataset\\\\train\\\\images\\\\5_jpg.rf.436d0c6cae5ebe1ed5d3cd07ba8a4207.jpg', 'dataset\\\\train\\\\images\\\\5_jpg.rf.48b4f45d14bd9236cd6f56729a6227bd.jpg', 'dataset\\\\train\\\\images\\\\5_jpg.rf.6fb58f888ec516ad776a197c0a1bf834.jpg', 'dataset\\\\train\\\\images\\\\6299JJL_jpg.rf.4be7aa1ef9a1ff678177f06833155eb6.jpg', 'dataset\\\\train\\\\images\\\\6299JJL_jpg.rf.983005f219cf60ed438ce6b07c81d734.jpg', 'dataset\\\\train\\\\images\\\\6299JJL_jpg.rf.cf894416237da38468835f4b12c00e07.jpg', 'dataset\\\\train\\\\images\\\\7270GVF_jpg.rf.2f9bf27a5966e86bfe14bcf8a16499ca.jpg', 'dataset\\\\train\\\\images\\\\7270GVF_jpg.rf.5d1bcbea314ce2ec8aad08dc98ace54d.jpg', 'dataset\\\\train\\\\images\\\\7270GVF_jpg.rf.efc9c982fbcc073d6b1dee7abe2e3aa4.jpg', 'dataset\\\\train\\\\images\\\\7_jpg.rf.ad23a58c142fc4c2c48abb60aaaaa9d0.jpg', 'dataset\\\\train\\\\images\\\\7_jpg.rf.ce895c85153035661ab005e7a4a5fd64.jpg', 'dataset\\\\train\\\\images\\\\7_jpg.rf.e6fadae9459c52dbe6abc39219555f23.jpg', 'dataset\\\\train\\\\images\\\\8_jpg.rf.c7fc155d7467fbd25c19db3d786dde60.jpg', 'dataset\\\\train\\\\images\\\\8_jpg.rf.da898b55d6724bbc6b312f9f083525a7.jpg', 'dataset\\\\train\\\\images\\\\8_jpg.rf.fb8e579f8b21d0b22263ca547a65d587.jpg', 'dataset\\\\train\\\\images\\\\CNP2309AW_jpg.rf.53d9c136d9bc859208cf802c2ebfe298.jpg', 'dataset\\\\train\\\\images\\\\CNP2309AW_jpg.rf.9bec9d57c9a31f1e658271854930ff39.jpg', 'dataset\\\\train\\\\images\\\\CNP2309AW_jpg.rf.c5ad418aecb109cc482240301c11ee1f.jpg', 'dataset\\\\train\\\\images\\\\Coches-mas-vendidos-Espana-2018_jpg.rf.24d660a205abf48d0b7e4e9f4a60cfff.jpg', 'dataset\\\\train\\\\images\\\\Coches-mas-vendidos-Espana-2018_jpg.rf.6c00c102018789f58d2b39a6ffb04c27.jpg', 'dataset\\\\train\\\\images\\\\Coches-mas-vendidos-Espana-2018_jpg.rf.d48fdee824b50d0ae4e0cc0a8806f088.jpg', 'dataset\\\\train\\\\images\\\\como-saber-que-ano-es-tu-coche-matricula_jpg.rf.2ba5ea0c6c9a67ee65e76c3ab6ed6715.jpg', 'dataset\\\\train\\\\images\\\\como-saber-que-ano-es-tu-coche-matricula_jpg.rf.c1d8ca3020ddbe6d2aaceedb3b2d06e1.jpg', 'dataset\\\\train\\\\images\\\\como-saber-que-ano-es-tu-coche-matricula_jpg.rf.fadd2cf0742a6930335a8d1f5beed428.jpg', 'dataset\\\\train\\\\images\\\\GC4370BV_jpg.rf.087798a45f907d690e0f5dc40480c4e6.jpg', 'dataset\\\\train\\\\images\\\\GC4370BV_jpg.rf.184189be68c7a463054c2b401507681a.jpg', 'dataset\\\\train\\\\images\\\\GC4370BV_jpg.rf.3a6ed1475edc4eaa2cbe882732c5b661.jpg', 'dataset\\\\train\\\\images\\\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-21_jpg.rf.431f7c473fc93b38322437342e36c981.jpg', 'dataset\\\\train\\\\images\\\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-21_jpg.rf.7e1ccd659e5eb877f1440c90ce3f959b.jpg', 'dataset\\\\train\\\\images\\\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-21_jpg.rf.a1d838443b180e60bac901e5b102c431.jpg', 'dataset\\\\train\\\\images\\\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-23_jpg.rf.044cc425696fe0300f9dad44d15bb60b.jpg', 'dataset\\\\train\\\\images\\\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-23_jpg.rf.68edadc0fa4dee14c8b327d5afe0b04a.jpg', 'dataset\\\\train\\\\images\\\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-23_jpg.rf.e45b2dd2933a08a8be70c4a54dbe44e4.jpg', 'dataset\\\\train\\\\images\\\\imagen8709_NM8710_MG7782316_jpeg.rf.277c597582ce042f109644bf66809412.jpg', 'dataset\\\\train\\\\images\\\\imagen8709_NM8710_MG7782316_jpeg.rf.407a648876013574378ca47fce8015a2.jpg', 'dataset\\\\train\\\\images\\\\imagen8709_NM8710_MG7782316_jpeg.rf.f81c0778a607649aad3a4b305623e265.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0072_jpg.rf.34b2bb62a501ab338685447d3c68bd09.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0072_jpg.rf.95da6158ffcddfabfc06e145a8008c78.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0072_jpg.rf.b76cef7fa7ec48a181bf99691499c678.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0073_jpg.rf.0c068170f9507c09e530fd295e2cea4d.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0073_jpg.rf.3ece7d8276881bbc9bfa62d16c2af881.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0073_jpg.rf.8371b0101c848c9b0c21c685d2c4b19a.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0074_jpg.rf.1f3d876ab0f942527cb5c3fa89b989db.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0074_jpg.rf.3088df95f698bbe2507eecf09c861d6d.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0074_jpg.rf.a107f0225f0435bd6db6696473a62a68.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0075_jpg.rf.4d13313f7f5b63d851ffada218ceaf9c.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0075_jpg.rf.bef08f980a918e4e4bd7a617d9572a0e.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0075_jpg.rf.d557eba8614d0c38f91cce99f212f9c2.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0080_jpg.rf.0233e97acddee76592e352bc37597d45.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0080_jpg.rf.31d57a83873315a0d405b9913e295bcd.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0080_jpg.rf.e0517b356f76fe17f7f33a99091584e3.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0081_jpg.rf.09a2ca6de61f5766ac970622c815ca7a.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0081_jpg.rf.1b296393ed8cc16603aa8a5ccd734e0b.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0081_jpg.rf.92da88db8b7bc0f28d5af086a86f77fd.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0082_jpg.rf.9c69abdfcd2f1babec0b58dabbe152bc.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0082_jpg.rf.a5bd4dabb38066a15a226250c563537a.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0082_jpg.rf.bfd88d74a244d8f7c3771d3d0948b596.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0083_jpg.rf.1a662b2ec9fd179e72d4c9ce770606a0.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0083_jpg.rf.325ff8dda4d4d13911f35d48114fd61d.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0083_jpg.rf.5ad35ccf4359060eee3f3e2831bd6a13.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0084_jpg.rf.2110e367ca827de881608ee363ae8844.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0084_jpg.rf.906fcc04d722cd9fab48ac286ff1428e.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0084_jpg.rf.9ca0fc6ec5c4859db3776ada54fd13e1.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0085_jpg.rf.3010ce7b0607ddef41d8ce4e58404ce8.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0085_jpg.rf.44dde9d6c859f1e358dac7fd46c7e9ba.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0085_jpg.rf.88dcf8c57e8f4bd5e7b56f946a6d0fb4.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0087_jpg.rf.1a65417a75b9f0a594a77bc35e68d137.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0087_jpg.rf.1f8fb433b7fdf35d5f191c1adea12f91.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0087_jpg.rf.801438e2c2a71e0e13c4fcbd80b779da.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0089_jpg.rf.6ce0405ebbf63479da5092c53eae03df.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0089_jpg.rf.a0022d050cd17787a90435667f6653b5.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0089_jpg.rf.fe92b4c209c31e407564c2c4cb1e47c2.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0090_jpg.rf.20d5fbc5f7ebdb5b4983153220aba64e.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0090_jpg.rf.3c25857482ce0688bf9f3145dab18b6a.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0090_jpg.rf.5f90e1629d676fefb6e9083b927d6de9.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0091_jpg.rf.35055fac41928adae110ab3ffd7b57ed.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0091_jpg.rf.60e57b96aa9318d08e715b9d7fe030fd.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0091_jpg.rf.b71b31acad1382b3124a9e6a1d9b09c4.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0092_jpg.rf.1234a42b229d75e6dbc17765941b9fad.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0092_jpg.rf.6f5828d11cdc9dceeb881bfe6b444757.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0092_jpg.rf.af1ce2c09ca232b360454a95b865e7ee.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0093_jpg.rf.86614547b32b0011485e050b67147ac9.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0093_jpg.rf.87b99c400680414547c012e79b033d7a.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0093_jpg.rf.b5866f8c0a1c7303664f8d80887ca4a6.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0095_jpg.rf.7a51ab4d1b3c95b8a075bc27d0548ce8.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0095_jpg.rf.a267cb6d3a17a0c91aa4702f813d4ab3.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0095_jpg.rf.bfc19821e2bd61a2f7bbf36381d24f2f.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0097_jpg.rf.3df87d2a08218a2ebbe7d21de8ec36f3.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0097_jpg.rf.4faf74aed255bc5205aecff82c52be06.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0097_jpg.rf.60aa1a9c76c09776fcb014f56efaf6ce.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0098_jpg.rf.50da97366a7a6fdc55c95bc1a85a80c4.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0098_jpg.rf.c774c29ec8bd4dd0a1558dc1a10626e3.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0098_jpg.rf.d4fe3fcd598e59a0358a58cce6f7fe97.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0099_jpg.rf.10b15f847d76e3bd1992104f85cb24f3.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0099_jpg.rf.94a74bbee7e69e2f50e540de6b2c07e6.jpg', 'dataset\\\\train\\\\images\\\\IMG-20221114-WA0099_jpg.rf.bcefe6e80d6eebc0f942d6984747a6a9.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114082327_jpg.rf.09892426bf5c509388525021427295ba.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114082327_jpg.rf.2249e78a66aea4ae20a24eda0f6fddac.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114082327_jpg.rf.27586eb58b7fe3efb8981a4ee8add907.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114082335_jpg.rf.28c13772bd71293604fb85db771e539d.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114082335_jpg.rf.566905736354bdf78588da2a484bc50a.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114082335_jpg.rf.5a244ed122cbb79176e1e9e00755eebd.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113754_jpg.rf.39695d2ef7c3513a13dbf16f8f0cd21a.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113754_jpg.rf.81432bb0887f0e55178576619bebdc91.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113754_jpg.rf.c87d0803603a9c1214d95e1881b93dc4.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113800_jpg.rf.3320ce783eb112d29f2dc27cb885d32e.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113800_jpg.rf.3dcf64dd71615d60a31c0c69392c7063.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113800_jpg.rf.60de8157fa5febb3e3de4c1400ed0ae6.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113823_jpg.rf.363441cf2af652724ee834d84a261ca4.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113823_jpg.rf.c9c09481c938daec3927d297d9dbb238.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113823_jpg.rf.f5d7a3cdae71671c7ceab413223f6c40.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113830_jpg.rf.a6ceff41f7238ab464a5e4d92e06be9b.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113830_jpg.rf.aa8e55333e20947e80269cdbc9019bae.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113830_jpg.rf.ae27a6e9c9b9f95e877997a7ded71c86.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113836_jpg.rf.17cdbe34fc49ec2a1f134ba421f629a8.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113836_jpg.rf.5e788a48c394be4c5dd5ee5f837c2204.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113836_jpg.rf.d99b3ef31c2bdfcd3b4a56372f7edfdb.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113843_jpg.rf.0135feafda88d3ce99d4def160c5f721.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113843_jpg.rf.86f7db77bc14fc64512b40e21435ad19.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113843_jpg.rf.d1611fc8dd9aab94d9112814367c23ac.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113902_jpg.rf.179c550ee618273d77b318b5535f1c18.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113902_jpg.rf.5f9f16744fb230fdde8492bd7ada43f9.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113902_jpg.rf.924a8e1607e456f36e87ccd1dfa16ef1.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113915_jpg.rf.28f2fddf5f22c11fddd171924b7bc6af.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113915_jpg.rf.2f8db902964710008f6e80b1d3180f83.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113915_jpg.rf.f1e359d45efc12005a28a8b94ed68336.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113931_jpg.rf.0308ae86f3e3aba24b6d96c7f1ab595c.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113931_jpg.rf.59dc39a3a2e594c750e66ae984b054d1.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113931_jpg.rf.ba3e01854029dfa6722abba62f01d026.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113935_jpg.rf.259170ff884f8d91ad2c55e60764b21d.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113935_jpg.rf.56704d5e3312518611dc9d49055ebd32.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114113935_jpg.rf.a49c369564f5a74b5a64c8c76e96f10d.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114114128_jpg.rf.46b3db19cfc1486146168bbfb4b2c2ec.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114114128_jpg.rf.d0eef2bee747e560350cc3111bbecfc7.jpg', 'dataset\\\\train\\\\images\\\\IMG20221114114128_jpg.rf.fc3a1a13374e87d526f168655a73dfeb.jpg', 'dataset\\\\train\\\\images\\\\prueba-peugeot-308-hybrid-phev-2_mid6359518109bdc_jpg.rf.0fa81518363f1aa124f81c119a0ac29c.jpg', 'dataset\\\\train\\\\images\\\\prueba-peugeot-308-hybrid-phev-2_mid6359518109bdc_jpg.rf.b6948cde30a2caacd138e6dbfecfe226.jpg', 'dataset\\\\train\\\\images\\\\prueba-peugeot-308-hybrid-phev-2_mid6359518109bdc_jpg.rf.c36d4cba2f3cad2cb17ee9ebe9617c3c.jpg']\n",
      "dataset\\train\\images\\0802HFP_jpg.rf.30755e346cf1455361344eeeceb55cb1.jpg\n",
      "dataset\\train\\images\\0802HFP_jpg.rf.30cd9ca231b6667068ad26b808dd99da.jpg\n",
      "dataset\\train\\images\\0802HFP_jpg.rf.ba381edbab2dcddf24f9739d99ae26d4.jpg\n",
      "dataset\\train\\images\\1159FPG_jpg.rf.165f7f6df48b376a9863eab1befe71bf.jpg\n",
      "dataset\\train\\images\\1159FPG_jpg.rf.3ff8b432d3fb4ab2537c7f6ec80ce560.jpg\n",
      "dataset\\train\\images\\1159FPG_jpg.rf.8ac0d77c1a7d6f3b8f208fe9ec6f887f.jpg\n",
      "dataset\\train\\images\\1319FSX_jpg.rf.42cac49225e519a2c8e5d1ef1bc1a9df.jpg\n",
      "dataset\\train\\images\\1319FSX_jpg.rf.8aa60298e9d1b1a0ec29e0189c61bf40.jpg\n",
      "dataset\\train\\images\\1319FSX_jpg.rf.f37800d74affae5e5dc10a94693dbfbf.jpg\n",
      "dataset\\train\\images\\15989862207427_jpg.rf.8f731f82cf1639282dc1a5c81fd7d483.jpg\n",
      "dataset\\train\\images\\15989862207427_jpg.rf.8ff0c28508f614a0427c9a7bf48136db.jpg\n",
      "dataset\\train\\images\\15989862207427_jpg.rf.d4400cbe860cbdc49c9f7a7ac785a91c.jpg\n",
      "dataset\\train\\images\\1637067480508_jpg.rf.49922346df4dbbe9f88c7ac5abaead22.jpg\n",
      "dataset\\train\\images\\1637067480508_jpg.rf.81614cec62651fd757f938c9293738b5.jpg\n",
      "dataset\\train\\images\\1637067480508_jpg.rf.e5c02fa0c2eb431dc8343b5ec703364e.jpg\n",
      "dataset\\train\\images\\2711LKN_jpg.rf.9d59545c3a3188695ec37613ae290ee5.jpg\n",
      "dataset\\train\\images\\2711LKN_jpg.rf.a034e77579ff63c99d4a46495303c37b.jpg\n",
      "dataset\\train\\images\\2711LKN_jpg.rf.a958f1f2817824fd4fa83f39806e09b1.jpg\n",
      "dataset\\train\\images\\2942HFB_jpg.rf.8263fa536f5d315f40e3807591092bba.jpg\n",
      "dataset\\train\\images\\2942HFB_jpg.rf.cd3eeddbc3fa7d636c5db16700f285b6.jpg\n",
      "dataset\\train\\images\\2942HFB_jpg.rf.fbf11cef15a1099115a1a06d5e151d04.jpg\n",
      "dataset\\train\\images\\3838KWB_jpg.rf.ace411bd6e092f78b250cdf0c0a71bfa.jpg\n",
      "dataset\\train\\images\\3838KWB_jpg.rf.b01806a282c2631288a4d62a189e2135.jpg\n",
      "dataset\\train\\images\\3838KWB_jpg.rf.e9f960b1ac9e2f957be2a50e29317099.jpg\n",
      "dataset\\train\\images\\4078BVX_jpg.rf.4358dea669efd28b780f048f930d293d.jpg\n",
      "dataset\\train\\images\\4078BVX_jpg.rf.ad45943dcf4ffac6044159efa348f466.jpg\n",
      "dataset\\train\\images\\4078BVX_jpg.rf.d6848a6462560959c8368f9616feeb0f.jpg\n",
      "dataset\\train\\images\\4950KZK_jpg.rf.14c74f9c463e6b15d8a111f95a18936a.jpg\n",
      "dataset\\train\\images\\4950KZK_jpg.rf.5673172dd504e94a89c92fa148cadf0b.jpg\n",
      "dataset\\train\\images\\4950KZK_jpg.rf.f51cf698836c629817570298b4e504dc.jpg\n",
      "dataset\\train\\images\\4_jpg.rf.5fc6f3248156631d9e8f89b9c56f0c42.jpg\n",
      "dataset\\train\\images\\4_jpg.rf.85c872bff5dff7e2d5d7a976d3cdd996.jpg\n",
      "dataset\\train\\images\\4_jpg.rf.861c1294fa47fb2e07ece975981cfafd.jpg\n",
      "dataset\\train\\images\\5921LMH_jpg.rf.0e2838ecb1dca96304e5b7efd4a7d372.jpg\n",
      "dataset\\train\\images\\5921LMH_jpg.rf.bb888f2d8ccfa2e85da9a516e9c4a6e1.jpg\n",
      "dataset\\train\\images\\5921LMH_jpg.rf.e51d2d2ccab8e372e88d4187cf03c71c.jpg\n",
      "dataset\\train\\images\\5_jpg.rf.436d0c6cae5ebe1ed5d3cd07ba8a4207.jpg\n",
      "dataset\\train\\images\\5_jpg.rf.48b4f45d14bd9236cd6f56729a6227bd.jpg\n",
      "dataset\\train\\images\\5_jpg.rf.6fb58f888ec516ad776a197c0a1bf834.jpg\n",
      "dataset\\train\\images\\6299JJL_jpg.rf.4be7aa1ef9a1ff678177f06833155eb6.jpg\n",
      "dataset\\train\\images\\6299JJL_jpg.rf.983005f219cf60ed438ce6b07c81d734.jpg\n",
      "dataset\\train\\images\\6299JJL_jpg.rf.cf894416237da38468835f4b12c00e07.jpg\n",
      "dataset\\train\\images\\7270GVF_jpg.rf.2f9bf27a5966e86bfe14bcf8a16499ca.jpg\n",
      "dataset\\train\\images\\7270GVF_jpg.rf.5d1bcbea314ce2ec8aad08dc98ace54d.jpg\n",
      "dataset\\train\\images\\7270GVF_jpg.rf.efc9c982fbcc073d6b1dee7abe2e3aa4.jpg\n",
      "dataset\\train\\images\\7_jpg.rf.ad23a58c142fc4c2c48abb60aaaaa9d0.jpg\n",
      "dataset\\train\\images\\7_jpg.rf.ce895c85153035661ab005e7a4a5fd64.jpg\n",
      "dataset\\train\\images\\7_jpg.rf.e6fadae9459c52dbe6abc39219555f23.jpg\n",
      "dataset\\train\\images\\8_jpg.rf.c7fc155d7467fbd25c19db3d786dde60.jpg\n",
      "dataset\\train\\images\\8_jpg.rf.da898b55d6724bbc6b312f9f083525a7.jpg\n",
      "dataset\\train\\images\\8_jpg.rf.fb8e579f8b21d0b22263ca547a65d587.jpg\n",
      "dataset\\train\\images\\CNP2309AW_jpg.rf.53d9c136d9bc859208cf802c2ebfe298.jpg\n",
      "dataset\\train\\images\\CNP2309AW_jpg.rf.9bec9d57c9a31f1e658271854930ff39.jpg\n",
      "dataset\\train\\images\\CNP2309AW_jpg.rf.c5ad418aecb109cc482240301c11ee1f.jpg\n",
      "dataset\\train\\images\\Coches-mas-vendidos-Espana-2018_jpg.rf.24d660a205abf48d0b7e4e9f4a60cfff.jpg\n",
      "dataset\\train\\images\\Coches-mas-vendidos-Espana-2018_jpg.rf.6c00c102018789f58d2b39a6ffb04c27.jpg\n",
      "dataset\\train\\images\\Coches-mas-vendidos-Espana-2018_jpg.rf.d48fdee824b50d0ae4e0cc0a8806f088.jpg\n",
      "dataset\\train\\images\\como-saber-que-ano-es-tu-coche-matricula_jpg.rf.2ba5ea0c6c9a67ee65e76c3ab6ed6715.jpg\n",
      "dataset\\train\\images\\como-saber-que-ano-es-tu-coche-matricula_jpg.rf.c1d8ca3020ddbe6d2aaceedb3b2d06e1.jpg\n",
      "dataset\\train\\images\\como-saber-que-ano-es-tu-coche-matricula_jpg.rf.fadd2cf0742a6930335a8d1f5beed428.jpg\n",
      "dataset\\train\\images\\GC4370BV_jpg.rf.087798a45f907d690e0f5dc40480c4e6.jpg\n",
      "dataset\\train\\images\\GC4370BV_jpg.rf.184189be68c7a463054c2b401507681a.jpg\n",
      "dataset\\train\\images\\GC4370BV_jpg.rf.3a6ed1475edc4eaa2cbe882732c5b661.jpg\n",
      "dataset\\train\\images\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-21_jpg.rf.431f7c473fc93b38322437342e36c981.jpg\n",
      "dataset\\train\\images\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-21_jpg.rf.7e1ccd659e5eb877f1440c90ce3f959b.jpg\n",
      "dataset\\train\\images\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-21_jpg.rf.a1d838443b180e60bac901e5b102c431.jpg\n",
      "dataset\\train\\images\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-23_jpg.rf.044cc425696fe0300f9dad44d15bb60b.jpg\n",
      "dataset\\train\\images\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-23_jpg.rf.68edadc0fa4dee14c8b327d5afe0b04a.jpg\n",
      "dataset\\train\\images\\Imagen-de-WhatsApp-2022-11-14-a-las-09-52-23_jpg.rf.e45b2dd2933a08a8be70c4a54dbe44e4.jpg\n",
      "dataset\\train\\images\\imagen8709_NM8710_MG7782316_jpeg.rf.277c597582ce042f109644bf66809412.jpg\n",
      "dataset\\train\\images\\imagen8709_NM8710_MG7782316_jpeg.rf.407a648876013574378ca47fce8015a2.jpg\n",
      "dataset\\train\\images\\imagen8709_NM8710_MG7782316_jpeg.rf.f81c0778a607649aad3a4b305623e265.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0072_jpg.rf.34b2bb62a501ab338685447d3c68bd09.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0072_jpg.rf.95da6158ffcddfabfc06e145a8008c78.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0072_jpg.rf.b76cef7fa7ec48a181bf99691499c678.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0073_jpg.rf.0c068170f9507c09e530fd295e2cea4d.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0073_jpg.rf.3ece7d8276881bbc9bfa62d16c2af881.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0073_jpg.rf.8371b0101c848c9b0c21c685d2c4b19a.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0074_jpg.rf.1f3d876ab0f942527cb5c3fa89b989db.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0074_jpg.rf.3088df95f698bbe2507eecf09c861d6d.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0074_jpg.rf.a107f0225f0435bd6db6696473a62a68.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0075_jpg.rf.4d13313f7f5b63d851ffada218ceaf9c.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0075_jpg.rf.bef08f980a918e4e4bd7a617d9572a0e.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0075_jpg.rf.d557eba8614d0c38f91cce99f212f9c2.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0080_jpg.rf.0233e97acddee76592e352bc37597d45.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0080_jpg.rf.31d57a83873315a0d405b9913e295bcd.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0080_jpg.rf.e0517b356f76fe17f7f33a99091584e3.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0081_jpg.rf.09a2ca6de61f5766ac970622c815ca7a.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0081_jpg.rf.1b296393ed8cc16603aa8a5ccd734e0b.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0081_jpg.rf.92da88db8b7bc0f28d5af086a86f77fd.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0082_jpg.rf.9c69abdfcd2f1babec0b58dabbe152bc.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0082_jpg.rf.a5bd4dabb38066a15a226250c563537a.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0082_jpg.rf.bfd88d74a244d8f7c3771d3d0948b596.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0083_jpg.rf.1a662b2ec9fd179e72d4c9ce770606a0.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0083_jpg.rf.325ff8dda4d4d13911f35d48114fd61d.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0083_jpg.rf.5ad35ccf4359060eee3f3e2831bd6a13.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0084_jpg.rf.2110e367ca827de881608ee363ae8844.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0084_jpg.rf.906fcc04d722cd9fab48ac286ff1428e.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0084_jpg.rf.9ca0fc6ec5c4859db3776ada54fd13e1.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0085_jpg.rf.3010ce7b0607ddef41d8ce4e58404ce8.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0085_jpg.rf.44dde9d6c859f1e358dac7fd46c7e9ba.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0085_jpg.rf.88dcf8c57e8f4bd5e7b56f946a6d0fb4.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0087_jpg.rf.1a65417a75b9f0a594a77bc35e68d137.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0087_jpg.rf.1f8fb433b7fdf35d5f191c1adea12f91.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0087_jpg.rf.801438e2c2a71e0e13c4fcbd80b779da.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0089_jpg.rf.6ce0405ebbf63479da5092c53eae03df.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0089_jpg.rf.a0022d050cd17787a90435667f6653b5.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0089_jpg.rf.fe92b4c209c31e407564c2c4cb1e47c2.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0090_jpg.rf.20d5fbc5f7ebdb5b4983153220aba64e.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0090_jpg.rf.3c25857482ce0688bf9f3145dab18b6a.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0090_jpg.rf.5f90e1629d676fefb6e9083b927d6de9.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0091_jpg.rf.35055fac41928adae110ab3ffd7b57ed.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0091_jpg.rf.60e57b96aa9318d08e715b9d7fe030fd.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0091_jpg.rf.b71b31acad1382b3124a9e6a1d9b09c4.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0092_jpg.rf.1234a42b229d75e6dbc17765941b9fad.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0092_jpg.rf.6f5828d11cdc9dceeb881bfe6b444757.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0092_jpg.rf.af1ce2c09ca232b360454a95b865e7ee.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0093_jpg.rf.86614547b32b0011485e050b67147ac9.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0093_jpg.rf.87b99c400680414547c012e79b033d7a.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0093_jpg.rf.b5866f8c0a1c7303664f8d80887ca4a6.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0095_jpg.rf.7a51ab4d1b3c95b8a075bc27d0548ce8.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0095_jpg.rf.a267cb6d3a17a0c91aa4702f813d4ab3.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0095_jpg.rf.bfc19821e2bd61a2f7bbf36381d24f2f.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0097_jpg.rf.3df87d2a08218a2ebbe7d21de8ec36f3.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0097_jpg.rf.4faf74aed255bc5205aecff82c52be06.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0097_jpg.rf.60aa1a9c76c09776fcb014f56efaf6ce.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0098_jpg.rf.50da97366a7a6fdc55c95bc1a85a80c4.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0098_jpg.rf.c774c29ec8bd4dd0a1558dc1a10626e3.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0098_jpg.rf.d4fe3fcd598e59a0358a58cce6f7fe97.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0099_jpg.rf.10b15f847d76e3bd1992104f85cb24f3.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0099_jpg.rf.94a74bbee7e69e2f50e540de6b2c07e6.jpg\n",
      "dataset\\train\\images\\IMG-20221114-WA0099_jpg.rf.bcefe6e80d6eebc0f942d6984747a6a9.jpg\n",
      "dataset\\train\\images\\IMG20221114082327_jpg.rf.09892426bf5c509388525021427295ba.jpg\n",
      "dataset\\train\\images\\IMG20221114082327_jpg.rf.2249e78a66aea4ae20a24eda0f6fddac.jpg\n",
      "dataset\\train\\images\\IMG20221114082327_jpg.rf.27586eb58b7fe3efb8981a4ee8add907.jpg\n",
      "dataset\\train\\images\\IMG20221114082335_jpg.rf.28c13772bd71293604fb85db771e539d.jpg\n",
      "dataset\\train\\images\\IMG20221114082335_jpg.rf.566905736354bdf78588da2a484bc50a.jpg\n",
      "dataset\\train\\images\\IMG20221114082335_jpg.rf.5a244ed122cbb79176e1e9e00755eebd.jpg\n",
      "dataset\\train\\images\\IMG20221114113754_jpg.rf.39695d2ef7c3513a13dbf16f8f0cd21a.jpg\n",
      "dataset\\train\\images\\IMG20221114113754_jpg.rf.81432bb0887f0e55178576619bebdc91.jpg\n",
      "dataset\\train\\images\\IMG20221114113754_jpg.rf.c87d0803603a9c1214d95e1881b93dc4.jpg\n",
      "dataset\\train\\images\\IMG20221114113800_jpg.rf.3320ce783eb112d29f2dc27cb885d32e.jpg\n",
      "dataset\\train\\images\\IMG20221114113800_jpg.rf.3dcf64dd71615d60a31c0c69392c7063.jpg\n",
      "dataset\\train\\images\\IMG20221114113800_jpg.rf.60de8157fa5febb3e3de4c1400ed0ae6.jpg\n",
      "dataset\\train\\images\\IMG20221114113823_jpg.rf.363441cf2af652724ee834d84a261ca4.jpg\n",
      "dataset\\train\\images\\IMG20221114113823_jpg.rf.c9c09481c938daec3927d297d9dbb238.jpg\n",
      "dataset\\train\\images\\IMG20221114113823_jpg.rf.f5d7a3cdae71671c7ceab413223f6c40.jpg\n",
      "dataset\\train\\images\\IMG20221114113830_jpg.rf.a6ceff41f7238ab464a5e4d92e06be9b.jpg\n",
      "dataset\\train\\images\\IMG20221114113830_jpg.rf.aa8e55333e20947e80269cdbc9019bae.jpg\n",
      "dataset\\train\\images\\IMG20221114113830_jpg.rf.ae27a6e9c9b9f95e877997a7ded71c86.jpg\n",
      "dataset\\train\\images\\IMG20221114113836_jpg.rf.17cdbe34fc49ec2a1f134ba421f629a8.jpg\n",
      "dataset\\train\\images\\IMG20221114113836_jpg.rf.5e788a48c394be4c5dd5ee5f837c2204.jpg\n",
      "dataset\\train\\images\\IMG20221114113836_jpg.rf.d99b3ef31c2bdfcd3b4a56372f7edfdb.jpg\n",
      "dataset\\train\\images\\IMG20221114113843_jpg.rf.0135feafda88d3ce99d4def160c5f721.jpg\n",
      "dataset\\train\\images\\IMG20221114113843_jpg.rf.86f7db77bc14fc64512b40e21435ad19.jpg\n",
      "dataset\\train\\images\\IMG20221114113843_jpg.rf.d1611fc8dd9aab94d9112814367c23ac.jpg\n",
      "dataset\\train\\images\\IMG20221114113902_jpg.rf.179c550ee618273d77b318b5535f1c18.jpg\n",
      "dataset\\train\\images\\IMG20221114113902_jpg.rf.5f9f16744fb230fdde8492bd7ada43f9.jpg\n",
      "dataset\\train\\images\\IMG20221114113902_jpg.rf.924a8e1607e456f36e87ccd1dfa16ef1.jpg\n",
      "dataset\\train\\images\\IMG20221114113915_jpg.rf.28f2fddf5f22c11fddd171924b7bc6af.jpg\n",
      "dataset\\train\\images\\IMG20221114113915_jpg.rf.2f8db902964710008f6e80b1d3180f83.jpg\n",
      "dataset\\train\\images\\IMG20221114113915_jpg.rf.f1e359d45efc12005a28a8b94ed68336.jpg\n",
      "dataset\\train\\images\\IMG20221114113931_jpg.rf.0308ae86f3e3aba24b6d96c7f1ab595c.jpg\n",
      "dataset\\train\\images\\IMG20221114113931_jpg.rf.59dc39a3a2e594c750e66ae984b054d1.jpg\n",
      "dataset\\train\\images\\IMG20221114113931_jpg.rf.ba3e01854029dfa6722abba62f01d026.jpg\n",
      "dataset\\train\\images\\IMG20221114113935_jpg.rf.259170ff884f8d91ad2c55e60764b21d.jpg\n",
      "dataset\\train\\images\\IMG20221114113935_jpg.rf.56704d5e3312518611dc9d49055ebd32.jpg\n",
      "dataset\\train\\images\\IMG20221114113935_jpg.rf.a49c369564f5a74b5a64c8c76e96f10d.jpg\n",
      "dataset\\train\\images\\IMG20221114114128_jpg.rf.46b3db19cfc1486146168bbfb4b2c2ec.jpg\n",
      "dataset\\train\\images\\IMG20221114114128_jpg.rf.d0eef2bee747e560350cc3111bbecfc7.jpg\n",
      "dataset\\train\\images\\IMG20221114114128_jpg.rf.fc3a1a13374e87d526f168655a73dfeb.jpg\n",
      "dataset\\train\\images\\prueba-peugeot-308-hybrid-phev-2_mid6359518109bdc_jpg.rf.0fa81518363f1aa124f81c119a0ac29c.jpg\n",
      "dataset\\train\\images\\prueba-peugeot-308-hybrid-phev-2_mid6359518109bdc_jpg.rf.b6948cde30a2caacd138e6dbfecfe226.jpg\n",
      "dataset\\train\\images\\prueba-peugeot-308-hybrid-phev-2_mid6359518109bdc_jpg.rf.c36d4cba2f3cad2cb17ee9ebe9617c3c.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Directorio base donde se encuentra la carpeta \"dataset\"\n",
    "base_dir = ''\n",
    "\n",
    "# Ruta completa de la carpeta \"train\" dentro de la estructura\n",
    "train_dir = os.path.join(base_dir, 'dataset', 'train', 'images')\n",
    "\n",
    "# Crear una lista para almacenar los nombres de los archivos que cumplan el patrón\n",
    "file_list = []\n",
    "\n",
    "# Iterar a través de los archivos en la carpeta \"train\"\n",
    "for root, dirs, files in os.walk(train_dir):\n",
    "    for filename in files:\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):\n",
    "            # Comprobar si el archivo es una imagen (puedes agregar más extensiones si es necesario)\n",
    "            file_list.append(os.path.join(root, filename))\n",
    "print(file_list)\n",
    "# Imprimir la lista de archivos que cumplen el patrón\n",
    "for file_path in file_list:\n",
    "    print(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba con dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 train, 162.6ms\n",
      "Speed: 8.1ms preprocess, 162.6ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.3\n",
      "Class name --> train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 oven, 155.1ms\n",
      "Speed: 8.8ms preprocess, 155.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.46\n",
      "Class name --> oven\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 1 oven, 169.9ms\n",
      "Speed: 9.6ms preprocess, 169.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.38\n",
      "Class name --> oven\n",
      "Confidence ---> 0.29\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 truck, 207.6ms\n",
      "Speed: 11.1ms preprocess, 207.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.64\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 truck, 179.9ms\n",
      "Speed: 2.6ms preprocess, 179.9ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.71\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 truck, 200.2ms\n",
      "Speed: 0.0ms preprocess, 200.2ms inference, 8.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.74\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 1 bus, 214.4ms\n",
      "Speed: 8.7ms preprocess, 214.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.34\n",
      "Class name --> bus\n",
      "Confidence ---> 0.32\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 bus, 1 truck, 289.4ms\n",
      "Speed: 10.0ms preprocess, 289.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.37\n",
      "Class name --> truck\n",
      "Confidence ---> 0.31\n",
      "Class name --> bus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 bus, 1 truck, 208.1ms\n",
      "Speed: 8.0ms preprocess, 208.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.54\n",
      "Class name --> bus\n",
      "Confidence ---> 0.43\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 truck, 180.1ms\n",
      "Speed: 7.8ms preprocess, 180.1ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.83\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 truck, 170.0ms\n",
      "Speed: 0.0ms preprocess, 170.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.74\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 truck, 169.2ms\n",
      "Speed: 10.4ms preprocess, 169.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.79\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 188.0ms\n",
      "Speed: 10.1ms preprocess, 188.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 remote, 195.7ms\n",
      "Speed: 9.7ms preprocess, 195.7ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.7\n",
      "Class name --> remote\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 189.8ms\n",
      "Speed: 0.0ms preprocess, 189.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.4\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 cars, 1 truck, 194.3ms\n",
      "Speed: 5.4ms preprocess, 194.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.76\n",
      "Class name --> car\n",
      "Confidence ---> 0.63\n",
      "Class name --> car\n",
      "Confidence ---> 0.38\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 cars, 1 truck, 239.8ms\n",
      "Speed: 0.0ms preprocess, 239.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.7\n",
      "Class name --> car\n",
      "Confidence ---> 0.65\n",
      "Class name --> car\n",
      "Confidence ---> 0.52\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 cars, 1 truck, 199.7ms\n",
      "Speed: 12.0ms preprocess, 199.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.8\n",
      "Class name --> car\n",
      "Confidence ---> 0.67\n",
      "Class name --> car\n",
      "Confidence ---> 0.39\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 190.4ms\n",
      "Speed: 9.6ms preprocess, 190.4ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.73\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 1 truck, 162.9ms\n",
      "Speed: 9.4ms preprocess, 162.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.58\n",
      "Class name --> truck\n",
      "Confidence ---> 0.47\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 1 truck, 124.2ms\n",
      "Speed: 0.0ms preprocess, 124.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.44\n",
      "Class name --> truck\n",
      "Confidence ---> 0.31\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 1 bus, 190.9ms\n",
      "Speed: 1.3ms preprocess, 190.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 118.4ms\n",
      "Speed: 0.0ms preprocess, 118.4ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.57\n",
      "Class name --> bus\n",
      "Confidence ---> 0.38\n",
      "Class name --> car\n",
      "Confidence ---> 0.37\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 cars, 1 truck, 124.1ms\n",
      "Speed: 5.6ms preprocess, 124.1ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 1 motorcycle, 1 parking meter, 128.3ms\n",
      "Speed: 8.7ms preprocess, 128.3ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.48\n",
      "Class name --> car\n",
      "Confidence ---> 0.47\n",
      "Class name --> car\n",
      "Confidence ---> 0.33\n",
      "Class name --> truck\n",
      "Confidence ---> 0.55\n",
      "Class name --> car\n",
      "Confidence ---> 0.35\n",
      "Class name --> motorbike\n",
      "Confidence ---> 0.32\n",
      "Class name --> parking meter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 1 backpack, 122.2ms\n",
      "Speed: 8.3ms preprocess, 122.2ms inference, 7.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 cars, 1 motorcycle, 130.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.59\n",
      "Class name --> car\n",
      "Confidence ---> 0.28\n",
      "Class name --> backpack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.5ms preprocess, 130.2ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.54\n",
      "Class name --> car\n",
      "Confidence ---> 0.27\n",
      "Class name --> motorbike\n",
      "Confidence ---> 0.26\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 bus, 246.0ms\n",
      "Speed: 3.7ms preprocess, 246.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 bus, 115.7ms\n",
      "Speed: 4.2ms preprocess, 115.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.87\n",
      "Class name --> bus\n",
      "Confidence ---> 0.87\n",
      "Class name --> bus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 bus, 176.6ms\n",
      "Speed: 4.6ms preprocess, 176.6ms inference, 8.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.85\n",
      "Class name --> bus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 3 cars, 149.2ms\n",
      "Speed: 8.2ms preprocess, 149.2ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.9\n",
      "Class name --> car\n",
      "Confidence ---> 0.77\n",
      "Class name --> car\n",
      "Confidence ---> 0.69\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 cars, 195.5ms\n",
      "Speed: 4.5ms preprocess, 195.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.9\n",
      "Class name --> car\n",
      "Confidence ---> 0.87\n",
      "Class name --> car\n",
      "Confidence ---> 0.48\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 cars, 188.3ms\n",
      "Speed: 0.0ms preprocess, 188.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.91\n",
      "Class name --> car\n",
      "Confidence ---> 0.86\n",
      "Class name --> car\n",
      "Confidence ---> 0.39\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 cars, 1 truck, 199.8ms\n",
      "Speed: 9.5ms preprocess, 199.8ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.86\n",
      "Class name --> car\n",
      "Confidence ---> 0.7\n",
      "Class name --> car\n",
      "Confidence ---> 0.57\n",
      "Class name --> car\n",
      "Confidence ---> 0.45\n",
      "Class name --> truck\n",
      "Confidence ---> 0.3\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 cars, 1 truck, 208.6ms\n",
      "Speed: 2.0ms preprocess, 208.6ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.71\n",
      "Class name --> car\n",
      "Confidence ---> 0.67\n",
      "Class name --> car\n",
      "Confidence ---> 0.41\n",
      "Class name --> car\n",
      "Confidence ---> 0.39\n",
      "Class name --> car\n",
      "Confidence ---> 0.29\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 cars, 1 truck, 191.0ms\n",
      "Speed: 8.6ms preprocess, 191.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.79\n",
      "Class name --> car\n",
      "Confidence ---> 0.76\n",
      "Class name --> car\n",
      "Confidence ---> 0.64\n",
      "Class name --> car\n",
      "Confidence ---> 0.35\n",
      "Class name --> car\n",
      "Confidence ---> 0.29\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 cars, 1 bus, 192.0ms\n",
      "Speed: 9.6ms preprocess, 192.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.9\n",
      "Class name --> car\n",
      "Confidence ---> 0.79\n",
      "Class name --> car\n",
      "Confidence ---> 0.34\n",
      "Class name --> bus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 cars, 1 bus, 190.1ms\n",
      "Speed: 10.5ms preprocess, 190.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.94\n",
      "Class name --> car\n",
      "Confidence ---> 0.63\n",
      "Class name --> car\n",
      "Confidence ---> 0.44\n",
      "Class name --> bus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 cars, 204.2ms\n",
      "Speed: 4.1ms preprocess, 204.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.92\n",
      "Class name --> car\n",
      "Confidence ---> 0.79\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 cars, 1 bus, 191.7ms\n",
      "Speed: 8.0ms preprocess, 191.7ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.87\n",
      "Class name --> car\n",
      "Confidence ---> 0.81\n",
      "Class name --> car\n",
      "Confidence ---> 0.77\n",
      "Class name --> car\n",
      "Confidence ---> 0.58\n",
      "Class name --> car\n",
      "Confidence ---> 0.46\n",
      "Class name --> bus\n",
      "Confidence ---> 0.29\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 cars, 1 truck, 160.5ms\n",
      "Speed: 9.5ms preprocess, 160.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.86\n",
      "Class name --> car\n",
      "Confidence ---> 0.85\n",
      "Class name --> car\n",
      "Confidence ---> 0.77\n",
      "Class name --> car\n",
      "Confidence ---> 0.57\n",
      "Class name --> car\n",
      "Confidence ---> 0.42\n",
      "Class name --> truck\n",
      "Confidence ---> 0.35\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 cars, 1 truck, 195.0ms\n",
      "Speed: 5.2ms preprocess, 195.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.84\n",
      "Class name --> car\n",
      "Confidence ---> 0.81\n",
      "Class name --> car\n",
      "Confidence ---> 0.79\n",
      "Class name --> car\n",
      "Confidence ---> 0.6\n",
      "Class name --> car\n",
      "Confidence ---> 0.49\n",
      "Class name --> car\n",
      "Confidence ---> 0.41\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 car, 172.3ms\n",
      "Speed: 7.4ms preprocess, 172.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.54\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 cars, 128.2ms\n",
      "Speed: 5.0ms preprocess, 128.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.52\n",
      "Class name --> car\n",
      "Confidence ---> 0.36\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 cars, 190.4ms\n",
      "Speed: 14.6ms preprocess, 190.4ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.46\n",
      "Class name --> car\n",
      "Confidence ---> 0.36\n",
      "Class name --> car\n",
      "Confidence ---> 0.29\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 142.8ms\n",
      "Speed: 3.8ms preprocess, 142.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.6\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 156.3ms\n",
      "Speed: 11.8ms preprocess, 156.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.68\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 1 truck, 175.0ms\n",
      "Speed: 5.0ms preprocess, 175.0ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.64\n",
      "Class name --> car\n",
      "Confidence ---> 0.64\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 persons, 4 cars, 159.8ms\n",
      "Speed: 5.0ms preprocess, 159.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.92\n",
      "Class name --> car\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> car\n",
      "Confidence ---> 0.72\n",
      "Class name --> car\n",
      "Confidence ---> 0.66\n",
      "Class name --> car\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 persons, 4 cars, 147.0ms\n",
      "Speed: 4.6ms preprocess, 147.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.9\n",
      "Class name --> car\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.82\n",
      "Class name --> car\n",
      "Confidence ---> 0.77\n",
      "Class name --> car\n",
      "Confidence ---> 0.7\n",
      "Class name --> car\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 persons, 4 cars, 199.9ms\n",
      "Speed: 5.1ms preprocess, 199.9ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 persons, 2 cars, 160.3ms\n",
      "Speed: 5.0ms preprocess, 160.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.95\n",
      "Class name --> car\n",
      "Confidence ---> 0.9\n",
      "Class name --> car\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.81\n",
      "Class name --> car\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> car\n",
      "Confidence ---> 0.83\n",
      "Class name --> car\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> car\n",
      "Confidence ---> 0.33\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 persons, 2 cars, 152.1ms\n",
      "Speed: 6.6ms preprocess, 152.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.86\n",
      "Class name --> car\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 7 persons, 4 cars, 182.9ms\n",
      "Speed: 8.9ms preprocess, 182.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.8\n",
      "Class name --> car\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> car\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> car\n",
      "Confidence ---> 0.35\n",
      "Class name --> car\n",
      "Confidence ---> 0.33\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 car, 1 truck, 493.7ms\n",
      "Speed: 5.5ms preprocess, 493.7ms inference, 6.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.41\n",
      "Class name --> car\n",
      "Confidence ---> 0.38\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 truck, 496.9ms\n",
      "Speed: 7.2ms preprocess, 496.9ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.52\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 bus, 1 truck, 258.2ms\n",
      "Speed: 17.6ms preprocess, 258.2ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.41\n",
      "Class name --> truck\n",
      "Confidence ---> 0.4\n",
      "Class name --> bus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 1 truck, 448.8ms\n",
      "Speed: 9.8ms preprocess, 448.8ms inference, 7.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.37\n",
      "Class name --> car\n",
      "Confidence ---> 0.3\n",
      "Class name --> truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 265.6ms\n",
      "Speed: 4.9ms preprocess, 265.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.39\n",
      "Class name --> car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 train, 206.7ms\n",
      "Speed: 6.7ms preprocess, 206.7ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence ---> 0.35\n",
      "Class name --> train\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "from ultralytics import YOLO  # Asegúrate de importar el módulo YOLO correcto\n",
    "\n",
    "import os\n",
    "\n",
    "# Directorio base donde se encuentra la carpeta \"dataset\"\n",
    "base_dir = ''\n",
    "\n",
    "# Ruta completa de la carpeta \"train\" dentro de la estructura\n",
    "train_dir = os.path.join(base_dir, 'dataset', 'train', 'images')\n",
    "\n",
    "# Crear una lista para almacenar los nombres de los archivos de imágenes\n",
    "image_files = []\n",
    "\n",
    "# Iterar a través de los archivos en la carpeta \"train\"\n",
    "for root, dirs, files in os.walk(train_dir):\n",
    "    for filename in files:\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):\n",
    "            # Comprobar si el archivo es una imagen (puedes agregar más extensiones si es necesario)\n",
    "            image_files.append(os.path.join(root, filename))\n",
    "\n",
    "# Carga del modelo YOLO\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "# Iterar a través de la lista de archivos de imágenes\n",
    "for image_path in image_files:\n",
    "    # Carga la imagen que deseas procesar\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Realiza inferencia en la imagen\n",
    "    results = model(img)\n",
    "\n",
    "    # Para cada detección\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            # Contenedor\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)  # Convierte a valores enteros\n",
    "\n",
    "            # Confianza\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "            print(\"Confidence --->\", confidence)\n",
    "\n",
    "            # Clase\n",
    "            cls = int(box.cls[0])\n",
    "            print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "            # Convierte el identificador numérico de la clase en un color RGB\n",
    "            escala = int((cls / len(classNames)) * 255 * 3)\n",
    "            if escala >= 255 * 2:\n",
    "                R = 255\n",
    "                G = 255\n",
    "                B = escala - 255 * 2\n",
    "            else:\n",
    "                if escala >= 255:\n",
    "                    R = 255\n",
    "                    G = escala - 255\n",
    "                    B = 0\n",
    "                else:\n",
    "                    R = escala\n",
    "                    G = 0\n",
    "                    B = 0\n",
    "\n",
    "            # Dibuja el contenedor y la clase\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "            cv2.putText(img, classNames[cls], (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "            # Obtén la ROI\n",
    "            roi = img[y1:y2, x1:x2]\n",
    "\n",
    "            # Convierte ROI a escala de grises\n",
    "            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Aplica umbral para encontrar contornos\n",
    "            _, thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            # Encuentra contornos en la ROI\n",
    "            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Umbral de área para considerar como contorno grande (ajusta este valor según tus necesidades)\n",
    "            area_threshold = 1000\n",
    "\n",
    "            # Filtra los contornos que tienen forma rectangular aproximada y un área grande\n",
    "            filtered_contours = [contour for contour in contours if is_approximately_rectangular(contour) and cv2.contourArea(contour) > area_threshold]\n",
    "\n",
    "            # Dibuja los contornos filtrados en la ROI\n",
    "            cv2.drawContours(roi, filtered_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Muestra la imagen con las detecciones y los contornos filtrados\n",
    "    cv2.imshow('Image', img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "# Cierra todas las ventanas de visualización\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Ultralytics YOLOv8.0.205  Python-3.11.5 torch-2.1.0+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=config.yaml, epochs=100, patience=15, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train6\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train6', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Eric\\Desktop\\vc-5\\P5\\dataset\\train\\labels... 174 images, 0 backgrounds, 0 corrupt: 100%|██████████| 174/174 [00:00<00:00, 1187.49it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Eric\\Desktop\\vc-5\\P5\\dataset\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Eric\\Desktop\\vc-5\\P5\\dataset\\valid\\labels... 16 images, 0 backgrounds, 0 corrupt: 100%|██████████| 16/16 [00:00<00:00, 1228.56it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Eric\\Desktop\\vc-5\\P5\\dataset\\valid\\labels.cache\n",
      "Plotting labels to runs\\detect\\train6\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train6\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100         0G      4.039      6.315      4.522         19        640: 100%|██████████| 11/11 [02:02<00:00, 11.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100         0G      3.924      5.467      4.298         26        640: 100%|██████████| 11/11 [01:29<00:00,  8.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100         0G      3.816      5.032      4.141         20        640: 100%|██████████| 11/11 [01:28<00:00,  8.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.77s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/100         0G      3.518       4.59      3.966         23        640: 100%|██████████| 11/11 [01:28<00:00,  8.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.75s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/100         0G      3.605       4.24      3.723         27        640: 100%|██████████| 11/11 [01:28<00:00,  8.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.62s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/100         0G      3.342      3.803      3.579         24        640: 100%|██████████| 11/11 [01:28<00:00,  8.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/100         0G      3.229      3.689      3.374         25        640: 100%|██████████| 11/11 [01:31<00:00,  8.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.96s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/100         0G      3.045      3.247      3.207         16        640: 100%|██████████| 11/11 [01:29<00:00,  8.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/100         0G      2.825      3.067      3.115         25        640: 100%|██████████| 11/11 [01:29<00:00,  8.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n",
      "                   all         16         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/100         0G      2.747      3.008       3.03         29        640: 100%|██████████| 11/11 [01:28<00:00,  8.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19    0.00158      0.158     0.0559     0.0169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/100         0G      2.909      3.029      3.086         23        640: 100%|██████████| 11/11 [01:17<00:00,  7.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19      0.194      0.105     0.0716     0.0111\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/100         0G      2.721      2.859      2.859         23        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "                   all         16         19      0.319      0.368      0.225     0.0648\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/100         0G       2.61      2.669      2.875         15        640: 100%|██████████| 11/11 [01:20<00:00,  7.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "                   all         16         19      0.343      0.211      0.105     0.0192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/100         0G      2.657      2.552      2.734         17        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19        0.2      0.158      0.111     0.0362\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/100         0G      2.445      2.374      2.623         18        640: 100%|██████████| 11/11 [01:20<00:00,  7.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "                   all         16         19    0.00592      0.632      0.011    0.00392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/100         0G      2.484      2.259      2.595         20        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "                   all         16         19     0.0691     0.0526     0.0334     0.0138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/100         0G      2.363      2.085      2.623         30        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.26s/it]\n",
      "                   all         16         19       0.46      0.137      0.268      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/100         0G      2.324      2.141      2.496         25        640: 100%|██████████| 11/11 [01:20<00:00,  7.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.55s/it]\n",
      "                   all         16         19      0.334      0.421      0.261     0.0969\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/100         0G      2.186       1.97      2.365         29        640: 100%|██████████| 11/11 [01:23<00:00,  7.59s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\n",
      "                   all         16         19      0.296      0.368      0.274     0.0928\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/100         0G      2.066       1.94      2.377         24        640: 100%|██████████| 11/11 [01:20<00:00,  7.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "                   all         16         19      0.485      0.421      0.393      0.143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/100         0G      2.119      1.923      2.351         26        640: 100%|██████████| 11/11 [01:21<00:00,  7.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "                   all         16         19      0.278      0.526      0.301      0.111\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/100         0G      2.061      1.839      2.349         18        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "                   all         16         19      0.322      0.474        0.4      0.189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/100         0G      2.163      1.847      2.413         26        640: 100%|██████████| 11/11 [01:20<00:00,  7.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19       0.45      0.526      0.408      0.206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/100         0G      2.117      1.741      2.325         18        640: 100%|██████████| 11/11 [01:20<00:00,  7.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "                   all         16         19      0.348      0.526      0.349     0.0933\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/100         0G      2.139       1.83      2.294         20        640: 100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "                   all         16         19      0.101      0.368     0.0798     0.0325\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/100         0G       1.96      1.756      2.314         16        640: 100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "                   all         16         19      0.405      0.632      0.443      0.177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/100         0G       1.97        1.7       2.27         30        640: 100%|██████████| 11/11 [01:20<00:00,  7.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "                   all         16         19      0.244      0.474      0.225      0.107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/100         0G      1.877      1.553      2.185         28        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "                   all         16         19      0.164      0.474      0.126     0.0313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/100         0G      1.958       1.65      2.291         16        640: 100%|██████████| 11/11 [01:20<00:00,  7.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n",
      "                   all         16         19      0.419      0.579      0.512      0.236\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/100         0G      1.776      1.496      2.107         29        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19      0.445      0.632      0.548      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/100         0G      1.808      1.455      2.068         22        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "                   all         16         19      0.556      0.684      0.546      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/100         0G       1.91      1.419      2.101         25        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19      0.335      0.579      0.433      0.153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/100         0G      1.889      1.542      2.153         27        640: 100%|██████████| 11/11 [01:19<00:00,  7.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.26s/it]\n",
      "                   all         16         19      0.633      0.526      0.546       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/100         0G      1.762      1.431      2.073         25        640: 100%|██████████| 11/11 [01:20<00:00,  7.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\n",
      "                   all         16         19       0.55      0.789      0.711      0.328\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/100         0G      1.738      1.383      2.021         32        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.30s/it]\n",
      "                   all         16         19      0.637      0.632      0.639      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/100         0G      1.697      1.432      2.045         12        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "                   all         16         19      0.662      0.474       0.58      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/100         0G      1.705      1.394      1.987         31        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.33s/it]\n",
      "                   all         16         19      0.508      0.684      0.655      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/100         0G      1.797      1.409      2.058         20        640: 100%|██████████| 11/11 [01:19<00:00,  7.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.33s/it]\n",
      "                   all         16         19      0.761      0.737      0.776      0.378\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/100         0G       1.71      1.256      1.937         25        640: 100%|██████████| 11/11 [01:20<00:00,  7.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "                   all         16         19      0.607      0.652      0.741      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/100         0G      1.648      1.301      1.916         20        640: 100%|██████████| 11/11 [01:23<00:00,  7.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\n",
      "                   all         16         19      0.636      0.737      0.744       0.35\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/100         0G      1.588      1.276      1.908         17        640: 100%|██████████| 11/11 [01:22<00:00,  7.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.49s/it]\n",
      "                   all         16         19      0.605      0.632       0.64      0.301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/100         0G      1.607      1.215      1.924         28        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "                   all         16         19      0.704      0.684      0.784      0.388\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/100         0G      1.543      1.195       1.82         32        640: 100%|██████████| 11/11 [01:20<00:00,  7.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "                   all         16         19       0.51      0.789      0.687      0.273\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/100         0G      1.598      1.283      1.919         20        640: 100%|██████████| 11/11 [01:21<00:00,  7.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "                   all         16         19      0.873      0.737      0.872      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/100         0G      1.695      1.225      1.927         25        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19      0.789      0.737      0.808      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/100         0G       1.56      1.181      1.853         23        640: 100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n",
      "                   all         16         19      0.647      0.842      0.744      0.357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/100         0G        1.6      1.173      1.863         21        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "                   all         16         19      0.874      0.842      0.813      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/100         0G      1.531      1.143      1.831         26        640: 100%|██████████| 11/11 [01:20<00:00,  7.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\n",
      "                   all         16         19      0.816      0.699      0.793       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/100         0G       1.54      1.175      1.817         19        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "                   all         16         19      0.653      0.737      0.689      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/100         0G      1.539      1.171      1.826         22        640: 100%|██████████| 11/11 [01:20<00:00,  7.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "                   all         16         19      0.573      0.842      0.708      0.375\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/100         0G      1.488      1.126      1.801         18        640: 100%|██████████| 11/11 [01:20<00:00,  7.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "                   all         16         19      0.622      0.789      0.695      0.297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/100         0G      1.557      1.108      1.848         25        640: 100%|██████████| 11/11 [01:20<00:00,  7.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.26s/it]\n",
      "                   all         16         19      0.782      0.789      0.788      0.351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/100         0G      1.461      1.078      1.741         26        640: 100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n",
      "                   all         16         19      0.755      0.737      0.811      0.407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/100         0G      1.514      1.118      1.741         24        640: 100%|██████████| 11/11 [01:20<00:00,  7.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.26s/it]\n",
      "                   all         16         19      0.773      0.737      0.786      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/100         0G       1.54      1.131      1.863         24        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "                   all         16         19      0.812       0.68      0.729      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/100         0G      1.524      1.136        1.8         23        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "                   all         16         19      0.687      0.737      0.737      0.355\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/100         0G      1.368      1.022      1.733         23        640: 100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "                   all         16         19      0.825      0.789       0.84      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/100         0G      1.477      1.127      1.845         21        640: 100%|██████████| 11/11 [01:20<00:00,  7.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "                   all         16         19      0.933      0.736      0.836      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/100         0G      1.545      1.068      1.774         28        640: 100%|██████████| 11/11 [01:20<00:00,  7.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.30s/it]\n",
      "                   all         16         19      0.731      0.859      0.862      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     60/100         0G       1.45      1.035      1.731         28        640: 100%|██████████| 11/11 [01:20<00:00,  7.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.47s/it]\n",
      "                   all         16         19      0.861      0.895      0.912      0.578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     61/100         0G      1.395     0.9921       1.68         26        640: 100%|██████████| 11/11 [01:21<00:00,  7.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "                   all         16         19      0.953      0.789      0.899      0.484\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     62/100         0G      1.391      1.026      1.706         17        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.38s/it]\n",
      "                   all         16         19      0.866      0.789      0.891      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     63/100         0G      1.389     0.9821      1.695         19        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "                   all         16         19      0.811      0.895      0.855      0.474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     64/100         0G      1.443      1.011      1.714         24        640: 100%|██████████| 11/11 [01:19<00:00,  7.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "                   all         16         19      0.923      0.684      0.813       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     65/100         0G      1.476     0.9925      1.738         21        640: 100%|██████████| 11/11 [01:19<00:00,  7.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n",
      "                   all         16         19      0.857      0.789      0.847      0.469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     66/100         0G      1.381     0.9845      1.678         21        640: 100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19      0.753      0.842      0.828      0.424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     67/100         0G      1.498     0.9765      1.698         26        640: 100%|██████████| 11/11 [01:21<00:00,  7.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                   all         16         19      0.801      0.789      0.812      0.457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     68/100         0G      1.471       1.03      1.701         24        640: 100%|██████████| 11/11 [01:20<00:00,  7.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\n",
      "                   all         16         19        0.9      0.684      0.826      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     69/100         0G      1.353     0.9627      1.636         21        640: 100%|██████████| 11/11 [01:20<00:00,  7.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.33s/it]\n",
      "                   all         16         19      0.873      0.725      0.829      0.393\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     70/100         0G      1.384     0.9411      1.686         26        640: 100%|██████████| 11/11 [01:21<00:00,  7.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "                   all         16         19          1      0.777      0.897      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     71/100         0G      1.419      1.026      1.652         34        640: 100%|██████████| 11/11 [01:20<00:00,  7.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "                   all         16         19      0.834      0.789      0.861      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     72/100         0G      1.413     0.9776      1.698         18        640: 100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\n",
      "                   all         16         19      0.989      0.842      0.913      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     73/100         0G      1.391     0.8984      1.713         22        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "                   all         16         19          1      0.782      0.907      0.485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     74/100         0G      1.458     0.9471      1.646         18        640: 100%|██████████| 11/11 [01:20<00:00,  7.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.30s/it]\n",
      "                   all         16         19      0.815      0.789      0.873      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     75/100         0G      1.515     0.9776      1.729         20        640: 100%|██████████| 11/11 [01:20<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "                   all         16         19      0.787      0.842      0.869      0.478\n",
      "Stopping training early as no improvement observed in last 15 epochs. Best results observed at epoch 60, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=15) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "75 epochs completed in 1.792 hours.\n",
      "Optimizer stripped from runs\\detect\\train6\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from runs\\detect\\train6\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating runs\\detect\\train6\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.205  Python-3.11.5 torch-2.1.0+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.62s/it]\n",
      "                   all         16         19      0.861      0.895      0.912      0.578\n",
      "Speed: 3.2ms preprocess, 149.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "\n",
    "# Use the model\n",
    "results = model.train(data=\"config.yaml\", epochs=100, patience=15)  # train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 49.3ms\n",
      "Speed: 1.0ms preprocess, 49.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 185.7ms\n",
      "Speed: 15.3ms preprocess, 185.7ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 137.2ms\n",
      "Speed: 7.7ms preprocess, 137.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 120.4ms\n",
      "Speed: 2.3ms preprocess, 120.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 58.5ms\n",
      "Speed: 1.0ms preprocess, 58.5ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 105.4ms\n",
      "Speed: 2.5ms preprocess, 105.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 108.9ms\n",
      "Speed: 3.0ms preprocess, 108.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.6ms\n",
      "Speed: 4.1ms preprocess, 95.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 44.7ms\n",
      "Speed: 0.0ms preprocess, 44.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 87.4ms\n",
      "Speed: 2.0ms preprocess, 87.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 38.2ms\n",
      "Speed: 1.0ms preprocess, 38.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 84.2ms\n",
      "Speed: 5.2ms preprocess, 84.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 43.4ms\n",
      "Speed: 1.0ms preprocess, 43.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 85.0ms\n",
      "Speed: 1.6ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 52.4ms\n",
      "Speed: 1.6ms preprocess, 52.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 84.6ms\n",
      "Speed: 2.0ms preprocess, 84.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 41.9ms\n",
      "Speed: 1.1ms preprocess, 41.9ms inference, 0.9ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 85.0ms\n",
      "Speed: 1.6ms preprocess, 85.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 41.4ms\n",
      "Speed: 0.0ms preprocess, 41.4ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 84.7ms\n",
      "Speed: 2.2ms preprocess, 84.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 42.5ms\n",
      "Speed: 1.1ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 85.3ms\n",
      "Speed: 2.0ms preprocess, 85.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 57.4ms\n",
      "Speed: 1.0ms preprocess, 57.4ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 83.9ms\n",
      "Speed: 2.0ms preprocess, 83.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 96.6ms\n",
      "Speed: 2.0ms preprocess, 96.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.3ms\n",
      "Speed: 3.1ms preprocess, 91.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.5ms\n",
      "Speed: 3.1ms preprocess, 86.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 73.1ms\n",
      "Speed: 2.0ms preprocess, 73.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 96x640 (no detections), 47.5ms\n",
      "Speed: 0.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 640)\n",
      "0: 384x640 1 matricula, 82.8ms\n",
      "Speed: 1.2ms preprocess, 82.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 99.7ms\n",
      "Speed: 2.0ms preprocess, 99.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.8ms\n",
      "Speed: 2.0ms preprocess, 85.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.5ms\n",
      "Speed: 2.0ms preprocess, 83.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.3ms\n",
      "Speed: 2.2ms preprocess, 85.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 75.0ms\n",
      "Speed: 2.0ms preprocess, 75.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.4ms\n",
      "Speed: 2.0ms preprocess, 81.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.8ms\n",
      "Speed: 2.0ms preprocess, 88.8ms inference, 0.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 76.1ms\n",
      "Speed: 2.1ms preprocess, 76.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.7ms\n",
      "Speed: 2.6ms preprocess, 83.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.4ms\n",
      "Speed: 1.0ms preprocess, 83.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 112.8ms\n",
      "Speed: 1.9ms preprocess, 112.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.4ms\n",
      "Speed: 2.0ms preprocess, 83.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.7ms\n",
      "Speed: 2.0ms preprocess, 82.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.2ms\n",
      "Speed: 2.0ms preprocess, 82.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.0ms\n",
      "Speed: 2.0ms preprocess, 80.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 79.1ms\n",
      "Speed: 1.5ms preprocess, 79.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.4ms\n",
      "Speed: 1.0ms preprocess, 95.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.7ms\n",
      "Speed: 2.0ms preprocess, 83.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 79.8ms\n",
      "Speed: 2.0ms preprocess, 79.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 76.3ms\n",
      "Speed: 2.6ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 72.8ms\n",
      "Speed: 2.0ms preprocess, 72.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.6ms\n",
      "Speed: 2.4ms preprocess, 83.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.7ms\n",
      "Speed: 2.0ms preprocess, 82.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.8ms\n",
      "Speed: 2.1ms preprocess, 83.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.1ms\n",
      "Speed: 1.6ms preprocess, 84.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 77.4ms\n",
      "Speed: 2.2ms preprocess, 77.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.7ms\n",
      "Speed: 2.0ms preprocess, 84.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.2ms\n",
      "Speed: 1.1ms preprocess, 84.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.6ms\n",
      "Speed: 1.0ms preprocess, 88.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 99.5ms\n",
      "Speed: 2.1ms preprocess, 99.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.4ms\n",
      "Speed: 2.1ms preprocess, 89.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.2ms\n",
      "Speed: 2.2ms preprocess, 91.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.4ms\n",
      "Speed: 2.4ms preprocess, 92.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.0ms\n",
      "Speed: 1.5ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.1ms\n",
      "Speed: 2.8ms preprocess, 95.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 93.0ms\n",
      "Speed: 2.5ms preprocess, 93.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.4ms\n",
      "Speed: 1.7ms preprocess, 85.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.9ms\n",
      "Speed: 2.0ms preprocess, 84.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.5ms\n",
      "Speed: 2.0ms preprocess, 87.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.8ms\n",
      "Speed: 2.0ms preprocess, 82.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.7ms\n",
      "Speed: 2.2ms preprocess, 83.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 79.3ms\n",
      "Speed: 2.5ms preprocess, 79.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.8ms\n",
      "Speed: 2.0ms preprocess, 83.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.5ms\n",
      "Speed: 2.1ms preprocess, 82.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 78.8ms\n",
      "Speed: 2.0ms preprocess, 78.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 78.5ms\n",
      "Speed: 1.5ms preprocess, 78.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.9ms\n",
      "Speed: 1.9ms preprocess, 87.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 78.5ms\n",
      "Speed: 2.0ms preprocess, 78.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.2ms\n",
      "Speed: 2.3ms preprocess, 83.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.6ms\n",
      "Speed: 1.0ms preprocess, 83.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 73.5ms\n",
      "Speed: 1.0ms preprocess, 73.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.0ms\n",
      "Speed: 2.2ms preprocess, 85.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 76.8ms\n",
      "Speed: 2.0ms preprocess, 76.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.0ms\n",
      "Speed: 2.0ms preprocess, 86.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.9ms\n",
      "Speed: 2.0ms preprocess, 81.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.1ms\n",
      "Speed: 2.0ms preprocess, 80.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.1ms\n",
      "Speed: 2.6ms preprocess, 84.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.8ms\n",
      "Speed: 2.0ms preprocess, 84.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.0ms\n",
      "Speed: 2.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.9ms\n",
      "Speed: 1.7ms preprocess, 83.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.1ms\n",
      "Speed: 2.3ms preprocess, 81.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.5ms\n",
      "Speed: 2.2ms preprocess, 85.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.3ms\n",
      "Speed: 1.0ms preprocess, 80.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.5ms\n",
      "Speed: 2.6ms preprocess, 90.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.8ms\n",
      "Speed: 2.0ms preprocess, 80.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.5ms\n",
      "Speed: 2.0ms preprocess, 89.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.7ms\n",
      "Speed: 2.0ms preprocess, 83.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.3ms\n",
      "Speed: 2.0ms preprocess, 87.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 162.3ms\n",
      "Speed: 1.5ms preprocess, 162.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.9ms\n",
      "Speed: 2.2ms preprocess, 87.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.3ms\n",
      "Speed: 2.0ms preprocess, 81.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.4ms\n",
      "Speed: 2.3ms preprocess, 83.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.8ms\n",
      "Speed: 1.6ms preprocess, 80.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.0ms\n",
      "Speed: 2.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.4ms\n",
      "Speed: 2.0ms preprocess, 83.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.3ms\n",
      "Speed: 2.0ms preprocess, 85.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.8ms\n",
      "Speed: 2.0ms preprocess, 86.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.9ms\n",
      "Speed: 2.0ms preprocess, 80.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 133.3ms\n",
      "Speed: 1.7ms preprocess, 133.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.7ms\n",
      "Speed: 2.1ms preprocess, 87.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.9ms\n",
      "Speed: 1.8ms preprocess, 89.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 76.7ms\n",
      "Speed: 2.1ms preprocess, 76.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.3ms\n",
      "Speed: 1.0ms preprocess, 85.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.9ms\n",
      "Speed: 2.0ms preprocess, 82.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.8ms\n",
      "Speed: 2.0ms preprocess, 83.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 116.2ms\n",
      "Speed: 2.0ms preprocess, 116.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 96.1ms\n",
      "Speed: 1.7ms preprocess, 96.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.4ms\n",
      "Speed: 2.1ms preprocess, 81.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.6ms\n",
      "Speed: 2.5ms preprocess, 86.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.2ms\n",
      "Speed: 1.0ms preprocess, 80.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.4ms\n",
      "Speed: 2.1ms preprocess, 90.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.2ms\n",
      "Speed: 2.6ms preprocess, 80.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.4ms\n",
      "Speed: 2.0ms preprocess, 83.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 108.1ms\n",
      "Speed: 2.0ms preprocess, 108.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.0ms\n",
      "Speed: 2.0ms preprocess, 85.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.4ms\n",
      "Speed: 1.0ms preprocess, 81.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 110.0ms\n",
      "Speed: 1.3ms preprocess, 110.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.7ms\n",
      "Speed: 2.5ms preprocess, 90.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.9ms\n",
      "Speed: 1.0ms preprocess, 81.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.6ms\n",
      "Speed: 2.1ms preprocess, 80.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.7ms\n",
      "Speed: 1.0ms preprocess, 81.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 256x640 (no detections), 79.0ms\n",
      "Speed: 1.6ms preprocess, 79.0ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 1 matricula, 83.9ms\n",
      "Speed: 2.0ms preprocess, 83.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 320x640 (no detections), 87.5ms\n",
      "Speed: 2.0ms preprocess, 87.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "0: 384x640 1 matricula, 86.3ms\n",
      "Speed: 2.0ms preprocess, 86.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 60.5ms\n",
      "Speed: 1.4ms preprocess, 60.5ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 53.4ms\n",
      "Speed: 1.0ms preprocess, 53.4ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 83.1ms\n",
      "Speed: 2.5ms preprocess, 83.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 43.3ms\n",
      "Speed: 1.0ms preprocess, 43.3ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 48.0ms\n",
      "Speed: 1.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 83.9ms\n",
      "Speed: 2.9ms preprocess, 83.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.6ms\n",
      "Speed: 1.5ms preprocess, 45.6ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 45.5ms\n",
      "Speed: 0.0ms preprocess, 45.5ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 80.2ms\n",
      "Speed: 2.0ms preprocess, 80.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 45.8ms\n",
      "Speed: 1.0ms preprocess, 45.8ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 82.4ms\n",
      "Speed: 1.1ms preprocess, 82.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 43.6ms\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 79.1ms\n",
      "Speed: 2.7ms preprocess, 79.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 46.4ms\n",
      "Speed: 1.0ms preprocess, 46.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 83.6ms\n",
      "Speed: 1.1ms preprocess, 83.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 49.4ms\n",
      "Speed: 0.7ms preprocess, 49.4ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 87.8ms\n",
      "Speed: 2.6ms preprocess, 87.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 52.6ms\n",
      "Speed: 2.0ms preprocess, 52.6ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 83.7ms\n",
      "Speed: 2.1ms preprocess, 83.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.5ms\n",
      "Speed: 1.6ms preprocess, 45.5ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 86.3ms\n",
      "Speed: 2.0ms preprocess, 86.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 46.1ms\n",
      "Speed: 1.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 82.9ms\n",
      "Speed: 1.0ms preprocess, 82.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 52.8ms\n",
      "Speed: 1.5ms preprocess, 52.8ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 87.1ms\n",
      "Speed: 2.2ms preprocess, 87.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 86.9ms\n",
      "Speed: 2.0ms preprocess, 86.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 40.2ms\n",
      "Speed: 1.0ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 85.4ms\n",
      "Speed: 2.0ms preprocess, 85.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.7ms\n",
      "Speed: 1.0ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 83.2ms\n",
      "Speed: 2.0ms preprocess, 83.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.6ms\n",
      "Speed: 1.0ms preprocess, 45.6ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 50.8ms\n",
      "Speed: 1.0ms preprocess, 50.8ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 82.6ms\n",
      "Speed: 2.0ms preprocess, 82.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 47.9ms\n",
      "Speed: 1.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 48.1ms\n",
      "Speed: 0.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 81.6ms\n",
      "Speed: 2.9ms preprocess, 81.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 44.3ms\n",
      "Speed: 1.0ms preprocess, 44.3ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 83.8ms\n",
      "Speed: 3.4ms preprocess, 83.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.3ms\n",
      "Speed: 0.6ms preprocess, 45.3ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 82.4ms\n",
      "Speed: 2.0ms preprocess, 82.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 48.0ms\n",
      "Speed: 2.1ms preprocess, 48.0ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 77.7ms\n",
      "Speed: 2.0ms preprocess, 77.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 43.7ms\n",
      "Speed: 1.0ms preprocess, 43.7ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.3ms\n",
      "Speed: 2.0ms preprocess, 84.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 82.9ms\n",
      "Speed: 1.5ms preprocess, 82.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 46.5ms\n",
      "Speed: 1.8ms preprocess, 46.5ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 56.1ms\n",
      "Speed: 1.0ms preprocess, 56.1ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 82.0ms\n",
      "Speed: 2.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 47.5ms\n",
      "Speed: 1.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 82.5ms\n",
      "Speed: 2.0ms preprocess, 82.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 45.9ms\n",
      "Speed: 1.5ms preprocess, 45.9ms inference, 0.7ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 88.7ms\n",
      "Speed: 2.1ms preprocess, 88.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 49.8ms\n",
      "Speed: 1.3ms preprocess, 49.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 85.1ms\n",
      "Speed: 2.0ms preprocess, 85.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 43.1ms\n",
      "Speed: 1.1ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.9ms\n",
      "Speed: 2.0ms preprocess, 84.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 46.4ms\n",
      "Speed: 1.0ms preprocess, 46.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 79.9ms\n",
      "Speed: 1.8ms preprocess, 79.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 51.8ms\n",
      "Speed: 1.0ms preprocess, 51.8ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 80.8ms\n",
      "Speed: 2.0ms preprocess, 80.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 55.0ms\n",
      "Speed: 1.0ms preprocess, 55.0ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 83.2ms\n",
      "Speed: 2.5ms preprocess, 83.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 52.4ms\n",
      "Speed: 1.0ms preprocess, 52.4ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 53.5ms\n",
      "Speed: 1.2ms preprocess, 53.5ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 84.1ms\n",
      "Speed: 1.6ms preprocess, 84.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 44.6ms\n",
      "Speed: 1.7ms preprocess, 44.6ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 51.9ms\n",
      "Speed: 1.5ms preprocess, 51.9ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 98.4ms\n",
      "Speed: 1.6ms preprocess, 98.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 47.0ms\n",
      "Speed: 1.0ms preprocess, 47.0ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 55.3ms\n",
      "Speed: 1.1ms preprocess, 55.3ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 81.9ms\n",
      "Speed: 2.0ms preprocess, 81.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 48.4ms\n",
      "Speed: 0.9ms preprocess, 48.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.6ms\n",
      "Speed: 2.4ms preprocess, 84.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.2ms\n",
      "Speed: 2.0ms preprocess, 87.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.1ms\n",
      "Speed: 3.0ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 104.3ms\n",
      "Speed: 1.0ms preprocess, 104.3ms inference, 0.5ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 87.9ms\n",
      "Speed: 2.0ms preprocess, 87.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.8ms\n",
      "Speed: 1.7ms preprocess, 83.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.5ms\n",
      "Speed: 2.7ms preprocess, 81.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.0ms\n",
      "Speed: 1.5ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.1ms\n",
      "Speed: 2.0ms preprocess, 84.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.8ms\n",
      "Speed: 2.0ms preprocess, 81.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 79.9ms\n",
      "Speed: 2.0ms preprocess, 79.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.3ms\n",
      "Speed: 1.6ms preprocess, 87.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.3ms\n",
      "Speed: 1.0ms preprocess, 80.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.2ms\n",
      "Speed: 1.8ms preprocess, 91.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.9ms\n",
      "Speed: 3.2ms preprocess, 92.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.2ms\n",
      "Speed: 2.6ms preprocess, 84.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.0ms\n",
      "Speed: 2.0ms preprocess, 85.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.0ms\n",
      "Speed: 2.2ms preprocess, 84.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 47.8ms\n",
      "Speed: 1.0ms preprocess, 47.8ms inference, 2.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 81.6ms\n",
      "Speed: 2.5ms preprocess, 81.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 49.5ms\n",
      "Speed: 1.4ms preprocess, 49.5ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 84.8ms\n",
      "Speed: 2.0ms preprocess, 84.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 46.6ms\n",
      "Speed: 1.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 77.9ms\n",
      "Speed: 1.0ms preprocess, 77.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 41.6ms\n",
      "Speed: 1.4ms preprocess, 41.6ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.1ms\n",
      "Speed: 2.0ms preprocess, 84.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 51.0ms\n",
      "Speed: 2.0ms preprocess, 51.0ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 224x640 (no detections), 62.8ms\n",
      "Speed: 1.0ms preprocess, 62.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 73.0ms\n",
      "Speed: 3.0ms preprocess, 73.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 40.3ms\n",
      "Speed: 1.0ms preprocess, 40.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "0: 160x640 (no detections), 45.6ms\n",
      "Speed: 1.2ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 84.6ms\n",
      "Speed: 2.6ms preprocess, 84.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 85.0ms\n",
      "Speed: 2.3ms preprocess, 85.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.9ms\n",
      "Speed: 2.0ms preprocess, 45.9ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 73.8ms\n",
      "Speed: 2.1ms preprocess, 73.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 54.4ms\n",
      "Speed: 0.7ms preprocess, 54.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 93.4ms\n",
      "Speed: 2.2ms preprocess, 93.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 86.9ms\n",
      "Speed: 2.8ms preprocess, 86.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 49.0ms\n",
      "Speed: 1.1ms preprocess, 49.0ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.9ms\n",
      "Speed: 2.0ms preprocess, 84.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 46.5ms\n",
      "Speed: 1.5ms preprocess, 46.5ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 81.0ms\n",
      "Speed: 2.6ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 44.8ms\n",
      "Speed: 1.0ms preprocess, 44.8ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 82.4ms\n",
      "Speed: 1.7ms preprocess, 82.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 104.1ms\n",
      "Speed: 1.9ms preprocess, 104.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.6ms\n",
      "Speed: 1.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 83.2ms\n",
      "Speed: 1.0ms preprocess, 83.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 46.2ms\n",
      "Speed: 1.1ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 87.2ms\n",
      "Speed: 2.5ms preprocess, 87.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 47.8ms\n",
      "Speed: 1.2ms preprocess, 47.8ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 81.4ms\n",
      "Speed: 2.0ms preprocess, 81.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.5ms\n",
      "Speed: 1.0ms preprocess, 45.5ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 76.9ms\n",
      "Speed: 1.5ms preprocess, 76.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 35.4ms\n",
      "Speed: 1.0ms preprocess, 35.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 81.1ms\n",
      "Speed: 2.0ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 43.0ms\n",
      "Speed: 0.0ms preprocess, 43.0ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.7ms\n",
      "Speed: 2.0ms preprocess, 84.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 38.5ms\n",
      "Speed: 1.8ms preprocess, 38.5ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 88.4ms\n",
      "Speed: 2.0ms preprocess, 88.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 84.1ms\n",
      "Speed: 1.5ms preprocess, 84.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 47.2ms\n",
      "Speed: 1.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 49.1ms\n",
      "Speed: 1.0ms preprocess, 49.1ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 81.1ms\n",
      "Speed: 2.0ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 44.3ms\n",
      "Speed: 0.5ms preprocess, 44.3ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.8ms\n",
      "Speed: 3.0ms preprocess, 84.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.5ms\n",
      "Speed: 0.9ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 80.4ms\n",
      "Speed: 2.0ms preprocess, 80.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 36.7ms\n",
      "Speed: 1.0ms preprocess, 36.7ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 81.9ms\n",
      "Speed: 2.4ms preprocess, 81.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 38.7ms\n",
      "Speed: 1.0ms preprocess, 38.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "0: 160x640 (no detections), 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 84.6ms\n",
      "Speed: 1.9ms preprocess, 84.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 41.4ms\n",
      "Speed: 1.0ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 80.8ms\n",
      "Speed: 2.0ms preprocess, 80.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 38.9ms\n",
      "Speed: 1.0ms preprocess, 38.9ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 77.3ms\n",
      "Speed: 1.9ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 46.1ms\n",
      "Speed: 1.1ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 83.9ms\n",
      "Speed: 2.0ms preprocess, 83.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 38.8ms\n",
      "Speed: 1.2ms preprocess, 38.8ms inference, 1.1ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 82.5ms\n",
      "Speed: 2.1ms preprocess, 82.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 48.4ms\n",
      "Speed: 1.0ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 224x640 (no detections), 52.1ms\n",
      "Speed: 1.0ms preprocess, 52.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 78.0ms\n",
      "Speed: 2.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 160x640 (no detections), 44.2ms\n",
      "Speed: 1.3ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 70.9ms\n",
      "Speed: 0.0ms preprocess, 70.9ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 3 matriculas, 86.2ms\n",
      "Speed: 1.8ms preprocess, 86.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 60.1ms\n",
      "Speed: 0.9ms preprocess, 60.1ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 51.2ms\n",
      "Speed: 0.5ms preprocess, 51.2ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 84.6ms\n",
      "Speed: 1.9ms preprocess, 84.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 52.0ms\n",
      "Speed: 1.0ms preprocess, 52.0ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 49.6ms\n",
      "Speed: 1.6ms preprocess, 49.6ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 128x640 (no detections), 35.3ms\n",
      "Speed: 2.0ms preprocess, 35.3ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 3 matriculas, 83.1ms\n",
      "Speed: 3.0ms preprocess, 83.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 49.6ms\n",
      "Speed: 1.0ms preprocess, 49.6ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 51.8ms\n",
      "Speed: 1.0ms preprocess, 51.8ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 224x640 (no detections), 57.5ms\n",
      "Speed: 1.6ms preprocess, 57.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 3 matriculas, 83.5ms\n",
      "Speed: 2.3ms preprocess, 83.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.9ms\n",
      "Speed: 1.0ms preprocess, 45.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 53.6ms\n",
      "Speed: 1.0ms preprocess, 53.6ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 86.9ms\n",
      "Speed: 1.9ms preprocess, 86.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 53.1ms\n",
      "Speed: 0.9ms preprocess, 53.1ms inference, 0.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 85.7ms\n",
      "Speed: 1.6ms preprocess, 85.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 58.9ms\n",
      "Speed: 1.0ms preprocess, 58.9ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 57.7ms\n",
      "Speed: 1.0ms preprocess, 57.7ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 83.4ms\n",
      "Speed: 2.0ms preprocess, 83.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 51.1ms\n",
      "Speed: 1.6ms preprocess, 51.1ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 224x640 (no detections), 54.6ms\n",
      "Speed: 1.8ms preprocess, 54.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 83.9ms\n",
      "Speed: 2.0ms preprocess, 83.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 51.1ms\n",
      "Speed: 1.0ms preprocess, 51.1ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 84.6ms\n",
      "Speed: 1.8ms preprocess, 84.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 46.1ms\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 224x640 (no detections), 51.9ms\n",
      "Speed: 1.0ms preprocess, 51.9ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 82.6ms\n",
      "Speed: 2.0ms preprocess, 82.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 44.5ms\n",
      "Speed: 0.0ms preprocess, 44.5ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 145.3ms\n",
      "Speed: 2.0ms preprocess, 145.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 47.3ms\n",
      "Speed: 0.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 83.1ms\n",
      "Speed: 2.0ms preprocess, 83.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 47.0ms\n",
      "Speed: 0.0ms preprocess, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 83.7ms\n",
      "Speed: 1.7ms preprocess, 83.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 80.9ms\n",
      "Speed: 2.1ms preprocess, 80.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.5ms\n",
      "Speed: 1.1ms preprocess, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.1ms\n",
      "Speed: 2.3ms preprocess, 84.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 61.4ms\n",
      "Speed: 1.0ms preprocess, 61.4ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.1ms\n",
      "Speed: 2.0ms preprocess, 84.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 82.7ms\n",
      "Speed: 2.4ms preprocess, 82.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.8ms\n",
      "Speed: 1.1ms preprocess, 45.8ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 85.6ms\n",
      "Speed: 2.0ms preprocess, 85.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 37.6ms\n",
      "Speed: 2.0ms preprocess, 37.6ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 80.4ms\n",
      "Speed: 3.0ms preprocess, 80.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 86.2ms\n",
      "Speed: 2.7ms preprocess, 86.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 46.4ms\n",
      "Speed: 1.0ms preprocess, 46.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 85.4ms\n",
      "Speed: 2.2ms preprocess, 85.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 43.9ms\n",
      "Speed: 2.0ms preprocess, 43.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.7ms\n",
      "Speed: 1.9ms preprocess, 84.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 51.9ms\n",
      "Speed: 1.0ms preprocess, 51.9ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 83.2ms\n",
      "Speed: 2.0ms preprocess, 83.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 54.8ms\n",
      "Speed: 1.0ms preprocess, 54.8ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 82.9ms\n",
      "Speed: 2.0ms preprocess, 82.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 44.6ms\n",
      "Speed: 1.1ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 83.2ms\n",
      "Speed: 2.0ms preprocess, 83.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 45.4ms\n",
      "Speed: 1.0ms preprocess, 45.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.1ms\n",
      "Speed: 2.0ms preprocess, 84.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 54.1ms\n",
      "Speed: 1.0ms preprocess, 54.1ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 80.5ms\n",
      "Speed: 2.7ms preprocess, 80.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 46.8ms\n",
      "Speed: 1.0ms preprocess, 46.8ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 80.0ms\n",
      "Speed: 2.7ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 77.3ms\n",
      "Speed: 2.1ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 55.9ms\n",
      "Speed: 1.0ms preprocess, 55.9ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 84.7ms\n",
      "Speed: 2.0ms preprocess, 84.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 47.0ms\n",
      "Speed: 1.9ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 75.7ms\n",
      "Speed: 2.0ms preprocess, 75.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 58.4ms\n",
      "Speed: 1.0ms preprocess, 58.4ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 90.5ms\n",
      "Speed: 2.0ms preprocess, 90.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 51.9ms\n",
      "Speed: 1.0ms preprocess, 51.9ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 84.4ms\n",
      "Speed: 2.6ms preprocess, 84.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 72.7ms\n",
      "Speed: 1.0ms preprocess, 72.7ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 160x640 (no detections), 47.4ms\n",
      "Speed: 0.6ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 106.0ms\n",
      "Speed: 3.1ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 44.1ms\n",
      "Speed: 0.0ms preprocess, 44.1ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 78.6ms\n",
      "Speed: 2.6ms preprocess, 78.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 53.9ms\n",
      "Speed: 1.5ms preprocess, 53.9ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 78.0ms\n",
      "Speed: 2.6ms preprocess, 78.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 50.4ms\n",
      "Speed: 1.0ms preprocess, 50.4ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 81.4ms\n",
      "Speed: 2.0ms preprocess, 81.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 44.4ms\n",
      "Speed: 1.0ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 83.1ms\n",
      "Speed: 2.6ms preprocess, 83.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 84.1ms\n",
      "Speed: 2.0ms preprocess, 84.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 46.4ms\n",
      "Speed: 1.0ms preprocess, 46.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 86.2ms\n",
      "Speed: 1.6ms preprocess, 86.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 46.4ms\n",
      "Speed: 1.0ms preprocess, 46.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 85.7ms\n",
      "Speed: 2.0ms preprocess, 85.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 56.7ms\n",
      "Speed: 1.7ms preprocess, 56.7ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 74.5ms\n",
      "Speed: 1.5ms preprocess, 74.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 47.8ms\n",
      "Speed: 1.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 256x640 (no detections), 60.2ms\n",
      "Speed: 1.5ms preprocess, 60.2ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 2 matriculas, 82.9ms\n",
      "Speed: 2.0ms preprocess, 82.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 256x640 (no detections), 60.4ms\n",
      "Speed: 1.0ms preprocess, 60.4ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 1 matricula, 82.6ms\n",
      "Speed: 2.0ms preprocess, 82.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 48.4ms\n",
      "Speed: 1.2ms preprocess, 48.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 88.9ms\n",
      "Speed: 2.0ms preprocess, 88.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 44.8ms\n",
      "Speed: 2.6ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 224x640 (no detections), 57.8ms\n",
      "Speed: 1.0ms preprocess, 57.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 80.3ms\n",
      "Speed: 2.0ms preprocess, 80.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 57.4ms\n",
      "Speed: 1.0ms preprocess, 57.4ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 78.0ms\n",
      "Speed: 2.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 55.9ms\n",
      "Speed: 2.1ms preprocess, 55.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 128x640 (no detections), 41.5ms\n",
      "Speed: 1.3ms preprocess, 41.5ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 2 matriculas, 106.2ms\n",
      "Speed: 2.0ms preprocess, 106.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 74.5ms\n",
      "Speed: 1.0ms preprocess, 74.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 160x640 (no detections), 68.0ms\n",
      "Speed: 1.6ms preprocess, 68.0ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 91.8ms\n",
      "Speed: 1.8ms preprocess, 91.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 49.2ms\n",
      "Speed: 2.0ms preprocess, 49.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 160x640 (no detections), 46.3ms\n",
      "Speed: 1.1ms preprocess, 46.3ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 80.7ms\n",
      "Speed: 2.0ms preprocess, 80.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.1ms\n",
      "Speed: 2.1ms preprocess, 82.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 59.2ms\n",
      "Speed: 1.0ms preprocess, 59.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 84.9ms\n",
      "Speed: 2.0ms preprocess, 84.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.9ms\n",
      "Speed: 2.0ms preprocess, 82.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 57.1ms\n",
      "Speed: 2.0ms preprocess, 57.1ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 87.5ms\n",
      "Speed: 1.8ms preprocess, 87.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 256x640 (no detections), 65.1ms\n",
      "Speed: 1.0ms preprocess, 65.1ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 1 matricula, 83.8ms\n",
      "Speed: 2.8ms preprocess, 83.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 256x640 (no detections), 61.9ms\n",
      "Speed: 1.0ms preprocess, 61.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 1 matricula, 81.2ms\n",
      "Speed: 2.0ms preprocess, 81.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 51.2ms\n",
      "Speed: 2.0ms preprocess, 51.2ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 83.7ms\n",
      "Speed: 1.4ms preprocess, 83.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 55.8ms\n",
      "Speed: 1.0ms preprocess, 55.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 84.7ms\n",
      "Speed: 2.4ms preprocess, 84.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 256x640 (no detections), 130.8ms\n",
      "Speed: 2.0ms preprocess, 130.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 1 matricula, 85.5ms\n",
      "Speed: 2.0ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 256x640 (no detections), 55.6ms\n",
      "Speed: 2.0ms preprocess, 55.6ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 288x640 (no detections), 79.3ms\n",
      "Speed: 1.0ms preprocess, 79.3ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "0: 384x640 2 matriculas, 82.2ms\n",
      "Speed: 2.0ms preprocess, 82.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 50.0ms\n",
      "Speed: 1.0ms preprocess, 50.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 57.5ms\n",
      "Speed: 1.3ms preprocess, 57.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 82.5ms\n",
      "Speed: 2.0ms preprocess, 82.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.2ms\n",
      "Speed: 2.2ms preprocess, 82.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.6ms\n",
      "Speed: 2.0ms preprocess, 91.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 448x640 (no detections), 126.9ms\n",
      "Speed: 2.0ms preprocess, 126.9ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "0: 384x640 1 matricula, 83.6ms\n",
      "Speed: 2.0ms preprocess, 83.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.0ms\n",
      "Speed: 2.0ms preprocess, 83.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.2ms\n",
      "Speed: 2.0ms preprocess, 92.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.5ms\n",
      "Speed: 2.7ms preprocess, 89.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.4ms\n",
      "Speed: 2.0ms preprocess, 83.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.4ms\n",
      "Speed: 1.7ms preprocess, 91.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.3ms\n",
      "Speed: 2.0ms preprocess, 92.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.6ms\n",
      "Speed: 2.0ms preprocess, 95.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.7ms\n",
      "Speed: 3.0ms preprocess, 92.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.0ms\n",
      "Speed: 2.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 97.6ms\n",
      "Speed: 3.1ms preprocess, 97.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.3ms\n",
      "Speed: 2.0ms preprocess, 91.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 98.0ms\n",
      "Speed: 1.8ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 99.2ms\n",
      "Speed: 2.0ms preprocess, 99.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 107.0ms\n",
      "Speed: 2.8ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 98.1ms\n",
      "Speed: 2.0ms preprocess, 98.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 102.3ms\n",
      "Speed: 2.7ms preprocess, 102.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 93.5ms\n",
      "Speed: 3.9ms preprocess, 93.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.8ms\n",
      "Speed: 2.0ms preprocess, 89.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 103.7ms\n",
      "Speed: 3.0ms preprocess, 103.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.3ms\n",
      "Speed: 2.4ms preprocess, 95.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 98.3ms\n",
      "Speed: 2.3ms preprocess, 98.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.8ms\n",
      "Speed: 3.2ms preprocess, 92.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.2ms\n",
      "Speed: 1.6ms preprocess, 95.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 101.7ms\n",
      "Speed: 3.0ms preprocess, 101.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 100.9ms\n",
      "Speed: 2.7ms preprocess, 100.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.6ms\n",
      "Speed: 2.3ms preprocess, 95.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 94.6ms\n",
      "Speed: 2.3ms preprocess, 94.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 97.2ms\n",
      "Speed: 2.0ms preprocess, 97.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 94.0ms\n",
      "Speed: 2.0ms preprocess, 94.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 108.4ms\n",
      "Speed: 2.4ms preprocess, 108.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 93.6ms\n",
      "Speed: 2.0ms preprocess, 93.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 99.5ms\n",
      "Speed: 2.3ms preprocess, 99.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 103.4ms\n",
      "Speed: 2.5ms preprocess, 103.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 107.0ms\n",
      "Speed: 2.1ms preprocess, 107.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 104.4ms\n",
      "Speed: 2.1ms preprocess, 104.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 103.6ms\n",
      "Speed: 2.4ms preprocess, 103.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 103.5ms\n",
      "Speed: 2.2ms preprocess, 103.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 94.4ms\n",
      "Speed: 2.0ms preprocess, 94.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 320x640 (no detections), 84.5ms\n",
      "Speed: 2.0ms preprocess, 84.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "0: 384x640 1 matricula, 95.3ms\n",
      "Speed: 2.0ms preprocess, 95.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 61.1ms\n",
      "Speed: 0.8ms preprocess, 61.1ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 224x640 (no detections), 61.0ms\n",
      "Speed: 1.0ms preprocess, 61.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 97.2ms\n",
      "Speed: 2.0ms preprocess, 97.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 63.6ms\n",
      "Speed: 1.0ms preprocess, 63.6ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 61.6ms\n",
      "Speed: 1.4ms preprocess, 61.6ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 92.0ms\n",
      "Speed: 2.2ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 61.9ms\n",
      "Speed: 1.4ms preprocess, 61.9ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 98.8ms\n",
      "Speed: 2.6ms preprocess, 98.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 61.3ms\n",
      "Speed: 1.0ms preprocess, 61.3ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 98.9ms\n",
      "Speed: 2.2ms preprocess, 98.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 64.1ms\n",
      "Speed: 1.0ms preprocess, 64.1ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 95.5ms\n",
      "Speed: 2.8ms preprocess, 95.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 64.8ms\n",
      "Speed: 1.0ms preprocess, 64.8ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 93.7ms\n",
      "Speed: 3.1ms preprocess, 93.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 74.9ms\n",
      "Speed: 0.5ms preprocess, 74.9ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 105.6ms\n",
      "Speed: 2.0ms preprocess, 105.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 59.7ms\n",
      "Speed: 1.0ms preprocess, 59.7ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 82.1ms\n",
      "Speed: 2.0ms preprocess, 82.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 52.4ms\n",
      "Speed: 1.0ms preprocess, 52.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 86.5ms\n",
      "Speed: 2.0ms preprocess, 86.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 63.9ms\n",
      "Speed: 1.0ms preprocess, 63.9ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 71.0ms\n",
      "Speed: 2.3ms preprocess, 71.0ms inference, 0.5ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 90.8ms\n",
      "Speed: 2.1ms preprocess, 90.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 60.6ms\n",
      "Speed: 1.0ms preprocess, 60.6ms inference, 1.5ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 56.8ms\n",
      "Speed: 1.0ms preprocess, 56.8ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 113.9ms\n",
      "Speed: 4.0ms preprocess, 113.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 67.1ms\n",
      "Speed: 1.0ms preprocess, 67.1ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 63.5ms\n",
      "Speed: 1.1ms preprocess, 63.5ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 95.0ms\n",
      "Speed: 2.0ms preprocess, 95.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 70.4ms\n",
      "Speed: 1.4ms preprocess, 70.4ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 102.5ms\n",
      "Speed: 2.7ms preprocess, 102.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 416x640 (no detections), 134.3ms\n",
      "Speed: 2.0ms preprocess, 134.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "0: 384x640 1 matricula, 112.5ms\n",
      "Speed: 1.7ms preprocess, 112.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 125.5ms\n",
      "Speed: 3.8ms preprocess, 125.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 117.6ms\n",
      "Speed: 1.6ms preprocess, 117.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 115.3ms\n",
      "Speed: 2.0ms preprocess, 115.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 101.5ms\n",
      "Speed: 2.8ms preprocess, 101.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 98.8ms\n",
      "Speed: 2.0ms preprocess, 98.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 94.4ms\n",
      "Speed: 2.0ms preprocess, 94.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 115.0ms\n",
      "Speed: 2.0ms preprocess, 115.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.3ms\n",
      "Speed: 2.8ms preprocess, 126.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 116.6ms\n",
      "Speed: 2.1ms preprocess, 116.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 97.0ms\n",
      "Speed: 2.1ms preprocess, 97.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.5ms\n",
      "Speed: 2.0ms preprocess, 95.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 97.4ms\n",
      "Speed: 2.0ms preprocess, 97.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 103.2ms\n",
      "Speed: 2.3ms preprocess, 103.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 96.5ms\n",
      "Speed: 3.1ms preprocess, 96.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 103.0ms\n",
      "Speed: 2.0ms preprocess, 103.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 97.3ms\n",
      "Speed: 3.3ms preprocess, 97.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 100.9ms\n",
      "Speed: 2.0ms preprocess, 100.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 96.3ms\n",
      "Speed: 3.0ms preprocess, 96.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 106.8ms\n",
      "Speed: 2.0ms preprocess, 106.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 109.9ms\n",
      "Speed: 2.2ms preprocess, 109.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 110.3ms\n",
      "Speed: 2.0ms preprocess, 110.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.8ms\n",
      "Speed: 3.5ms preprocess, 123.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 288x640 (no detections), 109.9ms\n",
      "Speed: 0.8ms preprocess, 109.9ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "0: 384x640 1 matricula, 124.9ms\n",
      "Speed: 4.7ms preprocess, 124.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.6ms\n",
      "Speed: 2.4ms preprocess, 121.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 125.1ms\n",
      "Speed: 1.5ms preprocess, 125.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 112.8ms\n",
      "Speed: 2.0ms preprocess, 112.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 69.4ms\n",
      "Speed: 1.7ms preprocess, 69.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 (no detections), 66.0ms\n",
      "Speed: 2.2ms preprocess, 66.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 100.3ms\n",
      "Speed: 3.0ms preprocess, 100.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 62.9ms\n",
      "Speed: 1.6ms preprocess, 62.9ms inference, 0.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 (no detections), 151.1ms\n",
      "Speed: 0.9ms preprocess, 151.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 97.3ms\n",
      "Speed: 3.1ms preprocess, 97.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 256x640 (no detections), 188.8ms\n",
      "Speed: 3.5ms preprocess, 188.8ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 (no detections), 178.4ms\n",
      "Speed: 3.0ms preprocess, 178.4ms inference, 1.5ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 2 matriculas, 244.2ms\n",
      "Speed: 4.3ms preprocess, 244.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 165.6ms\n",
      "Speed: 4.0ms preprocess, 165.6ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 236.0ms\n",
      "Speed: 6.8ms preprocess, 236.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 168.1ms\n",
      "Speed: 4.0ms preprocess, 168.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 246.2ms\n",
      "Speed: 4.1ms preprocess, 246.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 166.4ms\n",
      "Speed: 2.8ms preprocess, 166.4ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 247.5ms\n",
      "Speed: 7.5ms preprocess, 247.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 162.6ms\n",
      "Speed: 3.0ms preprocess, 162.6ms inference, 2.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 164.5ms\n",
      "Speed: 3.0ms preprocess, 164.5ms inference, 1.5ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 240.8ms\n",
      "Speed: 5.1ms preprocess, 240.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 157.8ms\n",
      "Speed: 3.1ms preprocess, 157.8ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 148.9ms\n",
      "Speed: 3.7ms preprocess, 148.9ms inference, 0.6ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 222.7ms\n",
      "Speed: 7.4ms preprocess, 222.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 256x640 (no detections), 195.3ms\n",
      "Speed: 2.6ms preprocess, 195.3ms inference, 2.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 224x640 (no detections), 170.6ms\n",
      "Speed: 3.4ms preprocess, 170.6ms inference, 0.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 242.2ms\n",
      "Speed: 3.6ms preprocess, 242.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 149.7ms\n",
      "Speed: 1.2ms preprocess, 149.7ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 256x640 (no detections), 184.1ms\n",
      "Speed: 3.7ms preprocess, 184.1ms inference, 2.3ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 2 matriculas, 267.1ms\n",
      "Speed: 4.5ms preprocess, 267.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 156.5ms\n",
      "Speed: 2.1ms preprocess, 156.5ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 288x640 (no detections), 190.5ms\n",
      "Speed: 3.9ms preprocess, 190.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "0: 384x640 2 matriculas, 218.4ms\n",
      "Speed: 5.2ms preprocess, 218.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 168.2ms\n",
      "Speed: 2.4ms preprocess, 168.2ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 256x640 (no detections), 170.6ms\n",
      "Speed: 3.0ms preprocess, 170.6ms inference, 2.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 2 matriculas, 220.2ms\n",
      "Speed: 3.4ms preprocess, 220.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 148.3ms\n",
      "Speed: 3.2ms preprocess, 148.3ms inference, 2.9ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 219.2ms\n",
      "Speed: 5.9ms preprocess, 219.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 107.5ms\n",
      "Speed: 2.1ms preprocess, 107.5ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 55.4ms\n",
      "Speed: 1.0ms preprocess, 55.4ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 3 matriculas, 239.1ms\n",
      "Speed: 3.1ms preprocess, 239.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 50.4ms\n",
      "Speed: 1.0ms preprocess, 50.4ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 95.6ms\n",
      "Speed: 2.9ms preprocess, 95.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 61.6ms\n",
      "Speed: 1.5ms preprocess, 61.6ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 78.3ms\n",
      "Speed: 1.3ms preprocess, 78.3ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 101.0ms\n",
      "Speed: 2.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 47.6ms\n",
      "Speed: 1.0ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 256x640 (no detections), 70.7ms\n",
      "Speed: 2.0ms preprocess, 70.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 2 matriculas, 92.8ms\n",
      "Speed: 2.4ms preprocess, 92.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 53.2ms\n",
      "Speed: 1.9ms preprocess, 53.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 256x640 (no detections), 57.9ms\n",
      "Speed: 1.8ms preprocess, 57.9ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 2 matriculas, 92.3ms\n",
      "Speed: 2.0ms preprocess, 92.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 61.0ms\n",
      "Speed: 0.9ms preprocess, 61.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 256x640 (no detections), 65.2ms\n",
      "Speed: 1.0ms preprocess, 65.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 2 matriculas, 84.5ms\n",
      "Speed: 2.0ms preprocess, 84.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 56.0ms\n",
      "Speed: 5.3ms preprocess, 56.0ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 89.6ms\n",
      "Speed: 2.0ms preprocess, 89.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 58.6ms\n",
      "Speed: 2.0ms preprocess, 58.6ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 92.4ms\n",
      "Speed: 6.1ms preprocess, 92.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 59.6ms\n",
      "Speed: 1.0ms preprocess, 59.6ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 83.0ms\n",
      "Speed: 2.0ms preprocess, 83.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.9ms\n",
      "Speed: 1.9ms preprocess, 86.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.3ms\n",
      "Speed: 2.0ms preprocess, 82.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 51.4ms\n",
      "Speed: 0.5ms preprocess, 51.4ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 90.2ms\n",
      "Speed: 2.0ms preprocess, 90.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 124.7ms\n",
      "Speed: 3.0ms preprocess, 124.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.8ms\n",
      "Speed: 2.0ms preprocess, 83.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.3ms\n",
      "Speed: 2.0ms preprocess, 88.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.6ms\n",
      "Speed: 4.4ms preprocess, 89.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.9ms\n",
      "Speed: 4.1ms preprocess, 83.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.9ms\n",
      "Speed: 2.0ms preprocess, 85.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 97.6ms\n",
      "Speed: 2.1ms preprocess, 97.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.0ms\n",
      "Speed: 2.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.4ms\n",
      "Speed: 1.0ms preprocess, 88.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.4ms\n",
      "Speed: 2.0ms preprocess, 90.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 102.6ms\n",
      "Speed: 2.6ms preprocess, 102.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.3ms\n",
      "Speed: 1.0ms preprocess, 88.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.0ms\n",
      "Speed: 2.0ms preprocess, 84.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 98.4ms\n",
      "Speed: 1.7ms preprocess, 98.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.4ms\n",
      "Speed: 1.0ms preprocess, 86.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 89.2ms\n",
      "Speed: 2.0ms preprocess, 89.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.2ms\n",
      "Speed: 2.0ms preprocess, 91.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 96x640 (no detections), 37.8ms\n",
      "Speed: 0.0ms preprocess, 37.8ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 640)\n",
      "0: 384x640 1 matricula, 91.7ms\n",
      "Speed: 2.0ms preprocess, 91.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.3ms\n",
      "Speed: 2.0ms preprocess, 89.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.1ms\n",
      "Speed: 4.2ms preprocess, 90.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.0ms\n",
      "Speed: 2.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 96x640 (no detections), 36.7ms\n",
      "Speed: 0.0ms preprocess, 36.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 640)\n",
      "0: 384x640 1 matricula, 92.1ms\n",
      "Speed: 2.0ms preprocess, 92.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.8ms\n",
      "Speed: 2.0ms preprocess, 89.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.7ms\n",
      "Speed: 2.0ms preprocess, 87.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 108.9ms\n",
      "Speed: 1.4ms preprocess, 108.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 113.1ms\n",
      "Speed: 1.4ms preprocess, 113.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.9ms\n",
      "Speed: 1.5ms preprocess, 91.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.5ms\n",
      "Speed: 1.0ms preprocess, 83.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.8ms\n",
      "Speed: 1.6ms preprocess, 82.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.3ms\n",
      "Speed: 2.0ms preprocess, 89.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 320x640 (no detections), 78.5ms\n",
      "Speed: 2.0ms preprocess, 78.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "0: 384x640 1 matricula, 85.1ms\n",
      "Speed: 2.1ms preprocess, 85.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.7ms\n",
      "Speed: 2.1ms preprocess, 92.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 49.0ms\n",
      "Speed: 1.1ms preprocess, 49.0ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 92.4ms\n",
      "Speed: 2.0ms preprocess, 92.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 50.4ms\n",
      "Speed: 0.0ms preprocess, 50.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 86.8ms\n",
      "Speed: 3.0ms preprocess, 86.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 47.0ms\n",
      "Speed: 1.6ms preprocess, 47.0ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 89.5ms\n",
      "Speed: 2.0ms preprocess, 89.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.0ms\n",
      "Speed: 2.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 40.8ms\n",
      "Speed: 1.1ms preprocess, 40.8ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 87.3ms\n",
      "Speed: 2.0ms preprocess, 87.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.5ms\n",
      "Speed: 3.0ms preprocess, 89.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.3ms\n",
      "Speed: 3.1ms preprocess, 85.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 90.4ms\n",
      "Speed: 2.6ms preprocess, 90.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 49.6ms\n",
      "Speed: 1.0ms preprocess, 49.6ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 97.9ms\n",
      "Speed: 2.6ms preprocess, 97.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 61.1ms\n",
      "Speed: 1.0ms preprocess, 61.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 84.9ms\n",
      "Speed: 2.0ms preprocess, 84.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 47.5ms\n",
      "Speed: 1.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 87.6ms\n",
      "Speed: 3.2ms preprocess, 87.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.7ms\n",
      "Speed: 3.0ms preprocess, 86.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 61.0ms\n",
      "Speed: 2.0ms preprocess, 61.0ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 84.3ms\n",
      "Speed: 2.0ms preprocess, 84.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 57.4ms\n",
      "Speed: 1.8ms preprocess, 57.4ms inference, 0.9ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 98.8ms\n",
      "Speed: 2.0ms preprocess, 98.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 165.2ms\n",
      "Speed: 2.1ms preprocess, 165.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 62.1ms\n",
      "Speed: 1.5ms preprocess, 62.1ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 117.6ms\n",
      "Speed: 3.0ms preprocess, 117.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 69.6ms\n",
      "Speed: 1.8ms preprocess, 69.6ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 116.1ms\n",
      "Speed: 1.9ms preprocess, 116.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 66.1ms\n",
      "Speed: 1.0ms preprocess, 66.1ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 108.6ms\n",
      "Speed: 2.0ms preprocess, 108.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 59.5ms\n",
      "Speed: 1.0ms preprocess, 59.5ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 256x640 (no detections), 82.4ms\n",
      "Speed: 2.3ms preprocess, 82.4ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 2 matriculas, 105.1ms\n",
      "Speed: 2.0ms preprocess, 105.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 256x640 (no detections), 81.5ms\n",
      "Speed: 2.0ms preprocess, 81.5ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 1 matricula, 126.0ms\n",
      "Speed: 2.0ms preprocess, 126.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 65.9ms\n",
      "Speed: 1.0ms preprocess, 65.9ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 107.0ms\n",
      "Speed: 2.1ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 59.1ms\n",
      "Speed: 1.0ms preprocess, 59.1ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 108.6ms\n",
      "Speed: 2.0ms preprocess, 108.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 60.2ms\n",
      "Speed: 2.0ms preprocess, 60.2ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 109.0ms\n",
      "Speed: 2.6ms preprocess, 109.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 66.0ms\n",
      "Speed: 2.0ms preprocess, 66.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 125.8ms\n",
      "Speed: 3.0ms preprocess, 125.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 70.8ms\n",
      "Speed: 1.0ms preprocess, 70.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 61.1ms\n",
      "Speed: 1.0ms preprocess, 61.1ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 101.7ms\n",
      "Speed: 2.0ms preprocess, 101.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 56.9ms\n",
      "Speed: 1.0ms preprocess, 56.9ms inference, 0.1ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 100.8ms\n",
      "Speed: 2.0ms preprocess, 100.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 60.3ms\n",
      "Speed: 1.6ms preprocess, 60.3ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 99.7ms\n",
      "Speed: 2.0ms preprocess, 99.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 60.1ms\n",
      "Speed: 1.0ms preprocess, 60.1ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 256x640 (no detections), 77.6ms\n",
      "Speed: 2.0ms preprocess, 77.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 2 matriculas, 105.2ms\n",
      "Speed: 3.0ms preprocess, 105.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 62.1ms\n",
      "Speed: 1.0ms preprocess, 62.1ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 115.0ms\n",
      "Speed: 4.2ms preprocess, 115.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 69.3ms\n",
      "Speed: 1.0ms preprocess, 69.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 384x640 (no detections), 100.8ms\n",
      "Speed: 1.0ms preprocess, 100.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 2 matriculas, 107.2ms\n",
      "Speed: 2.0ms preprocess, 107.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 53.2ms\n",
      "Speed: 1.0ms preprocess, 53.2ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 113.8ms\n",
      "Speed: 2.9ms preprocess, 113.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 54.7ms\n",
      "Speed: 2.0ms preprocess, 54.7ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 67.0ms\n",
      "Speed: 1.0ms preprocess, 67.0ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 110.8ms\n",
      "Speed: 2.5ms preprocess, 110.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 64.2ms\n",
      "Speed: 1.1ms preprocess, 64.2ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 128x640 (no detections), 54.7ms\n",
      "Speed: 1.0ms preprocess, 54.7ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 2 matriculas, 106.9ms\n",
      "Speed: 3.9ms preprocess, 106.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 54.6ms\n",
      "Speed: 1.8ms preprocess, 54.6ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 106.0ms\n",
      "Speed: 3.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 55.1ms\n",
      "Speed: 3.0ms preprocess, 55.1ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 101.9ms\n",
      "Speed: 2.0ms preprocess, 101.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 59.4ms\n",
      "Speed: 1.5ms preprocess, 59.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 74.7ms\n",
      "Speed: 1.2ms preprocess, 74.7ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 102.2ms\n",
      "Speed: 3.0ms preprocess, 102.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 71.2ms\n",
      "Speed: 1.2ms preprocess, 71.2ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 61.2ms\n",
      "Speed: 1.0ms preprocess, 61.2ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 110.3ms\n",
      "Speed: 2.0ms preprocess, 110.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 64.6ms\n",
      "Speed: 1.0ms preprocess, 64.6ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 112.6ms\n",
      "Speed: 2.7ms preprocess, 112.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 56.4ms\n",
      "Speed: 2.0ms preprocess, 56.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 100.6ms\n",
      "Speed: 2.0ms preprocess, 100.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 59.5ms\n",
      "Speed: 2.0ms preprocess, 59.5ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 64.3ms\n",
      "Speed: 2.0ms preprocess, 64.3ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 109.3ms\n",
      "Speed: 2.0ms preprocess, 109.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 55.4ms\n",
      "Speed: 1.0ms preprocess, 55.4ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 152.6ms\n",
      "Speed: 2.0ms preprocess, 152.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 58.0ms\n",
      "Speed: 1.0ms preprocess, 58.0ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 104.7ms\n",
      "Speed: 2.5ms preprocess, 104.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 51.1ms\n",
      "Speed: 1.4ms preprocess, 51.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 105.9ms\n",
      "Speed: 2.8ms preprocess, 105.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 108.7ms\n",
      "Speed: 2.7ms preprocess, 108.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 97.0ms\n",
      "Speed: 2.0ms preprocess, 97.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 96.9ms\n",
      "Speed: 2.1ms preprocess, 96.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 128.8ms\n",
      "Speed: 2.0ms preprocess, 128.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 73.9ms\n",
      "Speed: 1.0ms preprocess, 73.9ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 118.1ms\n",
      "Speed: 3.7ms preprocess, 118.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 62.8ms\n",
      "Speed: 2.3ms preprocess, 62.8ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 103.7ms\n",
      "Speed: 2.0ms preprocess, 103.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 58.1ms\n",
      "Speed: 1.0ms preprocess, 58.1ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 94.3ms\n",
      "Speed: 2.1ms preprocess, 94.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 55.6ms\n",
      "Speed: 1.0ms preprocess, 55.6ms inference, 1.1ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 108.3ms\n",
      "Speed: 3.0ms preprocess, 108.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 58.1ms\n",
      "Speed: 1.0ms preprocess, 58.1ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 224x640 (no detections), 73.1ms\n",
      "Speed: 1.0ms preprocess, 73.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 103.5ms\n",
      "Speed: 3.3ms preprocess, 103.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 60.1ms\n",
      "Speed: 2.0ms preprocess, 60.1ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 63.0ms\n",
      "Speed: 1.0ms preprocess, 63.0ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 93.0ms\n",
      "Speed: 3.0ms preprocess, 93.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 61.7ms\n",
      "Speed: 2.0ms preprocess, 61.7ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 74.4ms\n",
      "Speed: 2.0ms preprocess, 74.4ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 101.5ms\n",
      "Speed: 2.0ms preprocess, 101.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 53.6ms\n",
      "Speed: 1.1ms preprocess, 53.6ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 50.9ms\n",
      "Speed: 1.0ms preprocess, 50.9ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 99.5ms\n",
      "Speed: 3.7ms preprocess, 99.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 61.5ms\n",
      "Speed: 1.0ms preprocess, 61.5ms inference, 0.5ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 100.8ms\n",
      "Speed: 5.0ms preprocess, 100.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 57.3ms\n",
      "Speed: 1.0ms preprocess, 57.3ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 104.1ms\n",
      "Speed: 1.0ms preprocess, 104.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 65.8ms\n",
      "Speed: 2.0ms preprocess, 65.8ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 106.8ms\n",
      "Speed: 2.3ms preprocess, 106.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 62.4ms\n",
      "Speed: 1.0ms preprocess, 62.4ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 101.4ms\n",
      "Speed: 3.0ms preprocess, 101.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 61.2ms\n",
      "Speed: 1.0ms preprocess, 61.2ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 103.8ms\n",
      "Speed: 1.9ms preprocess, 103.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 59.5ms\n",
      "Speed: 2.0ms preprocess, 59.5ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 97.9ms\n",
      "Speed: 3.2ms preprocess, 97.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 115.1ms\n",
      "Speed: 1.0ms preprocess, 115.1ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 97.5ms\n",
      "Speed: 2.1ms preprocess, 97.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 69.3ms\n",
      "Speed: 1.0ms preprocess, 69.3ms inference, 1.1ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 104.1ms\n",
      "Speed: 2.0ms preprocess, 104.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 58.3ms\n",
      "Speed: 2.0ms preprocess, 58.3ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 105.7ms\n",
      "Speed: 3.9ms preprocess, 105.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 59.7ms\n",
      "Speed: 1.0ms preprocess, 59.7ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 100.3ms\n",
      "Speed: 2.0ms preprocess, 100.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 67.4ms\n",
      "Speed: 1.0ms preprocess, 67.4ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 98.8ms\n",
      "Speed: 2.0ms preprocess, 98.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 55.5ms\n",
      "Speed: 1.0ms preprocess, 55.5ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 105.4ms\n",
      "Speed: 2.0ms preprocess, 105.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 100.6ms\n",
      "Speed: 2.8ms preprocess, 100.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 103.3ms\n",
      "Speed: 2.7ms preprocess, 103.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 94.3ms\n",
      "Speed: 2.4ms preprocess, 94.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 104.8ms\n",
      "Speed: 2.0ms preprocess, 104.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 107.0ms\n",
      "Speed: 2.3ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 100.0ms\n",
      "Speed: 2.0ms preprocess, 100.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 112.2ms\n",
      "Speed: 2.0ms preprocess, 112.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 101.8ms\n",
      "Speed: 2.0ms preprocess, 101.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 98.6ms\n",
      "Speed: 2.9ms preprocess, 98.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 115.7ms\n",
      "Speed: 7.3ms preprocess, 115.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 100.3ms\n",
      "Speed: 3.1ms preprocess, 100.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 102.8ms\n",
      "Speed: 2.0ms preprocess, 102.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 100.0ms\n",
      "Speed: 3.0ms preprocess, 100.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 106.6ms\n",
      "Speed: 6.2ms preprocess, 106.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 100.7ms\n",
      "Speed: 3.2ms preprocess, 100.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 108.6ms\n",
      "Speed: 2.0ms preprocess, 108.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 98.4ms\n",
      "Speed: 2.0ms preprocess, 98.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 102.3ms\n",
      "Speed: 3.0ms preprocess, 102.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 118.1ms\n",
      "Speed: 5.7ms preprocess, 118.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 113.5ms\n",
      "Speed: 3.3ms preprocess, 113.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 99.5ms\n",
      "Speed: 2.0ms preprocess, 99.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 107.0ms\n",
      "Speed: 2.6ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 98.7ms\n",
      "Speed: 2.0ms preprocess, 98.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 119.4ms\n",
      "Speed: 2.2ms preprocess, 119.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 51.5ms\n",
      "Speed: 1.0ms preprocess, 51.5ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 112.1ms\n",
      "Speed: 1.9ms preprocess, 112.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 105.6ms\n",
      "Speed: 3.0ms preprocess, 105.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 106.7ms\n",
      "Speed: 2.6ms preprocess, 106.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 101.1ms\n",
      "Speed: 2.0ms preprocess, 101.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 67.6ms\n",
      "Speed: 1.0ms preprocess, 67.6ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 99.9ms\n",
      "Speed: 2.6ms preprocess, 99.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 63.0ms\n",
      "Speed: 1.0ms preprocess, 63.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 107.3ms\n",
      "Speed: 2.7ms preprocess, 107.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 67.8ms\n",
      "Speed: 1.0ms preprocess, 67.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 100.7ms\n",
      "Speed: 2.0ms preprocess, 100.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 54.4ms\n",
      "Speed: 1.0ms preprocess, 54.4ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 98.0ms\n",
      "Speed: 2.0ms preprocess, 98.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 55.6ms\n",
      "Speed: 2.0ms preprocess, 55.6ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 100.5ms\n",
      "Speed: 2.0ms preprocess, 100.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.6ms\n",
      "Speed: 2.4ms preprocess, 95.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 62.4ms\n",
      "Speed: 1.0ms preprocess, 62.4ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 119.7ms\n",
      "Speed: 2.0ms preprocess, 119.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 78.0ms\n",
      "Speed: 1.0ms preprocess, 78.0ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 103.9ms\n",
      "Speed: 2.5ms preprocess, 103.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 66.1ms\n",
      "Speed: 2.0ms preprocess, 66.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 97.5ms\n",
      "Speed: 2.0ms preprocess, 97.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 72.1ms\n",
      "Speed: 1.0ms preprocess, 72.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 99.6ms\n",
      "Speed: 2.1ms preprocess, 99.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 59.9ms\n",
      "Speed: 2.1ms preprocess, 59.9ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 158.2ms\n",
      "Speed: 3.2ms preprocess, 158.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 70.4ms\n",
      "Speed: 1.7ms preprocess, 70.4ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 110.2ms\n",
      "Speed: 2.3ms preprocess, 110.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 65.4ms\n",
      "Speed: 1.6ms preprocess, 65.4ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 224x640 (no detections), 74.5ms\n",
      "Speed: 0.9ms preprocess, 74.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 107.5ms\n",
      "Speed: 2.2ms preprocess, 107.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 67.2ms\n",
      "Speed: 1.0ms preprocess, 67.2ms inference, 1.9ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 102.0ms\n",
      "Speed: 2.0ms preprocess, 102.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 80.2ms\n",
      "Speed: 1.0ms preprocess, 80.2ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 112.8ms\n",
      "Speed: 2.2ms preprocess, 112.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 80.4ms\n",
      "Speed: 1.7ms preprocess, 80.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 105.7ms\n",
      "Speed: 2.2ms preprocess, 105.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 89.5ms\n",
      "Speed: 1.8ms preprocess, 89.5ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 135.1ms\n",
      "Speed: 1.6ms preprocess, 135.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 80.4ms\n",
      "Speed: 1.0ms preprocess, 80.4ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 116.9ms\n",
      "Speed: 2.7ms preprocess, 116.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 106.9ms\n",
      "Speed: 1.7ms preprocess, 106.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 69.3ms\n",
      "Speed: 1.1ms preprocess, 69.3ms inference, 0.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 111.6ms\n",
      "Speed: 2.2ms preprocess, 111.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 80.1ms\n",
      "Speed: 0.8ms preprocess, 80.1ms inference, 2.2ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 110.7ms\n",
      "Speed: 3.3ms preprocess, 110.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 68.0ms\n",
      "Speed: 0.7ms preprocess, 68.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 125.2ms\n",
      "Speed: 2.7ms preprocess, 125.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 69.8ms\n",
      "Speed: 1.7ms preprocess, 69.8ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 74.9ms\n",
      "Speed: 1.0ms preprocess, 74.9ms inference, 1.8ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 120.0ms\n",
      "Speed: 3.4ms preprocess, 120.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 84.0ms\n",
      "Speed: 1.1ms preprocess, 84.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 122.3ms\n",
      "Speed: 3.4ms preprocess, 122.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 61.3ms\n",
      "Speed: 1.0ms preprocess, 61.3ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 107.1ms\n",
      "Speed: 3.0ms preprocess, 107.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 92.1ms\n",
      "Speed: 1.6ms preprocess, 92.1ms inference, 1.1ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 113.3ms\n",
      "Speed: 3.0ms preprocess, 113.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 71.2ms\n",
      "Speed: 1.2ms preprocess, 71.2ms inference, 1.1ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 149.5ms\n",
      "Speed: 3.4ms preprocess, 149.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 135.6ms\n",
      "Speed: 3.0ms preprocess, 135.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 136.5ms\n",
      "Speed: 3.9ms preprocess, 136.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 145.3ms\n",
      "Speed: 2.0ms preprocess, 145.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 140.2ms\n",
      "Speed: 2.1ms preprocess, 140.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.2ms\n",
      "Speed: 2.0ms preprocess, 123.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 134.6ms\n",
      "Speed: 3.4ms preprocess, 134.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.1ms\n",
      "Speed: 2.2ms preprocess, 123.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 113.5ms\n",
      "Speed: 3.0ms preprocess, 113.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.0ms\n",
      "Speed: 2.9ms preprocess, 121.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 120.3ms\n",
      "Speed: 3.8ms preprocess, 120.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 109.8ms\n",
      "Speed: 2.8ms preprocess, 109.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 124.5ms\n",
      "Speed: 4.0ms preprocess, 124.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 106.9ms\n",
      "Speed: 2.4ms preprocess, 106.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 102.1ms\n",
      "Speed: 2.0ms preprocess, 102.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 100.4ms\n",
      "Speed: 5.0ms preprocess, 100.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 162.0ms\n",
      "Speed: 2.0ms preprocess, 162.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 227.6ms\n",
      "Speed: 4.0ms preprocess, 227.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 225.1ms\n",
      "Speed: 3.4ms preprocess, 225.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 237.8ms\n",
      "Speed: 4.5ms preprocess, 237.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 216.4ms\n",
      "Speed: 4.6ms preprocess, 216.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 228.1ms\n",
      "Speed: 6.0ms preprocess, 228.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 228.2ms\n",
      "Speed: 5.7ms preprocess, 228.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 236.5ms\n",
      "Speed: 6.0ms preprocess, 236.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 221.3ms\n",
      "Speed: 7.3ms preprocess, 221.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 241.4ms\n",
      "Speed: 5.8ms preprocess, 241.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 230.0ms\n",
      "Speed: 5.5ms preprocess, 230.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 234.3ms\n",
      "Speed: 5.7ms preprocess, 234.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 227.0ms\n",
      "Speed: 5.8ms preprocess, 227.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 228.8ms\n",
      "Speed: 5.0ms preprocess, 228.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 222.3ms\n",
      "Speed: 4.8ms preprocess, 222.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 220.1ms\n",
      "Speed: 3.9ms preprocess, 220.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 223.4ms\n",
      "Speed: 4.2ms preprocess, 223.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 211.6ms\n",
      "Speed: 4.0ms preprocess, 211.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 224.2ms\n",
      "Speed: 4.0ms preprocess, 224.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 229.7ms\n",
      "Speed: 4.8ms preprocess, 229.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 237.3ms\n",
      "Speed: 4.9ms preprocess, 237.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 230.6ms\n",
      "Speed: 6.0ms preprocess, 230.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 194.1ms\n",
      "Speed: 5.3ms preprocess, 194.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 216.5ms\n",
      "Speed: 3.7ms preprocess, 216.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 212.5ms\n",
      "Speed: 5.0ms preprocess, 212.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 231.1ms\n",
      "Speed: 4.6ms preprocess, 231.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 232.0ms\n",
      "Speed: 5.6ms preprocess, 232.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 232.7ms\n",
      "Speed: 5.6ms preprocess, 232.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 211.6ms\n",
      "Speed: 6.8ms preprocess, 211.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 191.9ms\n",
      "Speed: 5.1ms preprocess, 191.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 216.2ms\n",
      "Speed: 4.3ms preprocess, 216.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 236.7ms\n",
      "Speed: 3.9ms preprocess, 236.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 218.5ms\n",
      "Speed: 4.2ms preprocess, 218.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 213.4ms\n",
      "Speed: 4.6ms preprocess, 213.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 214.4ms\n",
      "Speed: 5.1ms preprocess, 214.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 187.9ms\n",
      "Speed: 5.0ms preprocess, 187.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 227.9ms\n",
      "Speed: 5.0ms preprocess, 227.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 247.4ms\n",
      "Speed: 5.7ms preprocess, 247.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 234.5ms\n",
      "Speed: 5.3ms preprocess, 234.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 226.7ms\n",
      "Speed: 6.3ms preprocess, 226.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 232.9ms\n",
      "Speed: 6.0ms preprocess, 232.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 241.6ms\n",
      "Speed: 6.2ms preprocess, 241.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 236.0ms\n",
      "Speed: 5.8ms preprocess, 236.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 225.8ms\n",
      "Speed: 5.3ms preprocess, 225.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 227.9ms\n",
      "Speed: 4.1ms preprocess, 227.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 232.3ms\n",
      "Speed: 5.8ms preprocess, 232.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 262.6ms\n",
      "Speed: 6.4ms preprocess, 262.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 237.0ms\n",
      "Speed: 9.0ms preprocess, 237.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 234.4ms\n",
      "Speed: 9.0ms preprocess, 234.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 232.7ms\n",
      "Speed: 5.8ms preprocess, 232.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 226.2ms\n",
      "Speed: 5.7ms preprocess, 226.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 207.3ms\n",
      "Speed: 4.3ms preprocess, 207.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 192.6ms\n",
      "Speed: 5.4ms preprocess, 192.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 215.6ms\n",
      "Speed: 4.0ms preprocess, 215.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 224.4ms\n",
      "Speed: 5.1ms preprocess, 224.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 205.7ms\n",
      "Speed: 2.5ms preprocess, 205.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 196.2ms\n",
      "Speed: 3.6ms preprocess, 196.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 235.4ms\n",
      "Speed: 8.9ms preprocess, 235.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 225.8ms\n",
      "Speed: 3.7ms preprocess, 225.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 229.0ms\n",
      "Speed: 5.3ms preprocess, 229.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 201.1ms\n",
      "Speed: 6.1ms preprocess, 201.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 213.4ms\n",
      "Speed: 5.1ms preprocess, 213.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 205.1ms\n",
      "Speed: 6.2ms preprocess, 205.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 239.3ms\n",
      "Speed: 7.4ms preprocess, 239.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 245.0ms\n",
      "Speed: 5.7ms preprocess, 245.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 241.0ms\n",
      "Speed: 4.5ms preprocess, 241.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 236.6ms\n",
      "Speed: 4.2ms preprocess, 236.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 198.8ms\n",
      "Speed: 5.5ms preprocess, 198.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 215.5ms\n",
      "Speed: 4.0ms preprocess, 215.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 204.9ms\n",
      "Speed: 4.4ms preprocess, 204.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 243.9ms\n",
      "Speed: 3.5ms preprocess, 243.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 249.3ms\n",
      "Speed: 4.7ms preprocess, 249.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 239.1ms\n",
      "Speed: 6.5ms preprocess, 239.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 212.1ms\n",
      "Speed: 3.0ms preprocess, 212.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 217.9ms\n",
      "Speed: 4.1ms preprocess, 217.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 126.3ms\n",
      "Speed: 1.6ms preprocess, 126.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 179.4ms\n",
      "Speed: 3.8ms preprocess, 179.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 95.2ms\n",
      "Speed: 1.0ms preprocess, 95.2ms inference, 0.5ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 177.3ms\n",
      "Speed: 4.3ms preprocess, 177.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 137.8ms\n",
      "Speed: 1.4ms preprocess, 137.8ms inference, 0.5ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 224x640 (no detections), 137.7ms\n",
      "Speed: 3.2ms preprocess, 137.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 153.5ms\n",
      "Speed: 4.5ms preprocess, 153.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 288x640 (no detections), 161.5ms\n",
      "Speed: 2.7ms preprocess, 161.5ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "0: 384x640 1 matricula, 201.5ms\n",
      "Speed: 3.6ms preprocess, 201.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 224x640 (no detections), 180.9ms\n",
      "Speed: 3.5ms preprocess, 180.9ms inference, 1.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 1 matricula, 279.9ms\n",
      "Speed: 3.4ms preprocess, 279.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 115.7ms\n",
      "Speed: 2.0ms preprocess, 115.7ms inference, 1.3ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 272.0ms\n",
      "Speed: 2.5ms preprocess, 272.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 99.3ms\n",
      "Speed: 1.5ms preprocess, 99.3ms inference, 0.8ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 98.4ms\n",
      "Speed: 0.9ms preprocess, 98.4ms inference, 1.4ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 195.1ms\n",
      "Speed: 3.0ms preprocess, 195.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 122.6ms\n",
      "Speed: 1.5ms preprocess, 122.6ms inference, 2.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 210.0ms\n",
      "Speed: 4.2ms preprocess, 210.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 105.5ms\n",
      "Speed: 1.2ms preprocess, 105.5ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 193.3ms\n",
      "Speed: 3.1ms preprocess, 193.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 110.8ms\n",
      "Speed: 1.5ms preprocess, 110.8ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 200.1ms\n",
      "Speed: 5.2ms preprocess, 200.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 114.6ms\n",
      "Speed: 3.0ms preprocess, 114.6ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 201.5ms\n",
      "Speed: 3.3ms preprocess, 201.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 101.4ms\n",
      "Speed: 2.6ms preprocess, 101.4ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 223.7ms\n",
      "Speed: 5.4ms preprocess, 223.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 105.5ms\n",
      "Speed: 2.8ms preprocess, 105.5ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "\n",
      "0: 224x640 (no detections), 141.8ms\n",
      "Speed: 3.0ms preprocess, 141.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 216.4ms\n",
      "Speed: 4.0ms preprocess, 216.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 122.7ms\n",
      "Speed: 2.5ms preprocess, 122.7ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 137.1ms\n",
      "Speed: 3.4ms preprocess, 137.1ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 225.2ms\n",
      "Speed: 6.6ms preprocess, 225.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 128.9ms\n",
      "Speed: 3.5ms preprocess, 128.9ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 144.4ms\n",
      "Speed: 3.4ms preprocess, 144.4ms inference, 2.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 221.3ms\n",
      "Speed: 4.7ms preprocess, 221.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 136.5ms\n",
      "Speed: 2.8ms preprocess, 136.5ms inference, 1.7ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 160x640 (no detections), 100.4ms\n",
      "Speed: 1.5ms preprocess, 100.4ms inference, 2.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 239.4ms\n",
      "Speed: 4.6ms preprocess, 239.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 135.7ms\n",
      "Speed: 2.0ms preprocess, 135.7ms inference, 0.5ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 192x640 (no detections), 173.9ms\n",
      "Speed: 1.8ms preprocess, 173.9ms inference, 2.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 180.8ms\n",
      "Speed: 3.4ms preprocess, 180.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 114.7ms\n",
      "Speed: 3.0ms preprocess, 114.7ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 263.8ms\n",
      "Speed: 7.4ms preprocess, 263.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 114.5ms\n",
      "Speed: 2.2ms preprocess, 114.5ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 208.6ms\n",
      "Speed: 4.0ms preprocess, 208.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 114.9ms\n",
      "Speed: 2.6ms preprocess, 114.9ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 110.7ms\n",
      "Speed: 1.5ms preprocess, 110.7ms inference, 0.6ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 183.8ms\n",
      "Speed: 5.1ms preprocess, 183.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 123.4ms\n",
      "Speed: 2.5ms preprocess, 123.4ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 102.5ms\n",
      "Speed: 2.0ms preprocess, 102.5ms inference, 0.7ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 185.0ms\n",
      "Speed: 2.5ms preprocess, 185.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 111.4ms\n",
      "Speed: 1.9ms preprocess, 111.4ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 188.0ms\n",
      "Speed: 3.8ms preprocess, 188.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 99.8ms\n",
      "Speed: 1.7ms preprocess, 99.8ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 184.0ms\n",
      "Speed: 3.5ms preprocess, 184.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 98.5ms\n",
      "Speed: 1.4ms preprocess, 98.5ms inference, 0.8ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 185.6ms\n",
      "Speed: 3.9ms preprocess, 185.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 120.9ms\n",
      "Speed: 2.0ms preprocess, 120.9ms inference, 1.1ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 224x640 (no detections), 176.0ms\n",
      "Speed: 3.0ms preprocess, 176.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "0: 384x640 2 matriculas, 195.0ms\n",
      "Speed: 5.2ms preprocess, 195.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 139.5ms\n",
      "Speed: 3.0ms preprocess, 139.5ms inference, 2.6ms postprocess per image at shape (1, 3, 192, 640)\n",
      "\n",
      "0: 160x640 (no detections), 134.6ms\n",
      "Speed: 1.4ms preprocess, 134.6ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 229.1ms\n",
      "Speed: 7.5ms preprocess, 229.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 148.4ms\n",
      "Speed: 2.0ms preprocess, 148.4ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 188.9ms\n",
      "Speed: 5.7ms preprocess, 188.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 115.2ms\n",
      "Speed: 1.0ms preprocess, 115.2ms inference, 0.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 212.1ms\n",
      "Speed: 4.9ms preprocess, 212.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 132.8ms\n",
      "Speed: 1.7ms preprocess, 132.8ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 256x640 (no detections), 146.0ms\n",
      "Speed: 2.0ms preprocess, 146.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "0: 384x640 2 matriculas, 217.6ms\n",
      "Speed: 4.3ms preprocess, 217.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 114.4ms\n",
      "Speed: 2.0ms preprocess, 114.4ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 201.0ms\n",
      "Speed: 3.7ms preprocess, 201.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 126.7ms\n",
      "Speed: 2.2ms preprocess, 126.7ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 192x640 (no detections), 139.1ms\n",
      "Speed: 3.0ms preprocess, 139.1ms inference, 0.5ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 2 matriculas, 275.3ms\n",
      "Speed: 10.4ms preprocess, 275.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 116.3ms\n",
      "Speed: 1.4ms preprocess, 116.3ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "\n",
      "0: 160x640 (no detections), 116.1ms\n",
      "Speed: 1.5ms preprocess, 116.1ms inference, 1.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 2 matriculas, 213.6ms\n",
      "Speed: 4.2ms preprocess, 213.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 151.0ms\n",
      "Speed: 2.2ms preprocess, 151.0ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 240.8ms\n",
      "Speed: 7.7ms preprocess, 240.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 128.0ms\n",
      "Speed: 1.6ms preprocess, 128.0ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 222.3ms\n",
      "Speed: 8.9ms preprocess, 222.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 126.1ms\n",
      "Speed: 2.1ms preprocess, 126.1ms inference, 0.5ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 218.5ms\n",
      "Speed: 6.0ms preprocess, 218.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 192x640 (no detections), 131.3ms\n",
      "Speed: 2.6ms preprocess, 131.3ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 640)\n",
      "0: 384x640 1 matricula, 194.5ms\n",
      "Speed: 3.5ms preprocess, 194.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 160x640 (no detections), 143.6ms\n",
      "Speed: 1.3ms preprocess, 143.6ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 640)\n",
      "0: 384x640 1 matricula, 239.0ms\n",
      "Speed: 7.9ms preprocess, 239.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 128x640 (no detections), 114.3ms\n",
      "Speed: 3.1ms preprocess, 114.3ms inference, 2.0ms postprocess per image at shape (1, 3, 128, 640)\n",
      "0: 384x640 1 matricula, 237.5ms\n",
      "Speed: 6.1ms preprocess, 237.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 235.7ms\n",
      "Speed: 5.6ms preprocess, 235.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 253.8ms\n",
      "Speed: 6.5ms preprocess, 253.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 228.7ms\n",
      "Speed: 6.7ms preprocess, 228.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 243.2ms\n",
      "Speed: 6.0ms preprocess, 243.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 209.6ms\n",
      "Speed: 6.2ms preprocess, 209.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 246.2ms\n",
      "Speed: 4.9ms preprocess, 246.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 247.7ms\n",
      "Speed: 5.9ms preprocess, 247.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 230.0ms\n",
      "Speed: 5.5ms preprocess, 230.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 242.2ms\n",
      "Speed: 5.9ms preprocess, 242.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 202.2ms\n",
      "Speed: 6.8ms preprocess, 202.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 217.8ms\n",
      "Speed: 3.2ms preprocess, 217.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 225.1ms\n",
      "Speed: 4.0ms preprocess, 225.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 236.5ms\n",
      "Speed: 5.8ms preprocess, 236.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 248.8ms\n",
      "Speed: 5.0ms preprocess, 248.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 265.8ms\n",
      "Speed: 7.0ms preprocess, 265.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 233.5ms\n",
      "Speed: 6.5ms preprocess, 233.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 228.7ms\n",
      "Speed: 7.8ms preprocess, 228.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 232.3ms\n",
      "Speed: 5.6ms preprocess, 232.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 252.7ms\n",
      "Speed: 7.6ms preprocess, 252.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 225.2ms\n",
      "Speed: 4.6ms preprocess, 225.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 224.6ms\n",
      "Speed: 4.9ms preprocess, 224.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 237.2ms\n",
      "Speed: 6.5ms preprocess, 237.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 242.9ms\n",
      "Speed: 5.0ms preprocess, 242.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 235.0ms\n",
      "Speed: 5.8ms preprocess, 235.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 224.4ms\n",
      "Speed: 3.8ms preprocess, 224.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 239.8ms\n",
      "Speed: 6.2ms preprocess, 239.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 232.6ms\n",
      "Speed: 7.7ms preprocess, 232.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 218.0ms\n",
      "Speed: 4.4ms preprocess, 218.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 218.7ms\n",
      "Speed: 3.0ms preprocess, 218.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 241.8ms\n",
      "Speed: 5.6ms preprocess, 241.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 236.9ms\n",
      "Speed: 3.7ms preprocess, 236.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 263.1ms\n",
      "Speed: 5.9ms preprocess, 263.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 244.0ms\n",
      "Speed: 8.6ms preprocess, 244.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 232.5ms\n",
      "Speed: 6.0ms preprocess, 232.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 246.7ms\n",
      "Speed: 5.3ms preprocess, 246.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 223.2ms\n",
      "Speed: 3.0ms preprocess, 223.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 216.2ms\n",
      "Speed: 5.4ms preprocess, 216.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 202.2ms\n",
      "Speed: 3.7ms preprocess, 202.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 231.1ms\n",
      "Speed: 3.8ms preprocess, 231.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 227.6ms\n",
      "Speed: 5.2ms preprocess, 227.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 266.1ms\n",
      "Speed: 6.6ms preprocess, 266.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import easyocr\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Carga de los modelos\n",
    "# Carga del modelo YOLO\n",
    "car_model = YOLO('yolov8n.pt')\n",
    "\n",
    "license_plate_model = YOLO('best.pt')\n",
    "\n",
    "# Captura de video desde un archivo\n",
    "cap = cv2.VideoCapture('prueba.mp4')  # Reemplaza 'tu_video.mp4' con el nombre de tu archivo de video\n",
    "\n",
    "# Inicializa el lector de OCR de EasyOCR\n",
    "reader = easyocr.Reader(lang_list=['en'])  # Ajusta los idiomas según tus necesidades\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Realiza detección de vehículos en el frame\n",
    "    car_results = license_plate_model(frame, stream=True)\n",
    "\n",
    "    for r in car_results:\n",
    "        car_boxes = r.boxes\n",
    "\n",
    "        for car_box in car_boxes:\n",
    "            x1, y1, x2, y2 = car_box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Dibuja el bounding box del vehículo\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "            # Realiza detección de matrículas en el área del vehículo\n",
    "            license_plate_crop = frame[y1:y2, x1:x2]\n",
    "            license_plate_results = license_plate_model(license_plate_crop, stream=True)\n",
    "\n",
    "            for lp_result in license_plate_results:\n",
    "                lp_boxes = lp_result.boxes\n",
    "\n",
    "                for lp_box in lp_boxes:\n",
    "                    x1_lp, y1_lp, x2_lp, y2_lp = lp_box.xyxy[0]\n",
    "                    x1_lp, y1_lp, x2_lp, y2_lp = int(x1_lp), int(y1_lp), int(x2_lp), int(y2_lp)\n",
    "\n",
    "                    # Dibuja el bounding box de la matrícula\n",
    "                    cv2.rectangle(frame, (x1 + x1_lp, y1 + y1_lp), (x1 + x2_lp, y1 + y2_lp), (0, 0, 255), 2)\n",
    "\n",
    "                    # Realiza OCR en la matrícula con EasyOCR\n",
    "                    license_plate_crop = frame[y1 + y1_lp:y1 + y2_lp, x1 + x1_lp:x1 + x2_lp]\n",
    "                    gray_plate = cv2.cvtColor(license_plate_crop, cv2.COLOR_BGR2GRAY)\n",
    "                    results = reader.readtext(gray_plate)\n",
    "\n",
    "                    if results:\n",
    "                        license_plate_text = results[0][1]\n",
    "\n",
    "                        # Muestra el texto de la matrícula en la ventana\n",
    "                        cv2.putText(frame, license_plate_text, (x1 + x1_lp, y1 + y1_lp - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "    # Muestra el frame con las detecciones en una ventana\n",
    "    cv2.imshow('Video con Detecciones', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import easyocr\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 256x640 1 matricula, 357.0ms\n",
      "Speed: 54.8ms preprocess, 357.0ms inference, 27.8ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 1 matricula, 123.2ms\n",
      "Speed: 1.9ms preprocess, 123.2ms inference, 4.1ms postprocess per image at shape (1, 3, 256, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'matricula'}\n",
      "orig_img: array([[[153, 147, 147],\n",
      "        [177, 170, 170],\n",
      "        [192, 185, 185],\n",
      "        ...,\n",
      "        [ 58,  56,  54],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[150, 145, 144],\n",
      "        [160, 153, 153],\n",
      "        [211, 204, 204],\n",
      "        ...,\n",
      "        [ 72,  69,  66],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[154, 149, 148],\n",
      "        [137, 130, 130],\n",
      "        [187, 180, 180],\n",
      "        ...,\n",
      "        [133, 130, 127],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 29,  28,  25],\n",
      "        [ 27,  26,  23],\n",
      "        [ 26,  25,  22],\n",
      "        ...,\n",
      "        [194, 192, 191],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[ 25,  24,  21],\n",
      "        [ 25,  24,  21],\n",
      "        [ 25,  24,  21],\n",
      "        ...,\n",
      "        [195, 193, 192],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[ 24,  23,  20],\n",
      "        [ 24,  23,  20],\n",
      "        [ 24,  23,  20],\n",
      "        ...,\n",
      "        [195, 193, 192],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8)\n",
      "orig_shape: (248, 636)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: None\n",
      "speed: {'preprocess': 1.9316673278808594, 'inference': 123.20446968078613, 'postprocess': 4.117250442504883}]\n",
      "Confidence ---> 0.3\n",
      "Class name --> matricula\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"matricula\"]\n",
    "\n",
    "# Lee la imagen desde un archivo\n",
    "img = cv2.imread('mssulove.png')\n",
    "\n",
    "# Perform inference on the image\n",
    "results = model(img) \n",
    "print(model(img))\n",
    "# Para cada detección\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "\n",
    "    for box in boxes:\n",
    "        # Contenedor\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "\n",
    "        # Confianza\n",
    "        confidence = math.ceil((box.conf[0]*100))/100\n",
    "        print(\"Confidence --->\",confidence)\n",
    "\n",
    "        # Clase\n",
    "        cls = int(box.cls[0])\n",
    "        print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "        # Convierte identificador numérico de clase a un color RGB\n",
    "        escala = int((cls / len(classNames)) * 255 * 3)\n",
    "        if escala >= 255*2:\n",
    "            R = 255\n",
    "            G = 255\n",
    "            B = escala - 255*2\n",
    "        else:\n",
    "            if escala >= 255:\n",
    "                R = 255\n",
    "                G = escala - 255\n",
    "                B = 0\n",
    "            else:\n",
    "                R = escala\n",
    "                G = 0\n",
    "                B = 0\n",
    "\n",
    "        # Dibuja el contenedor y clase\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 1)\n",
    "        cv2.putText(img, classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "# Muestra la imagen con las detecciones\n",
    "cv2.imshow('Imagen con Detecciones', img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Destruye la ventana\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba Eric OCR 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "\n",
      "0: 256x640 1 matricula, 92.1ms\n",
      "Speed: 3.6ms preprocess, 92.1ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "\n",
      "0: 256x640 1 matricula, 86.5ms\n",
      "Speed: 2.4ms preprocess, 86.5ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'matricula'}\n",
      "orig_img: array([[[153, 147, 147],\n",
      "        [177, 170, 170],\n",
      "        [192, 185, 185],\n",
      "        ...,\n",
      "        [ 58,  56,  54],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[150, 145, 144],\n",
      "        [160, 153, 153],\n",
      "        [211, 204, 204],\n",
      "        ...,\n",
      "        [ 72,  69,  66],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[154, 149, 148],\n",
      "        [137, 130, 130],\n",
      "        [187, 180, 180],\n",
      "        ...,\n",
      "        [133, 130, 127],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 29,  28,  25],\n",
      "        [ 27,  26,  23],\n",
      "        [ 26,  25,  22],\n",
      "        ...,\n",
      "        [194, 192, 191],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[ 25,  24,  21],\n",
      "        [ 25,  24,  21],\n",
      "        [ 25,  24,  21],\n",
      "        ...,\n",
      "        [195, 193, 192],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[ 24,  23,  20],\n",
      "        [ 24,  23,  20],\n",
      "        [ 24,  23,  20],\n",
      "        ...,\n",
      "        [195, 193, 192],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8)\n",
      "orig_shape: (248, 636)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: None\n",
      "speed: {'preprocess': 2.44140625, 'inference': 86.48824691772461, 'postprocess': 0.9970664978027344}]\n",
      "Confidence ---> 0.3\n",
      "Class name --> matricula\n",
      "resultados:\n",
      "[([[0, 36], [226, 36], [226, 112], [0, 112]], '4716 HHS', 0.31653263454835023)]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"matricula\"]\n",
    "\n",
    "# Lee la imagen desde un archivo\n",
    "img = cv2.imread('mssulove.png')\n",
    "\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "# Perform inference on the image\n",
    "results = model(img) \n",
    "print(model(img))\n",
    "# Para cada detección\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "\n",
    "    for box in boxes:\n",
    "        # Contenedor\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "\n",
    "        # Confianza\n",
    "        confidence = math.ceil((box.conf[0]*100))/100\n",
    "        print(\"Confidence --->\",confidence)\n",
    "\n",
    "        # Clase\n",
    "        cls = int(box.cls[0])\n",
    "        print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "        # Convierte identificador numérico de clase a un color RGB\n",
    "        escala = int((cls / len(classNames)) * 255 * 3)\n",
    "        if escala >= 255*2:\n",
    "            R = 255\n",
    "            G = 255\n",
    "            B = escala - 255*2\n",
    "        else:\n",
    "            if escala >= 255:\n",
    "                R = 255\n",
    "                G = escala - 255\n",
    "                B = 0\n",
    "            else:\n",
    "                R = escala\n",
    "                G = 0\n",
    "                B = 0\n",
    "        # Dibuja el contenedor y clase\n",
    "        cv2.rectangle(img, (x1+7, y1), (x2+7, y2), (R, G, B), 2)\n",
    "\n",
    "        # Realiza OCR en la matrícula con EasyOCR\n",
    "        license_plate_crop = img[y1-5:y2+5, x1+10:x2+10]\n",
    "        # Redimensiona la región de la matrícula a un tamaño deseado\n",
    "        new_width = 250  # Define el ancho deseado\n",
    "        new_height = 150  # Define la altura deseada\n",
    "        license_plate_crop_resized = cv2.resize(license_plate_crop, (new_width, new_height))\n",
    "\n",
    "        # Procesa la región de la matrícula redimensionada\n",
    "        license_plate_crop_gray = cv2.cvtColor(license_plate_crop_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Ajusta los parámetros de umbralización adaptativa para hacer las letras negras más claras\n",
    "        block_size = 21  # Tamaño del bloque para la umbralización adaptativa (debe ser impar)\n",
    "        C = 3  # Constante que se resta del valor promedio (puede ajustarse)\n",
    "\n",
    "        license_plate_crop_thresh = cv2.adaptiveThreshold(license_plate_crop_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, C)\n",
    "\n",
    "        # Realiza OCR en la región de la matrícula redimensionada\n",
    "        results = reader.readtext(license_plate_crop_thresh)\n",
    "\n",
    "         # Verifica license_plate_crop\n",
    "        \n",
    "        cv2.imshow('License Plate Crop', license_plate_crop_thresh)\n",
    "        print(\"resultados:\")\n",
    "        print(results)\n",
    "        print(\"----------------------\")\n",
    "\n",
    "        # Para cada resultado de OCR\n",
    "        for (bbox, text, prob) in results:\n",
    "            # Dibuja el texto reconocido\n",
    "            (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "            cv2.rectangle(license_plate_crop, (x1 + int(top_left[0]), y1 + int(top_left[1])),\n",
    "                        (x1 + int(bottom_right[0]), y1 + int(bottom_right[1])), (0, 0, 255), 2)\n",
    "            cv2.putText(img, text, (x1 + int(top_left[0]), y1 + int(top_left[1]) - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "# Muestra la imagen con las detecciones\n",
    "cv2.imshow('Imagen con Detecciones', img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Destruye la ventana\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba Eric OCR 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import easyocr\n",
    "from ultralytics import YOLO\n",
    "import string\n",
    "# Mapping dictionaries for character conversion\n",
    "dict_char_to_int = {'O': '0',\n",
    "                    'I': '1',\n",
    "                    'J': '3',\n",
    "                    'A': '4',\n",
    "                    'G': '6',\n",
    "                    'S': '5'}\n",
    "\n",
    "dict_int_to_char = {'0': 'O',\n",
    "                    '1': 'I',\n",
    "                    '3': 'J',\n",
    "                    '4': 'A',\n",
    "                    '6': 'G',\n",
    "                    '5': 'S'}\n",
    "\n",
    "\n",
    "def license_complies_format(text):\n",
    "    \"\"\"\n",
    "    Check if the license plate text complies with the required format.\n",
    "\n",
    "    Args:\n",
    "        text (str): License plate text.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the license plate complies with the format, False otherwise.\n",
    "    \"\"\"\n",
    "    if len(text) != 7:\n",
    "        return False\n",
    "\n",
    "    if (text[0] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[0] in dict_char_to_int.keys()) and \\\n",
    "       (text[1] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[1] in dict_char_to_int.keys()) and \\\n",
    "       (text[2] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[2] in dict_char_to_int.keys()) and \\\n",
    "       (text[3] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[3] in dict_char_to_int.keys()) and \\\n",
    "       (text[4] in string.ascii_uppercase or text[4] in dict_int_to_char.keys()) and \\\n",
    "       (text[5] in string.ascii_uppercase or text[5] in dict_int_to_char.keys()) and \\\n",
    "       (text[6] in string.ascii_uppercase or text[6] in dict_int_to_char.keys()):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def format_license(text):\n",
    "    \"\"\"\n",
    "    Format the license plate text by converting characters using the mapping dictionaries.\n",
    "\n",
    "    Args:\n",
    "        text (str): License plate text.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted license plate text.\n",
    "    \"\"\"\n",
    "    license_plate_ = ''\n",
    "    mapping = {0: dict_int_to_char, 1: dict_int_to_char, 4: dict_int_to_char, 5: dict_int_to_char, 6: dict_int_to_char,\n",
    "               2: dict_char_to_int, 3: dict_char_to_int}\n",
    "    for j in [0, 1, 2, 3, 4, 5, 6]:\n",
    "        if text[j] in mapping[j].keys():\n",
    "            license_plate_ += mapping[j][text[j]]\n",
    "        else:\n",
    "            license_plate_ += text[j]\n",
    "\n",
    "    return license_plate_\n",
    "\n",
    "\n",
    "def read_license_plate(license_plate_crop):\n",
    "    \"\"\"\n",
    "    Read the license plate text from the given cropped image.\n",
    "\n",
    "    Args:\n",
    "        license_plate_crop (PIL.Image.Image): Cropped image containing the license plate.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing the formatted license plate text and its confidence score.\n",
    "    \"\"\"\n",
    "\n",
    "    detections = reader.readtext(license_plate_crop)\n",
    "\n",
    "    for detection in detections:\n",
    "        bbox, text, score = detection\n",
    "\n",
    "        text = text.upper().replace(' ', '')\n",
    "\n",
    "        if license_complies_format(text):\n",
    "            return format_license(text), score\n",
    "\n",
    "    return None, None\n",
    "\n",
    "# Carga de los modelos\n",
    "# Carga del modelo YOLO\n",
    "car_model = YOLO('yolov8n.pt')\n",
    "\n",
    "license_plate_model = YOLO('best.pt')\n",
    "\n",
    "# Captura de video desde un archivo\n",
    "cap = cv2.VideoCapture('prueba.mp4')  # Reemplaza 'prueba.mp4' con el nombre de tu archivo de video\n",
    "\n",
    "# Inicializa el lector de OCR de EasyOCR\n",
    "reader = easyocr.Reader(lang_list=['en'])  # Ajusta los idiomas según tus necesidades\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Realiza detección de vehículos en el frame\n",
    "    car_results = license_plate_model(frame, stream=True)\n",
    "\n",
    "    for r in car_results:\n",
    "        car_boxes = r.boxes\n",
    "\n",
    "        for car_box in car_boxes:\n",
    "            x1, y1, x2, y2 = car_box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Dibuja el bounding box del vehículo\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "            # Realiza detección de matrículas en el área del vehículo\n",
    "            license_plate_crop = frame[y1-5:y2+5, x1:x2+10]\n",
    "            license_plate_results = license_plate_model(license_plate_crop, stream=True)\n",
    "\n",
    "            # Redimensiona la región de la matrícula a un tamaño deseado\n",
    "            new_width = 250  # Define el ancho deseado\n",
    "            new_height = 150  # Define la altura deseada\n",
    "            license_plate_crop_resized = cv2.resize(license_plate_crop, (new_width, new_height))\n",
    "\n",
    "\n",
    "            # read license plate number\n",
    "            license_plate_text, license_plate_text_score = read_license_plate(license_plate_crop_thresh)\n",
    "\n",
    "            # Verifica license_plate_crop\n",
    "            \n",
    "            cv2.imshow('License Plate Crop', license_plate_crop_thresh)\n",
    "            print(\"resultados:\")\n",
    "            print(results)\n",
    "            print(\"----------------------\")\n",
    "\n",
    "            # Para cada resultado de OCR\n",
    "            for (bbox, text, prob) in results:\n",
    "                print(\"LLEGAMOS\")\n",
    "                print()\n",
    "                print(\"----------------------\")\n",
    "                # Dibuja el texto reconocido\n",
    "                cv2.putText(frame, text, (x1 + int(top_left[0]), y1 + int(top_left[1]) - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "    # Muestra el frame con las detecciones en una ventana\n",
    "    cv2.imshow('Video con Detecciones', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba Eric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 11 cars, 2 motorcycles, 2 buss, 3 trucks, 2 traffic lights, 297.4ms\n",
      "Speed: 37.0ms preprocess, 297.4ms inference, 21.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 134.3ms\n",
      "Speed: 2.3ms preprocess, 134.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 11 cars, 2 motorcycles, 2 buss, 3 trucks, 3 traffic lights, 121.8ms\n",
      "Speed: 4.0ms preprocess, 121.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 127.9ms\n",
      "Speed: 2.8ms preprocess, 127.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 11 cars, 2 motorcycles, 2 buss, 2 trucks, 3 traffic lights, 145.4ms\n",
      "Speed: 2.0ms preprocess, 145.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.2ms\n",
      "Speed: 3.0ms preprocess, 126.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 12 cars, 2 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 137.2ms\n",
      "Speed: 2.5ms preprocess, 137.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 121.7ms\n",
      "Speed: 3.1ms preprocess, 121.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 7 cars, 2 motorcycles, 2 buss, 2 trucks, 3 traffic lights, 134.0ms\n",
      "Speed: 2.0ms preprocess, 134.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.5ms\n",
      "Speed: 2.0ms preprocess, 121.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 8 cars, 2 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 135.0ms\n",
      "Speed: 3.5ms preprocess, 135.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 128.4ms\n",
      "Speed: 3.0ms preprocess, 128.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 11 cars, 2 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 135.2ms\n",
      "Speed: 2.0ms preprocess, 135.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 118.6ms\n",
      "Speed: 1.0ms preprocess, 118.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 11 cars, 2 motorcycles, 1 bus, 2 trucks, 2 traffic lights, 132.3ms\n",
      "Speed: 3.1ms preprocess, 132.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 119.5ms\n",
      "Speed: 2.0ms preprocess, 119.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 10 cars, 2 motorcycles, 1 bus, 2 trucks, 2 traffic lights, 124.5ms\n",
      "Speed: 2.0ms preprocess, 124.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 147.2ms\n",
      "Speed: 1.9ms preprocess, 147.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 11 cars, 2 motorcycles, 2 buss, 2 trucks, 3 traffic lights, 142.5ms\n",
      "Speed: 3.4ms preprocess, 142.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 118.4ms\n",
      "Speed: 3.0ms preprocess, 118.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 11 cars, 2 motorcycles, 1 bus, 3 trucks, 3 traffic lights, 130.5ms\n",
      "Speed: 4.1ms preprocess, 130.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 120.0ms\n",
      "Speed: 2.2ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 13 cars, 2 motorcycles, 1 bus, 3 trucks, 3 traffic lights, 130.5ms\n",
      "Speed: 3.8ms preprocess, 130.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 120.8ms\n",
      "Speed: 3.3ms preprocess, 120.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 14 cars, 2 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 133.1ms\n",
      "Speed: 1.5ms preprocess, 133.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 125.2ms\n",
      "Speed: 2.2ms preprocess, 125.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 11 cars, 2 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 126.9ms\n",
      "Speed: 2.0ms preprocess, 126.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 123.4ms\n",
      "Speed: 2.7ms preprocess, 123.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11 cars, 2 motorcycles, 1 bus, 3 trucks, 3 traffic lights, 126.1ms\n",
      "Speed: 2.0ms preprocess, 126.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 132.9ms\n",
      "Speed: 2.0ms preprocess, 132.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 10 cars, 2 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 133.9ms\n",
      "Speed: 2.0ms preprocess, 133.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 139.0ms\n",
      "Speed: 2.0ms preprocess, 139.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 14 cars, 3 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 128.4ms\n",
      "Speed: 2.8ms preprocess, 128.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 132.0ms\n",
      "Speed: 3.5ms preprocess, 132.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 12 cars, 3 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 122.5ms\n",
      "Speed: 2.5ms preprocess, 122.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.2ms\n",
      "Speed: 2.0ms preprocess, 121.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 14 cars, 2 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 126.4ms\n",
      "Speed: 3.1ms preprocess, 126.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 125.7ms\n",
      "Speed: 2.4ms preprocess, 125.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 13 cars, 3 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 125.2ms\n",
      "Speed: 2.9ms preprocess, 125.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 117.2ms\n",
      "Speed: 2.5ms preprocess, 117.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 12 cars, 3 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 132.8ms\n",
      "Speed: 3.0ms preprocess, 132.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 129.2ms\n",
      "Speed: 2.3ms preprocess, 129.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 14 cars, 2 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 136.4ms\n",
      "Speed: 2.0ms preprocess, 136.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 147.7ms\n",
      "Speed: 3.0ms preprocess, 147.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 12 cars, 2 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 155.8ms\n",
      "Speed: 3.0ms preprocess, 155.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 143.5ms\n",
      "Speed: 3.1ms preprocess, 143.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 13 cars, 2 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 138.6ms\n",
      "Speed: 3.1ms preprocess, 138.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 139.0ms\n",
      "Speed: 2.9ms preprocess, 139.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15 cars, 2 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 126.0ms\n",
      "Speed: 2.0ms preprocess, 126.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 135.2ms\n",
      "Speed: 3.6ms preprocess, 135.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 14 cars, 3 motorcycles, 2 buss, 2 trucks, 3 traffic lights, 159.2ms\n",
      "Speed: 2.0ms preprocess, 159.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 125.9ms\n",
      "Speed: 3.9ms preprocess, 125.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 13 cars, 3 motorcycles, 2 buss, 2 trucks, 3 traffic lights, 137.8ms\n",
      "Speed: 1.0ms preprocess, 137.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 146.0ms\n",
      "Speed: 3.0ms preprocess, 146.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 15 cars, 3 motorcycles, 2 buss, 2 trucks, 3 traffic lights, 136.3ms\n",
      "Speed: 1.9ms preprocess, 136.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 130.4ms\n",
      "Speed: 2.0ms preprocess, 130.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 14 cars, 2 motorcycles, 2 buss, 2 trucks, 3 traffic lights, 137.5ms\n",
      "Speed: 3.3ms preprocess, 137.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.8ms\n",
      "Speed: 5.7ms preprocess, 123.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 12 cars, 3 motorcycles, 1 bus, 2 trucks, 2 traffic lights, 126.5ms\n",
      "Speed: 2.0ms preprocess, 126.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 127.8ms\n",
      "Speed: 2.4ms preprocess, 127.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 16 cars, 3 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 130.3ms\n",
      "Speed: 3.8ms preprocess, 130.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 124.4ms\n",
      "Speed: 3.0ms preprocess, 124.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16 cars, 4 motorcycles, 2 buss, 2 trucks, 3 traffic lights, 125.9ms\n",
      "Speed: 3.4ms preprocess, 125.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 131.7ms\n",
      "Speed: 2.0ms preprocess, 131.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15 cars, 2 motorcycles, 2 buss, 2 trucks, 3 traffic lights, 138.7ms\n",
      "Speed: 2.0ms preprocess, 138.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 127.9ms\n",
      "Speed: 2.8ms preprocess, 127.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 14 cars, 3 motorcycles, 3 buss, 2 trucks, 4 traffic lights, 133.7ms\n",
      "Speed: 2.6ms preprocess, 133.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 127.4ms\n",
      "Speed: 2.3ms preprocess, 127.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 14 cars, 3 motorcycles, 2 buss, 2 trucks, 3 traffic lights, 131.4ms\n",
      "Speed: 2.0ms preprocess, 131.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 124.8ms\n",
      "Speed: 2.0ms preprocess, 124.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 14 cars, 3 motorcycles, 2 buss, 2 trucks, 3 traffic lights, 132.5ms\n",
      "Speed: 3.2ms preprocess, 132.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 118.9ms\n",
      "Speed: 3.7ms preprocess, 118.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 14 cars, 3 motorcycles, 2 buss, 2 trucks, 3 traffic lights, 138.9ms\n",
      "Speed: 4.0ms preprocess, 138.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 133.2ms\n",
      "Speed: 3.3ms preprocess, 133.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15 cars, 2 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 125.6ms\n",
      "Speed: 4.7ms preprocess, 125.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 129.8ms\n",
      "Speed: 3.0ms preprocess, 129.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14 cars, 2 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 132.5ms\n",
      "Speed: 3.6ms preprocess, 132.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 138.1ms\n",
      "Speed: 2.3ms preprocess, 138.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14 cars, 2 motorcycles, 1 bus, 1 truck, 5 traffic lights, 131.4ms\n",
      "Speed: 4.8ms preprocess, 131.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 183.5ms\n",
      "Speed: 3.3ms preprocess, 183.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15 cars, 2 motorcycles, 2 buss, 2 trucks, 3 traffic lights, 129.4ms\n",
      "Speed: 3.0ms preprocess, 129.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.2ms\n",
      "Speed: 2.0ms preprocess, 122.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 16 cars, 2 motorcycles, 3 buss, 1 truck, 3 traffic lights, 137.1ms\n",
      "Speed: 2.0ms preprocess, 137.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 124.4ms\n",
      "Speed: 2.6ms preprocess, 124.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 12 cars, 2 motorcycles, 3 buss, 2 trucks, 3 traffic lights, 128.4ms\n",
      "Speed: 2.0ms preprocess, 128.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 128.1ms\n",
      "Speed: 3.4ms preprocess, 128.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 13 cars, 3 motorcycles, 2 buss, 2 trucks, 3 traffic lights, 131.4ms\n",
      "Speed: 3.0ms preprocess, 131.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 129.7ms\n",
      "Speed: 3.0ms preprocess, 129.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 13 cars, 2 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 137.3ms\n",
      "Speed: 2.6ms preprocess, 137.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 131.1ms\n",
      "Speed: 2.5ms preprocess, 131.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 15 cars, 2 motorcycles, 1 bus, 2 trucks, 4 traffic lights, 144.1ms\n",
      "Speed: 2.0ms preprocess, 144.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 147.5ms\n",
      "Speed: 2.2ms preprocess, 147.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 14 cars, 1 motorcycle, 2 buss, 3 trucks, 3 traffic lights, 129.8ms\n",
      "Speed: 2.9ms preprocess, 129.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 131.0ms\n",
      "Speed: 2.8ms preprocess, 131.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 13 cars, 1 motorcycle, 4 buss, 2 trucks, 3 traffic lights, 143.7ms\n",
      "Speed: 2.8ms preprocess, 143.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.4ms\n",
      "Speed: 2.1ms preprocess, 122.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 13 cars, 1 motorcycle, 2 buss, 2 trucks, 3 traffic lights, 133.7ms\n",
      "Speed: 2.8ms preprocess, 133.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.1ms\n",
      "Speed: 2.5ms preprocess, 121.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14 cars, 1 motorcycle, 2 buss, 3 trucks, 3 traffic lights, 127.2ms\n",
      "Speed: 3.8ms preprocess, 127.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.4ms\n",
      "Speed: 4.0ms preprocess, 123.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14 cars, 1 motorcycle, 2 buss, 2 trucks, 3 traffic lights, 131.7ms\n",
      "Speed: 2.0ms preprocess, 131.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.1ms\n",
      "Speed: 4.2ms preprocess, 122.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14 cars, 1 motorcycle, 1 bus, 3 trucks, 2 traffic lights, 125.4ms\n",
      "Speed: 2.0ms preprocess, 125.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.8ms\n",
      "Speed: 2.0ms preprocess, 122.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14 cars, 1 motorcycle, 2 buss, 2 trucks, 4 traffic lights, 132.3ms\n",
      "Speed: 3.0ms preprocess, 132.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 172.2ms\n",
      "Speed: 3.7ms preprocess, 172.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14 cars, 1 motorcycle, 1 bus, 2 trucks, 4 traffic lights, 161.5ms\n",
      "Speed: 2.0ms preprocess, 161.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 152.8ms\n",
      "Speed: 3.6ms preprocess, 152.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 15 cars, 1 motorcycle, 1 bus, 2 trucks, 4 traffic lights, 136.8ms\n",
      "Speed: 3.0ms preprocess, 136.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 119.8ms\n",
      "Speed: 2.0ms preprocess, 119.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15 cars, 1 motorcycle, 2 trucks, 4 traffic lights, 139.5ms\n",
      "Speed: 2.9ms preprocess, 139.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 124.4ms\n",
      "Speed: 2.2ms preprocess, 124.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 13 cars, 3 motorcycles, 2 trucks, 4 traffic lights, 147.2ms\n",
      "Speed: 2.7ms preprocess, 147.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 147.1ms\n",
      "Speed: 4.1ms preprocess, 147.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 12 cars, 1 motorcycle, 2 trucks, 3 traffic lights, 161.4ms\n",
      "Speed: 4.3ms preprocess, 161.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 149.2ms\n",
      "Speed: 3.5ms preprocess, 149.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14 cars, 1 motorcycle, 2 trucks, 3 traffic lights, 148.8ms\n",
      "Speed: 2.5ms preprocess, 148.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 154.4ms\n",
      "Speed: 4.6ms preprocess, 154.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 13 cars, 1 motorcycle, 2 trucks, 4 traffic lights, 138.4ms\n",
      "Speed: 2.8ms preprocess, 138.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 125.1ms\n",
      "Speed: 3.5ms preprocess, 125.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14 cars, 1 motorcycle, 2 trucks, 4 traffic lights, 129.7ms\n",
      "Speed: 1.5ms preprocess, 129.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 130.4ms\n",
      "Speed: 3.0ms preprocess, 130.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 13 cars, 1 motorcycle, 2 trucks, 3 traffic lights, 144.9ms\n",
      "Speed: 2.0ms preprocess, 144.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 131.3ms\n",
      "Speed: 3.0ms preprocess, 131.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 13 cars, 1 motorcycle, 2 trucks, 4 traffic lights, 135.7ms\n",
      "Speed: 2.4ms preprocess, 135.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 144.0ms\n",
      "Speed: 3.8ms preprocess, 144.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11 cars, 1 motorcycle, 2 trucks, 3 traffic lights, 1 stop sign, 145.5ms\n",
      "Speed: 2.4ms preprocess, 145.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 148.0ms\n",
      "Speed: 4.2ms preprocess, 148.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13 cars, 2 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 1 stop sign, 154.9ms\n",
      "Speed: 2.0ms preprocess, 154.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 146.0ms\n",
      "Speed: 2.0ms preprocess, 146.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16 cars, 1 motorcycle, 2 trucks, 4 traffic lights, 144.9ms\n",
      "Speed: 2.9ms preprocess, 144.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 143.5ms\n",
      "Speed: 5.1ms preprocess, 143.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 17 cars, 1 motorcycle, 2 trucks, 2 traffic lights, 134.4ms\n",
      "Speed: 2.5ms preprocess, 134.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 144.0ms\n",
      "Speed: 2.0ms preprocess, 144.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16 cars, 1 motorcycle, 1 bus, 2 trucks, 3 traffic lights, 135.6ms\n",
      "Speed: 2.0ms preprocess, 135.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 161.6ms\n",
      "Speed: 2.0ms preprocess, 161.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 18 cars, 1 motorcycle, 2 trucks, 2 traffic lights, 181.2ms\n",
      "Speed: 4.1ms preprocess, 181.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 139.2ms\n",
      "Speed: 5.1ms preprocess, 139.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 19 cars, 1 bus, 2 trucks, 4 traffic lights, 140.2ms\n",
      "Speed: 2.8ms preprocess, 140.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 133.1ms\n",
      "Speed: 3.1ms preprocess, 133.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 cars, 1 bus, 2 trucks, 3 traffic lights, 1 suitcase, 136.6ms\n",
      "Speed: 3.6ms preprocess, 136.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.9ms\n",
      "Speed: 2.6ms preprocess, 126.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 17 cars, 1 bus, 2 trucks, 3 traffic lights, 1 suitcase, 127.4ms\n",
      "Speed: 1.7ms preprocess, 127.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 130.5ms\n",
      "Speed: 3.1ms preprocess, 130.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 17 cars, 1 motorcycle, 1 bus, 2 trucks, 3 traffic lights, 132.6ms\n",
      "Speed: 1.5ms preprocess, 132.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.3ms\n",
      "Speed: 2.0ms preprocess, 126.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 20 cars, 2 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 133.2ms\n",
      "Speed: 3.0ms preprocess, 133.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.4ms\n",
      "Speed: 2.0ms preprocess, 121.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22 cars, 1 motorcycle, 1 bus, 2 trucks, 3 traffic lights, 129.8ms\n",
      "Speed: 3.0ms preprocess, 129.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 127.1ms\n",
      "Speed: 3.3ms preprocess, 127.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 19 cars, 1 motorcycle, 1 bus, 2 trucks, 4 traffic lights, 128.9ms\n",
      "Speed: 2.8ms preprocess, 128.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 118.4ms\n",
      "Speed: 2.1ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 18 cars, 1 bus, 2 trucks, 4 traffic lights, 126.8ms\n",
      "Speed: 3.2ms preprocess, 126.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.8ms\n",
      "Speed: 3.9ms preprocess, 122.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 21 cars, 1 motorcycle, 1 bus, 2 trucks, 3 traffic lights, 131.7ms\n",
      "Speed: 3.2ms preprocess, 131.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 118.8ms\n",
      "Speed: 3.0ms preprocess, 118.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 21 cars, 1 bus, 2 trucks, 3 traffic lights, 145.8ms\n",
      "Speed: 2.0ms preprocess, 145.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.8ms\n",
      "Speed: 2.0ms preprocess, 121.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 21 cars, 1 bus, 2 trucks, 3 traffic lights, 131.4ms\n",
      "Speed: 2.0ms preprocess, 131.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.7ms\n",
      "Speed: 3.1ms preprocess, 121.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20 cars, 1 bus, 2 trucks, 3 traffic lights, 134.4ms\n",
      "Speed: 3.4ms preprocess, 134.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.0ms\n",
      "Speed: 2.7ms preprocess, 123.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 20 cars, 1 bus, 2 trucks, 3 traffic lights, 134.8ms\n",
      "Speed: 3.4ms preprocess, 134.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 125.8ms\n",
      "Speed: 1.5ms preprocess, 125.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 21 cars, 1 bus, 2 trucks, 2 traffic lights, 132.3ms\n",
      "Speed: 2.3ms preprocess, 132.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 118.7ms\n",
      "Speed: 2.0ms preprocess, 118.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 21 cars, 2 trucks, 3 traffic lights, 131.5ms\n",
      "Speed: 2.8ms preprocess, 131.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.3ms\n",
      "Speed: 3.8ms preprocess, 123.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20 cars, 2 trucks, 3 traffic lights, 134.2ms\n",
      "Speed: 3.0ms preprocess, 134.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.8ms\n",
      "Speed: 3.5ms preprocess, 122.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 21 cars, 2 trucks, 3 traffic lights, 129.8ms\n",
      "Speed: 3.7ms preprocess, 129.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 120.7ms\n",
      "Speed: 4.0ms preprocess, 120.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 19 cars, 2 trucks, 3 traffic lights, 126.4ms\n",
      "Speed: 2.0ms preprocess, 126.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 125.8ms\n",
      "Speed: 1.3ms preprocess, 125.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 18 cars, 2 trucks, 3 traffic lights, 130.7ms\n",
      "Speed: 2.0ms preprocess, 130.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.1ms\n",
      "Speed: 2.5ms preprocess, 126.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 21 cars, 2 trucks, 3 traffic lights, 130.2ms\n",
      "Speed: 2.0ms preprocess, 130.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.1ms\n",
      "Speed: 3.7ms preprocess, 121.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 23 cars, 1 bus, 2 trucks, 3 traffic lights, 189.3ms\n",
      "Speed: 2.0ms preprocess, 189.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 125.0ms\n",
      "Speed: 2.9ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 19 cars, 1 bus, 2 trucks, 3 traffic lights, 135.9ms\n",
      "Speed: 2.0ms preprocess, 135.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 130.5ms\n",
      "Speed: 3.0ms preprocess, 130.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 20 cars, 1 bus, 2 trucks, 3 traffic lights, 135.4ms\n",
      "Speed: 2.8ms preprocess, 135.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.3ms\n",
      "Speed: 3.1ms preprocess, 121.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 19 cars, 2 trucks, 3 traffic lights, 133.6ms\n",
      "Speed: 2.7ms preprocess, 133.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 128.3ms\n",
      "Speed: 3.4ms preprocess, 128.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 21 cars, 2 trucks, 3 traffic lights, 131.3ms\n",
      "Speed: 2.0ms preprocess, 131.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 124.4ms\n",
      "Speed: 1.0ms preprocess, 124.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22 cars, 2 trucks, 3 traffic lights, 137.6ms\n",
      "Speed: 3.1ms preprocess, 137.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.8ms\n",
      "Speed: 2.8ms preprocess, 126.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 22 cars, 2 trucks, 3 traffic lights, 134.9ms\n",
      "Speed: 2.0ms preprocess, 134.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 125.1ms\n",
      "Speed: 2.6ms preprocess, 125.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 23 cars, 2 trucks, 3 traffic lights, 133.5ms\n",
      "Speed: 2.0ms preprocess, 133.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 135.6ms\n",
      "Speed: 2.0ms preprocess, 135.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 23 cars, 3 trucks, 3 traffic lights, 132.6ms\n",
      "Speed: 3.0ms preprocess, 132.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.8ms\n",
      "Speed: 15.4ms preprocess, 123.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 24 cars, 2 trucks, 3 traffic lights, 129.4ms\n",
      "Speed: 3.3ms preprocess, 129.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 134.7ms\n",
      "Speed: 3.1ms preprocess, 134.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 25 cars, 4 trucks, 3 traffic lights, 137.1ms\n",
      "Speed: 2.0ms preprocess, 137.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.4ms\n",
      "Speed: 3.0ms preprocess, 126.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 23 cars, 3 trucks, 3 traffic lights, 135.3ms\n",
      "Speed: 3.5ms preprocess, 135.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 125.5ms\n",
      "Speed: 2.1ms preprocess, 125.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 24 cars, 4 trucks, 3 traffic lights, 160.3ms\n",
      "Speed: 2.0ms preprocess, 160.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 148.7ms\n",
      "Speed: 3.0ms preprocess, 148.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 23 cars, 3 trucks, 3 traffic lights, 166.8ms\n",
      "Speed: 3.1ms preprocess, 166.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 170.9ms\n",
      "Speed: 3.2ms preprocess, 170.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 23 cars, 3 trucks, 3 traffic lights, 135.5ms\n",
      "Speed: 3.1ms preprocess, 135.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 142.9ms\n",
      "Speed: 3.1ms preprocess, 142.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24 cars, 3 trucks, 4 traffic lights, 140.7ms\n",
      "Speed: 3.0ms preprocess, 140.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 118.5ms\n",
      "Speed: 3.1ms preprocess, 118.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 23 cars, 3 trucks, 4 traffic lights, 124.8ms\n",
      "Speed: 3.0ms preprocess, 124.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 120.9ms\n",
      "Speed: 2.0ms preprocess, 120.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 24 cars, 3 trucks, 4 traffic lights, 128.5ms\n",
      "Speed: 4.4ms preprocess, 128.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.5ms\n",
      "Speed: 2.0ms preprocess, 121.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 23 cars, 3 trucks, 4 traffic lights, 137.9ms\n",
      "Speed: 3.0ms preprocess, 137.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 114.5ms\n",
      "Speed: 3.2ms preprocess, 114.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 24 cars, 3 trucks, 4 traffic lights, 127.0ms\n",
      "Speed: 3.0ms preprocess, 127.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.2ms\n",
      "Speed: 2.8ms preprocess, 122.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 24 cars, 3 trucks, 4 traffic lights, 128.2ms\n",
      "Speed: 3.1ms preprocess, 128.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 124.4ms\n",
      "Speed: 2.5ms preprocess, 124.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 24 cars, 3 trucks, 4 traffic lights, 129.9ms\n",
      "Speed: 2.0ms preprocess, 129.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.5ms\n",
      "Speed: 3.3ms preprocess, 126.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 22 cars, 4 trucks, 4 traffic lights, 127.9ms\n",
      "Speed: 2.2ms preprocess, 127.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 117.8ms\n",
      "Speed: 3.0ms preprocess, 117.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 22 cars, 1 bus, 3 trucks, 4 traffic lights, 130.5ms\n",
      "Speed: 3.0ms preprocess, 130.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.6ms\n",
      "Speed: 2.0ms preprocess, 123.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 22 cars, 1 bus, 4 trucks, 4 traffic lights, 131.5ms\n",
      "Speed: 2.0ms preprocess, 131.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 124.8ms\n",
      "Speed: 3.6ms preprocess, 124.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19 cars, 5 trucks, 4 traffic lights, 124.2ms\n",
      "Speed: 2.0ms preprocess, 124.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 135.5ms\n",
      "Speed: 3.0ms preprocess, 135.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 cars, 1 bus, 5 trucks, 4 traffic lights, 124.9ms\n",
      "Speed: 3.9ms preprocess, 124.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 124.3ms\n",
      "Speed: 3.1ms preprocess, 124.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19 cars, 5 trucks, 4 traffic lights, 129.2ms\n",
      "Speed: 2.9ms preprocess, 129.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.1ms\n",
      "Speed: 2.0ms preprocess, 121.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 19 cars, 5 trucks, 4 traffic lights, 136.4ms\n",
      "Speed: 1.4ms preprocess, 136.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 124.1ms\n",
      "Speed: 2.5ms preprocess, 124.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 23 cars, 5 trucks, 4 traffic lights, 129.7ms\n",
      "Speed: 2.3ms preprocess, 129.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.3ms\n",
      "Speed: 3.2ms preprocess, 122.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20 cars, 1 bus, 5 trucks, 4 traffic lights, 131.4ms\n",
      "Speed: 3.6ms preprocess, 131.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 127.9ms\n",
      "Speed: 3.4ms preprocess, 127.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 21 cars, 1 bus, 5 trucks, 4 traffic lights, 131.1ms\n",
      "Speed: 1.8ms preprocess, 131.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 128.3ms\n",
      "Speed: 3.5ms preprocess, 128.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20 cars, 1 bus, 5 trucks, 4 traffic lights, 138.3ms\n",
      "Speed: 1.0ms preprocess, 138.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 129.7ms\n",
      "Speed: 2.3ms preprocess, 129.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20 cars, 1 bus, 4 trucks, 4 traffic lights, 138.4ms\n",
      "Speed: 1.0ms preprocess, 138.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 130.1ms\n",
      "Speed: 5.1ms preprocess, 130.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 21 cars, 2 buss, 4 trucks, 3 traffic lights, 141.9ms\n",
      "Speed: 3.1ms preprocess, 141.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 126.4ms\n",
      "Speed: 2.0ms preprocess, 126.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19 cars, 2 buss, 5 trucks, 3 traffic lights, 134.6ms\n",
      "Speed: 2.4ms preprocess, 134.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 124.9ms\n",
      "Speed: 2.0ms preprocess, 124.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20 cars, 2 buss, 4 trucks, 3 traffic lights, 135.2ms\n",
      "Speed: 2.0ms preprocess, 135.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 129.1ms\n",
      "Speed: 2.0ms preprocess, 129.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 23 cars, 2 buss, 2 trucks, 4 traffic lights, 154.0ms\n",
      "Speed: 3.0ms preprocess, 154.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 139.8ms\n",
      "Speed: 3.0ms preprocess, 139.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 cars, 2 buss, 2 trucks, 4 traffic lights, 140.9ms\n",
      "Speed: 2.7ms preprocess, 140.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 135.2ms\n",
      "Speed: 4.1ms preprocess, 135.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 cars, 3 buss, 2 trucks, 3 traffic lights, 140.1ms\n",
      "Speed: 3.4ms preprocess, 140.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 133.1ms\n",
      "Speed: 2.0ms preprocess, 133.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 cars, 1 bus, 3 trucks, 4 traffic lights, 134.4ms\n",
      "Speed: 2.5ms preprocess, 134.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 143.6ms\n",
      "Speed: 2.0ms preprocess, 143.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 cars, 1 bus, 3 trucks, 4 traffic lights, 131.5ms\n",
      "Speed: 3.2ms preprocess, 131.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 154.2ms\n",
      "Speed: 2.1ms preprocess, 154.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20 cars, 1 bus, 3 trucks, 5 traffic lights, 159.9ms\n",
      "Speed: 2.6ms preprocess, 159.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 149.8ms\n",
      "Speed: 3.7ms preprocess, 149.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 21 cars, 2 buss, 2 trucks, 3 traffic lights, 206.4ms\n",
      "Speed: 2.0ms preprocess, 206.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 153.5ms\n",
      "Speed: 2.0ms preprocess, 153.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19 cars, 2 buss, 3 trucks, 3 traffic lights, 136.1ms\n",
      "Speed: 3.0ms preprocess, 136.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 125.2ms\n",
      "Speed: 3.9ms preprocess, 125.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 22 cars, 2 buss, 3 trucks, 3 traffic lights, 129.7ms\n",
      "Speed: 3.0ms preprocess, 129.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 122.1ms\n",
      "Speed: 1.6ms preprocess, 122.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 21 cars, 2 buss, 2 trucks, 3 traffic lights, 129.0ms\n",
      "Speed: 1.9ms preprocess, 129.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 120.9ms\n",
      "Speed: 3.0ms preprocess, 120.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 cars, 2 buss, 2 trucks, 3 traffic lights, 128.6ms\n",
      "Speed: 2.0ms preprocess, 128.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 124.2ms\n",
      "Speed: 3.7ms preprocess, 124.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 cars, 2 buss, 2 trucks, 3 traffic lights, 129.0ms\n",
      "Speed: 1.0ms preprocess, 129.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 137.5ms\n",
      "Speed: 2.1ms preprocess, 137.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 buss, 3 trucks, 3 traffic lights, 123.0ms\n",
      "Speed: 2.8ms preprocess, 123.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 124.7ms\n",
      "Speed: 3.4ms preprocess, 124.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 cars, 2 buss, 3 trucks, 3 traffic lights, 133.7ms\n",
      "Speed: 3.3ms preprocess, 133.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 120.5ms\n",
      "Speed: 2.0ms preprocess, 120.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 1 bus, 2 trucks, 3 traffic lights, 131.3ms\n",
      "Speed: 2.7ms preprocess, 131.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 117.2ms\n",
      "Speed: 2.0ms preprocess, 117.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 cars, 1 bus, 3 trucks, 3 traffic lights, 129.5ms\n",
      "Speed: 2.0ms preprocess, 129.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 120.6ms\n",
      "Speed: 3.2ms preprocess, 120.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 2 buss, 3 trucks, 4 traffic lights, 124.8ms\n",
      "Speed: 2.0ms preprocess, 124.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 123.5ms\n",
      "Speed: 2.0ms preprocess, 123.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 2 buss, 4 trucks, 3 traffic lights, 128.6ms\n",
      "Speed: 2.0ms preprocess, 128.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 123.3ms\n",
      "Speed: 2.0ms preprocess, 123.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 3 buss, 4 trucks, 4 traffic lights, 1 stop sign, 130.7ms\n",
      "Speed: 1.7ms preprocess, 130.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 129.5ms\n",
      "Speed: 2.0ms preprocess, 129.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 cars, 3 buss, 3 trucks, 4 traffic lights, 1 stop sign, 122.7ms\n",
      "Speed: 2.5ms preprocess, 122.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 118.6ms\n",
      "Speed: 2.3ms preprocess, 118.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 cars, 2 buss, 3 trucks, 3 traffic lights, 1 stop sign, 131.0ms\n",
      "Speed: 2.7ms preprocess, 131.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 131.2ms\n",
      "Speed: 2.0ms preprocess, 131.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 cars, 2 buss, 3 trucks, 3 traffic lights, 1 stop sign, 150.7ms\n",
      "Speed: 2.0ms preprocess, 150.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 116.3ms\n",
      "Speed: 3.0ms preprocess, 116.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 cars, 3 buss, 3 trucks, 3 traffic lights, 1 stop sign, 129.7ms\n",
      "Speed: 2.9ms preprocess, 129.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 136.2ms\n",
      "Speed: 2.0ms preprocess, 136.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 buss, 2 trucks, 3 traffic lights, 1 stop sign, 134.2ms\n",
      "Speed: 2.0ms preprocess, 134.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 129.0ms\n",
      "Speed: 3.5ms preprocess, 129.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19 cars, 3 buss, 3 trucks, 3 traffic lights, 1 stop sign, 127.7ms\n",
      "Speed: 4.4ms preprocess, 127.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 127.9ms\n",
      "Speed: 3.5ms preprocess, 127.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 cars, 2 buss, 3 trucks, 3 traffic lights, 1 stop sign, 135.2ms\n",
      "Speed: 2.2ms preprocess, 135.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 138.2ms\n",
      "Speed: 2.3ms preprocess, 138.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 18 cars, 2 buss, 3 trucks, 3 traffic lights, 1 stop sign, 139.7ms\n",
      "Speed: 2.2ms preprocess, 139.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 128.6ms\n",
      "Speed: 2.0ms preprocess, 128.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 18 cars, 3 buss, 3 trucks, 3 traffic lights, 1 stop sign, 132.1ms\n",
      "Speed: 3.0ms preprocess, 132.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 133.6ms\n",
      "Speed: 2.0ms preprocess, 133.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 cars, 3 buss, 2 trucks, 3 traffic lights, 132.9ms\n",
      "Speed: 3.0ms preprocess, 132.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 129.9ms\n",
      "Speed: 2.5ms preprocess, 129.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 3 buss, 2 trucks, 3 traffic lights, 139.2ms\n",
      "Speed: 2.0ms preprocess, 139.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 121.6ms\n",
      "Speed: 2.0ms preprocess, 121.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 cars, 3 buss, 2 trucks, 3 traffic lights, 131.6ms\n",
      "Speed: 2.0ms preprocess, 131.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 125.9ms\n",
      "Speed: 2.6ms preprocess, 125.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 2 buss, 1 truck, 3 traffic lights, 151.6ms\n",
      "Speed: 2.6ms preprocess, 151.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 129.9ms\n",
      "Speed: 1.9ms preprocess, 129.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 1 bus, 2 trucks, 3 traffic lights, 127.7ms\n",
      "Speed: 2.0ms preprocess, 127.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.5ms\n",
      "Speed: 2.8ms preprocess, 123.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 1 bus, 2 trucks, 3 traffic lights, 126.7ms\n",
      "Speed: 2.5ms preprocess, 126.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 127.8ms\n",
      "Speed: 2.8ms preprocess, 127.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 1 bus, 2 trucks, 3 traffic lights, 135.4ms\n",
      "Speed: 4.5ms preprocess, 135.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.3ms\n",
      "Speed: 2.0ms preprocess, 122.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 2 trucks, 4 traffic lights, 137.7ms\n",
      "Speed: 2.0ms preprocess, 137.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 125.8ms\n",
      "Speed: 2.0ms preprocess, 125.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 1 truck, 3 traffic lights, 133.5ms\n",
      "Speed: 2.0ms preprocess, 133.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 124.3ms\n",
      "Speed: 3.4ms preprocess, 124.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 1 truck, 4 traffic lights, 139.5ms\n",
      "Speed: 1.5ms preprocess, 139.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.1ms\n",
      "Speed: 3.1ms preprocess, 122.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 1 bus, 1 truck, 3 traffic lights, 133.4ms\n",
      "Speed: 1.6ms preprocess, 133.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 116.9ms\n",
      "Speed: 2.0ms preprocess, 116.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 cars, 1 bus, 2 trucks, 3 traffic lights, 1 stop sign, 122.8ms\n",
      "Speed: 2.8ms preprocess, 122.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.0ms\n",
      "Speed: 2.5ms preprocess, 122.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 17 cars, 2 trucks, 3 traffic lights, 1 stop sign, 126.5ms\n",
      "Speed: 2.1ms preprocess, 126.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 127.5ms\n",
      "Speed: 2.1ms preprocess, 127.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15 cars, 1 bus, 1 truck, 3 traffic lights, 134.8ms\n",
      "Speed: 2.0ms preprocess, 134.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.5ms\n",
      "Speed: 3.0ms preprocess, 126.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15 cars, 1 bus, 1 truck, 4 traffic lights, 132.6ms\n",
      "Speed: 2.0ms preprocess, 132.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 125.0ms\n",
      "Speed: 13.1ms preprocess, 125.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14 cars, 1 bus, 1 truck, 3 traffic lights, 125.7ms\n",
      "Speed: 2.7ms preprocess, 125.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 116.0ms\n",
      "Speed: 2.0ms preprocess, 116.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15 cars, 1 bus, 1 truck, 3 traffic lights, 133.2ms\n",
      "Speed: 2.0ms preprocess, 133.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.6ms\n",
      "Speed: 2.0ms preprocess, 126.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 cars, 1 bus, 1 truck, 5 traffic lights, 191.9ms\n",
      "Speed: 4.0ms preprocess, 191.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.8ms\n",
      "Speed: 3.7ms preprocess, 123.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 cars, 1 bus, 1 truck, 4 traffic lights, 125.4ms\n",
      "Speed: 2.0ms preprocess, 125.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 117.6ms\n",
      "Speed: 4.0ms preprocess, 117.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 cars, 1 truck, 3 traffic lights, 126.1ms\n",
      "Speed: 2.0ms preprocess, 126.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 122.8ms\n",
      "Speed: 3.1ms preprocess, 122.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 1 truck, 4 traffic lights, 135.7ms\n",
      "Speed: 3.2ms preprocess, 135.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 122.7ms\n",
      "Speed: 2.3ms preprocess, 122.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 cars, 1 truck, 4 traffic lights, 123.2ms\n",
      "Speed: 2.9ms preprocess, 123.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 109.3ms\n",
      "Speed: 3.0ms preprocess, 109.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 1 truck, 3 traffic lights, 134.0ms\n",
      "Speed: 2.6ms preprocess, 134.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 120.1ms\n",
      "Speed: 2.0ms preprocess, 120.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 9 cars, 1 truck, 3 traffic lights, 125.8ms\n",
      "Speed: 2.0ms preprocess, 125.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 133.9ms\n",
      "Speed: 3.5ms preprocess, 133.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 9 cars, 1 truck, 3 traffic lights, 126.3ms\n",
      "Speed: 3.0ms preprocess, 126.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 123.7ms\n",
      "Speed: 3.9ms preprocess, 123.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 cars, 1 bus, 1 truck, 4 traffic lights, 124.4ms\n",
      "Speed: 2.5ms preprocess, 124.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 125.9ms\n",
      "Speed: 2.0ms preprocess, 125.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 bus, 1 truck, 3 traffic lights, 134.4ms\n",
      "Speed: 4.0ms preprocess, 134.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 132.1ms\n",
      "Speed: 6.0ms preprocess, 132.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 cars, 1 bus, 2 trucks, 4 traffic lights, 1 stop sign, 140.2ms\n",
      "Speed: 3.5ms preprocess, 140.2ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 128.6ms\n",
      "Speed: 4.4ms preprocess, 128.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 cars, 1 bus, 2 trucks, 4 traffic lights, 135.1ms\n",
      "Speed: 4.5ms preprocess, 135.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 118.8ms\n",
      "Speed: 3.7ms preprocess, 118.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 1 bus, 2 trucks, 4 traffic lights, 137.9ms\n",
      "Speed: 2.0ms preprocess, 137.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 125.1ms\n",
      "Speed: 2.9ms preprocess, 125.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 4 traffic lights, 1 stop sign, 130.5ms\n",
      "Speed: 2.9ms preprocess, 130.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 120.1ms\n",
      "Speed: 4.5ms preprocess, 120.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 cars, 1 truck, 3 traffic lights, 158.2ms\n",
      "Speed: 3.9ms preprocess, 158.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 128.6ms\n",
      "Speed: 2.5ms preprocess, 128.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 cars, 1 bus, 2 trucks, 3 traffic lights, 139.9ms\n",
      "Speed: 2.0ms preprocess, 139.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 124.0ms\n",
      "Speed: 4.3ms preprocess, 124.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 cars, 1 bus, 1 truck, 3 traffic lights, 140.9ms\n",
      "Speed: 2.0ms preprocess, 140.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 129.4ms\n",
      "Speed: 3.8ms preprocess, 129.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 1 bus, 1 truck, 4 traffic lights, 138.3ms\n",
      "Speed: 3.0ms preprocess, 138.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 127.6ms\n",
      "Speed: 2.2ms preprocess, 127.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 cars, 1 bus, 2 trucks, 4 traffic lights, 134.9ms\n",
      "Speed: 4.2ms preprocess, 134.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 124.9ms\n",
      "Speed: 3.6ms preprocess, 124.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 cars, 1 bus, 1 truck, 3 traffic lights, 136.9ms\n",
      "Speed: 1.5ms preprocess, 136.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 125.1ms\n",
      "Speed: 2.8ms preprocess, 125.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 9 cars, 1 bus, 1 truck, 3 traffic lights, 139.6ms\n",
      "Speed: 2.6ms preprocess, 139.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 121.9ms\n",
      "Speed: 2.6ms preprocess, 121.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 1 bus, 1 truck, 4 traffic lights, 138.6ms\n",
      "Speed: 1.0ms preprocess, 138.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 139.4ms\n",
      "Speed: 2.0ms preprocess, 139.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 cars, 1 bus, 1 truck, 3 traffic lights, 131.9ms\n",
      "Speed: 3.1ms preprocess, 131.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 119.9ms\n",
      "Speed: 3.0ms preprocess, 119.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 cars, 1 bus, 1 truck, 4 traffic lights, 132.2ms\n",
      "Speed: 2.0ms preprocess, 132.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 121.3ms\n",
      "Speed: 2.5ms preprocess, 121.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 1 bus, 1 truck, 4 traffic lights, 129.8ms\n",
      "Speed: 3.8ms preprocess, 129.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 118.6ms\n",
      "Speed: 2.0ms preprocess, 118.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 cars, 1 bus, 2 trucks, 3 traffic lights, 123.4ms\n",
      "Speed: 2.7ms preprocess, 123.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 123.9ms\n",
      "Speed: 2.0ms preprocess, 123.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 cars, 1 bus, 2 trucks, 4 traffic lights, 124.3ms\n",
      "Speed: 3.6ms preprocess, 124.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 121.2ms\n",
      "Speed: 3.0ms preprocess, 121.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 cars, 1 bus, 2 trucks, 4 traffic lights, 124.6ms\n",
      "Speed: 1.5ms preprocess, 124.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 122.2ms\n",
      "Speed: 2.5ms preprocess, 122.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 cars, 1 bus, 2 trucks, 3 traffic lights, 136.2ms\n",
      "Speed: 2.0ms preprocess, 136.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 145.1ms\n",
      "Speed: 2.5ms preprocess, 145.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15 cars, 1 bus, 2 trucks, 3 traffic lights, 129.6ms\n",
      "Speed: 3.0ms preprocess, 129.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 132.6ms\n",
      "Speed: 3.0ms preprocess, 132.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16 cars, 2 trucks, 3 traffic lights, 136.4ms\n",
      "Speed: 3.0ms preprocess, 136.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 121.1ms\n",
      "Speed: 2.1ms preprocess, 121.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 cars, 2 trucks, 3 traffic lights, 132.2ms\n",
      "Speed: 3.5ms preprocess, 132.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 126.0ms\n",
      "Speed: 2.0ms preprocess, 126.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 2 trucks, 3 traffic lights, 139.1ms\n",
      "Speed: 3.0ms preprocess, 139.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 127.7ms\n",
      "Speed: 2.0ms preprocess, 127.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 cars, 2 trucks, 4 traffic lights, 168.9ms\n",
      "Speed: 2.8ms preprocess, 168.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 146.0ms\n",
      "Speed: 2.1ms preprocess, 146.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 cars, 2 trucks, 4 traffic lights, 159.6ms\n",
      "Speed: 2.8ms preprocess, 159.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 matriculas, 126.7ms\n",
      "Speed: 3.0ms preprocess, 126.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 cars, 2 trucks, 3 traffic lights, 139.9ms\n",
      "Speed: 3.5ms preprocess, 139.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 236.5ms\n",
      "Speed: 3.1ms preprocess, 236.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 cars, 2 trucks, 3 traffic lights, 150.0ms\n",
      "Speed: 4.0ms preprocess, 150.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 matriculas, 144.3ms\n",
      "Speed: 3.5ms preprocess, 144.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 cars, 2 trucks, 3 traffic lights, 154.5ms\n",
      "Speed: 2.0ms preprocess, 154.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 matriculas, 122.7ms\n",
      "Speed: 2.0ms preprocess, 122.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 cars, 2 trucks, 4 traffic lights, 136.2ms\n",
      "Speed: 2.5ms preprocess, 136.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 129.0ms\n",
      "Speed: 2.0ms preprocess, 129.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 cars, 2 trucks, 3 traffic lights, 141.1ms\n",
      "Speed: 2.3ms preprocess, 141.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 128.9ms\n",
      "Speed: 2.0ms preprocess, 128.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 2 trucks, 3 traffic lights, 129.5ms\n",
      "Speed: 2.9ms preprocess, 129.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 132.5ms\n",
      "Speed: 2.0ms preprocess, 132.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 cars, 2 trucks, 3 traffic lights, 147.5ms\n",
      "Speed: 3.3ms preprocess, 147.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 125.5ms\n",
      "Speed: 2.0ms preprocess, 125.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 cars, 3 trucks, 3 traffic lights, 150.5ms\n",
      "Speed: 3.0ms preprocess, 150.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 125.2ms\n",
      "Speed: 3.0ms preprocess, 125.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 cars, 3 trucks, 3 traffic lights, 140.5ms\n",
      "Speed: 2.6ms preprocess, 140.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 129.5ms\n",
      "Speed: 5.8ms preprocess, 129.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 cars, 3 trucks, 2 traffic lights, 137.8ms\n",
      "Speed: 2.2ms preprocess, 137.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 121.7ms\n",
      "Speed: 4.1ms preprocess, 121.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 cars, 1 bus, 2 trucks, 3 traffic lights, 123.0ms\n",
      "Speed: 2.3ms preprocess, 123.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 125.7ms\n",
      "Speed: 2.0ms preprocess, 125.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 1 bus, 4 trucks, 3 traffic lights, 133.1ms\n",
      "Speed: 3.0ms preprocess, 133.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 128.4ms\n",
      "Speed: 2.0ms preprocess, 128.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 cars, 1 bus, 3 trucks, 2 traffic lights, 137.7ms\n",
      "Speed: 2.6ms preprocess, 137.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 140.2ms\n",
      "Speed: 2.0ms preprocess, 140.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 cars, 2 trucks, 2 traffic lights, 145.7ms\n",
      "Speed: 2.0ms preprocess, 145.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 133.7ms\n",
      "Speed: 15.7ms preprocess, 133.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 cars, 3 trucks, 3 traffic lights, 139.3ms\n",
      "Speed: 3.3ms preprocess, 139.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 129.6ms\n",
      "Speed: 2.0ms preprocess, 129.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 cars, 1 bus, 4 trucks, 2 traffic lights, 128.0ms\n",
      "Speed: 4.2ms preprocess, 128.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 119.0ms\n",
      "Speed: 4.2ms preprocess, 119.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 9 cars, 4 trucks, 2 traffic lights, 134.5ms\n",
      "Speed: 2.6ms preprocess, 134.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 125.5ms\n",
      "Speed: 2.0ms preprocess, 125.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 cars, 1 bus, 4 trucks, 2 traffic lights, 131.7ms\n",
      "Speed: 3.4ms preprocess, 131.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 140.6ms\n",
      "Speed: 2.4ms preprocess, 140.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 cars, 1 bus, 4 trucks, 4 traffic lights, 151.6ms\n",
      "Speed: 3.0ms preprocess, 151.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 147.8ms\n",
      "Speed: 2.6ms preprocess, 147.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 1 bus, 3 trucks, 4 traffic lights, 144.3ms\n",
      "Speed: 4.0ms preprocess, 144.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 124.3ms\n",
      "Speed: 3.1ms preprocess, 124.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 1 bus, 3 trucks, 5 traffic lights, 144.5ms\n",
      "Speed: 2.0ms preprocess, 144.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 135.3ms\n",
      "Speed: 4.6ms preprocess, 135.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 cars, 1 bus, 4 trucks, 2 traffic lights, 128.3ms\n",
      "Speed: 2.0ms preprocess, 128.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 135.4ms\n",
      "Speed: 2.6ms preprocess, 135.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 cars, 1 bus, 3 trucks, 3 traffic lights, 158.5ms\n",
      "Speed: 3.8ms preprocess, 158.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 159.9ms\n",
      "Speed: 4.0ms preprocess, 159.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11 cars, 1 bus, 4 trucks, 2 traffic lights, 153.9ms\n",
      "Speed: 4.5ms preprocess, 153.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 150.4ms\n",
      "Speed: 5.1ms preprocess, 150.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 9 cars, 1 bus, 4 trucks, 2 traffic lights, 132.1ms\n",
      "Speed: 2.5ms preprocess, 132.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 157.7ms\n",
      "Speed: 3.7ms preprocess, 157.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10 cars, 1 bus, 3 trucks, 3 traffic lights, 152.2ms\n",
      "Speed: 3.0ms preprocess, 152.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 171.9ms\n",
      "Speed: 5.6ms preprocess, 171.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 cars, 1 bus, 3 trucks, 2 traffic lights, 156.9ms\n",
      "Speed: 3.6ms preprocess, 156.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 127.8ms\n",
      "Speed: 3.9ms preprocess, 127.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 cars, 1 bus, 3 trucks, 3 traffic lights, 137.4ms\n",
      "Speed: 3.9ms preprocess, 137.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 122.7ms\n",
      "Speed: 2.0ms preprocess, 122.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10 cars, 1 bus, 4 trucks, 3 traffic lights, 131.6ms\n",
      "Speed: 2.3ms preprocess, 131.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 127.9ms\n",
      "Speed: 2.4ms preprocess, 127.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 9 cars, 1 bus, 2 trucks, 3 traffic lights, 132.6ms\n",
      "Speed: 4.0ms preprocess, 132.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 138.4ms\n",
      "Speed: 3.1ms preprocess, 138.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 cars, 2 trucks, 3 traffic lights, 137.7ms\n",
      "Speed: 2.5ms preprocess, 137.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 128.4ms\n",
      "Speed: 2.1ms preprocess, 128.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13 cars, 1 truck, 3 traffic lights, 130.3ms\n",
      "Speed: 2.2ms preprocess, 130.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 121.9ms\n",
      "Speed: 1.6ms preprocess, 121.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14 cars, 2 trucks, 3 traffic lights, 156.4ms\n",
      "Speed: 3.0ms preprocess, 156.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 131.4ms\n",
      "Speed: 2.0ms preprocess, 131.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 17 cars, 1 truck, 4 traffic lights, 150.5ms\n",
      "Speed: 1.6ms preprocess, 150.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 132.7ms\n",
      "Speed: 2.0ms preprocess, 132.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14 cars, 1 truck, 3 traffic lights, 139.5ms\n",
      "Speed: 2.5ms preprocess, 139.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 132.4ms\n",
      "Speed: 3.5ms preprocess, 132.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16 cars, 2 trucks, 3 traffic lights, 192.9ms\n",
      "Speed: 2.0ms preprocess, 192.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 124.2ms\n",
      "Speed: 2.0ms preprocess, 124.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16 cars, 3 trucks, 3 traffic lights, 136.7ms\n",
      "Speed: 2.2ms preprocess, 136.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 121.4ms\n",
      "Speed: 2.9ms preprocess, 121.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 20 cars, 2 trucks, 3 traffic lights, 122.8ms\n",
      "Speed: 3.1ms preprocess, 122.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 123.7ms\n",
      "Speed: 3.2ms preprocess, 123.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 21 cars, 3 trucks, 3 traffic lights, 130.1ms\n",
      "Speed: 2.6ms preprocess, 130.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 129.7ms\n",
      "Speed: 2.5ms preprocess, 129.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 21 cars, 1 bus, 2 trucks, 3 traffic lights, 142.6ms\n",
      "Speed: 3.0ms preprocess, 142.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 138.4ms\n",
      "Speed: 2.0ms preprocess, 138.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 19 cars, 2 trucks, 4 traffic lights, 177.7ms\n",
      "Speed: 3.8ms preprocess, 177.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 131.4ms\n",
      "Speed: 3.5ms preprocess, 131.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 18 cars, 2 trucks, 5 traffic lights, 144.7ms\n",
      "Speed: 1.5ms preprocess, 144.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 121.2ms\n",
      "Speed: 1.4ms preprocess, 121.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 19 cars, 1 bus, 2 trucks, 4 traffic lights, 128.5ms\n",
      "Speed: 1.5ms preprocess, 128.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 122.5ms\n",
      "Speed: 2.0ms preprocess, 122.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 19 cars, 2 trucks, 4 traffic lights, 125.4ms\n",
      "Speed: 3.1ms preprocess, 125.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 121.8ms\n",
      "Speed: 2.8ms preprocess, 121.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 19 cars, 3 trucks, 4 traffic lights, 137.5ms\n",
      "Speed: 4.0ms preprocess, 137.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 148.1ms\n",
      "Speed: 1.9ms preprocess, 148.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 18 cars, 2 trucks, 3 traffic lights, 130.3ms\n",
      "Speed: 2.1ms preprocess, 130.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 123.7ms\n",
      "Speed: 2.0ms preprocess, 123.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 18 cars, 3 trucks, 3 traffic lights, 125.5ms\n",
      "Speed: 2.2ms preprocess, 125.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 121.9ms\n",
      "Speed: 2.2ms preprocess, 121.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 18 cars, 2 trucks, 3 traffic lights, 126.7ms\n",
      "Speed: 2.0ms preprocess, 126.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 125.3ms\n",
      "Speed: 3.1ms preprocess, 125.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 19 cars, 2 trucks, 3 traffic lights, 124.9ms\n",
      "Speed: 3.4ms preprocess, 124.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 121.6ms\n",
      "Speed: 2.1ms preprocess, 121.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20 cars, 2 trucks, 3 traffic lights, 127.8ms\n",
      "Speed: 4.6ms preprocess, 127.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.1ms\n",
      "Speed: 3.1ms preprocess, 126.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 18 cars, 2 trucks, 3 traffic lights, 134.7ms\n",
      "Speed: 2.0ms preprocess, 134.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 128.5ms\n",
      "Speed: 4.1ms preprocess, 128.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 21 cars, 2 trucks, 4 traffic lights, 137.7ms\n",
      "Speed: 2.9ms preprocess, 137.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 138.4ms\n",
      "Speed: 1.5ms preprocess, 138.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 18 cars, 3 trucks, 3 traffic lights, 152.4ms\n",
      "Speed: 3.9ms preprocess, 152.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 127.2ms\n",
      "Speed: 2.0ms preprocess, 127.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 cars, 3 trucks, 4 traffic lights, 138.9ms\n",
      "Speed: 3.6ms preprocess, 138.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 129.7ms\n",
      "Speed: 2.2ms preprocess, 129.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 20 cars, 2 trucks, 4 traffic lights, 135.3ms\n",
      "Speed: 2.0ms preprocess, 135.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 120.4ms\n",
      "Speed: 3.5ms preprocess, 120.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 18 cars, 1 truck, 3 traffic lights, 129.4ms\n",
      "Speed: 3.1ms preprocess, 129.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 122.1ms\n",
      "Speed: 3.6ms preprocess, 122.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 19 cars, 2 trucks, 3 traffic lights, 127.4ms\n",
      "Speed: 3.0ms preprocess, 127.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 153.9ms\n",
      "Speed: 3.0ms preprocess, 153.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 17 cars, 1 truck, 3 traffic lights, 145.8ms\n",
      "Speed: 4.1ms preprocess, 145.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 128.0ms\n",
      "Speed: 3.0ms preprocess, 128.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 19 cars, 1 truck, 3 traffic lights, 136.9ms\n",
      "Speed: 3.0ms preprocess, 136.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 134.3ms\n",
      "Speed: 3.9ms preprocess, 134.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 17 cars, 1 truck, 3 traffic lights, 143.9ms\n",
      "Speed: 2.0ms preprocess, 143.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 164.7ms\n",
      "Speed: 3.0ms preprocess, 164.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 17 cars, 1 truck, 4 traffic lights, 179.5ms\n",
      "Speed: 4.1ms preprocess, 179.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 174.8ms\n",
      "Speed: 2.5ms preprocess, 174.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 18 cars, 1 truck, 3 traffic lights, 143.2ms\n",
      "Speed: 2.4ms preprocess, 143.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 169.8ms\n",
      "Speed: 2.0ms preprocess, 169.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 20 cars, 1 truck, 3 traffic lights, 152.6ms\n",
      "Speed: 3.9ms preprocess, 152.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 168.3ms\n",
      "Speed: 2.7ms preprocess, 168.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 20 cars, 1 truck, 2 traffic lights, 155.1ms\n",
      "Speed: 3.1ms preprocess, 155.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 142.0ms\n",
      "Speed: 4.0ms preprocess, 142.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 21 cars, 1 truck, 3 traffic lights, 1 stop sign, 176.1ms\n",
      "Speed: 3.0ms preprocess, 176.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 172.7ms\n",
      "Speed: 3.7ms preprocess, 172.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 21 cars, 1 truck, 3 traffic lights, 162.2ms\n",
      "Speed: 2.5ms preprocess, 162.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 164.3ms\n",
      "Speed: 3.7ms preprocess, 164.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 23 cars, 1 truck, 3 traffic lights, 179.5ms\n",
      "Speed: 2.5ms preprocess, 179.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 158.0ms\n",
      "Speed: 3.0ms preprocess, 158.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 24 cars, 1 truck, 3 traffic lights, 196.9ms\n",
      "Speed: 3.7ms preprocess, 196.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 190.5ms\n",
      "Speed: 4.7ms preprocess, 190.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 24 cars, 1 truck, 3 traffic lights, 183.4ms\n",
      "Speed: 3.0ms preprocess, 183.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 158.5ms\n",
      "Speed: 3.0ms preprocess, 158.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 24 cars, 1 truck, 3 traffic lights, 158.1ms\n",
      "Speed: 3.0ms preprocess, 158.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 180.5ms\n",
      "Speed: 1.2ms preprocess, 180.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 23 cars, 1 truck, 3 traffic lights, 139.7ms\n",
      "Speed: 2.5ms preprocess, 139.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 113.9ms\n",
      "Speed: 1.9ms preprocess, 113.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22 cars, 1 motorcycle, 1 truck, 2 traffic lights, 1 stop sign, 101.0ms\n",
      "Speed: 3.0ms preprocess, 101.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.4ms\n",
      "Speed: 2.0ms preprocess, 90.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22 cars, 1 motorcycle, 1 truck, 2 traffic lights, 1 stop sign, 118.6ms\n",
      "Speed: 2.2ms preprocess, 118.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 94.9ms\n",
      "Speed: 2.7ms preprocess, 94.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 23 cars, 1 truck, 3 traffic lights, 1 stop sign, 98.8ms\n",
      "Speed: 2.2ms preprocess, 98.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.4ms\n",
      "Speed: 2.6ms preprocess, 92.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22 cars, 1 motorcycle, 1 truck, 3 traffic lights, 1 stop sign, 129.2ms\n",
      "Speed: 1.5ms preprocess, 129.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 119.1ms\n",
      "Speed: 2.9ms preprocess, 119.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 26 cars, 1 truck, 2 traffic lights, 106.8ms\n",
      "Speed: 3.1ms preprocess, 106.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.3ms\n",
      "Speed: 1.6ms preprocess, 87.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 24 cars, 1 motorcycle, 1 truck, 3 traffic lights, 97.6ms\n",
      "Speed: 3.0ms preprocess, 97.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.7ms\n",
      "Speed: 2.7ms preprocess, 87.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 25 cars, 1 motorcycle, 1 truck, 2 traffic lights, 109.0ms\n",
      "Speed: 1.0ms preprocess, 109.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.0ms\n",
      "Speed: 1.9ms preprocess, 88.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 17 cars, 1 motorcycle, 1 truck, 3 traffic lights, 92.8ms\n",
      "Speed: 2.1ms preprocess, 92.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.7ms\n",
      "Speed: 1.5ms preprocess, 85.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 18 cars, 1 motorcycle, 1 truck, 3 traffic lights, 1 stop sign, 90.5ms\n",
      "Speed: 2.4ms preprocess, 90.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.2ms\n",
      "Speed: 2.0ms preprocess, 89.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 18 cars, 1 motorcycle, 1 truck, 3 traffic lights, 1 stop sign, 93.5ms\n",
      "Speed: 2.6ms preprocess, 93.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 165.3ms\n",
      "Speed: 2.2ms preprocess, 165.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 16 cars, 1 motorcycle, 1 truck, 3 traffic lights, 187.6ms\n",
      "Speed: 3.1ms preprocess, 187.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 219.5ms\n",
      "Speed: 3.0ms preprocess, 219.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 13 cars, 1 motorcycle, 1 truck, 3 traffic lights, 175.8ms\n",
      "Speed: 3.2ms preprocess, 175.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 113.1ms\n",
      "Speed: 5.3ms preprocess, 113.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15 cars, 2 motorcycles, 1 truck, 2 traffic lights, 1 stop sign, 130.0ms\n",
      "Speed: 2.0ms preprocess, 130.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 151.4ms\n",
      "Speed: 3.3ms preprocess, 151.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11 cars, 2 motorcycles, 2 trucks, 2 traffic lights, 1 stop sign, 191.2ms\n",
      "Speed: 6.2ms preprocess, 191.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.3ms\n",
      "Speed: 3.2ms preprocess, 122.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 10 cars, 1 motorcycle, 1 truck, 2 traffic lights, 1 stop sign, 113.6ms\n",
      "Speed: 2.2ms preprocess, 113.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 108.7ms\n",
      "Speed: 2.2ms preprocess, 108.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 9 cars, 1 motorcycle, 1 truck, 2 traffic lights, 121.4ms\n",
      "Speed: 2.1ms preprocess, 121.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 117.4ms\n",
      "Speed: 2.1ms preprocess, 117.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 8 cars, 1 motorcycle, 1 truck, 3 traffic lights, 117.8ms\n",
      "Speed: 3.1ms preprocess, 117.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 109.1ms\n",
      "Speed: 2.1ms preprocess, 109.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 9 cars, 1 motorcycle, 2 trucks, 2 traffic lights, 107.2ms\n",
      "Speed: 2.5ms preprocess, 107.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.6ms\n",
      "Speed: 2.0ms preprocess, 121.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 8 cars, 1 motorcycle, 1 truck, 2 traffic lights, 120.6ms\n",
      "Speed: 2.3ms preprocess, 120.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 124.6ms\n",
      "Speed: 3.4ms preprocess, 124.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 9 cars, 1 motorcycle, 1 truck, 2 traffic lights, 114.3ms\n",
      "Speed: 2.1ms preprocess, 114.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 103.8ms\n",
      "Speed: 5.5ms preprocess, 103.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 9 cars, 1 motorcycle, 2 trucks, 2 traffic lights, 100.5ms\n",
      "Speed: 2.1ms preprocess, 100.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.6ms\n",
      "Speed: 2.8ms preprocess, 92.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 9 cars, 1 motorcycle, 1 truck, 2 traffic lights, 100.4ms\n",
      "Speed: 1.7ms preprocess, 100.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 104.7ms\n",
      "Speed: 2.5ms preprocess, 104.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 10 cars, 1 motorcycle, 1 truck, 3 traffic lights, 127.3ms\n",
      "Speed: 2.8ms preprocess, 127.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 203.6ms\n",
      "Speed: 4.0ms preprocess, 203.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 9 cars, 1 motorcycle, 2 trucks, 2 traffic lights, 109.1ms\n",
      "Speed: 2.4ms preprocess, 109.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.0ms\n",
      "Speed: 2.9ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 9 cars, 1 motorcycle, 2 trucks, 2 traffic lights, 122.3ms\n",
      "Speed: 2.3ms preprocess, 122.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 116.4ms\n",
      "Speed: 3.5ms preprocess, 116.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 12 cars, 1 motorcycle, 2 trucks, 3 traffic lights, 207.4ms\n",
      "Speed: 2.1ms preprocess, 207.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 157.0ms\n",
      "Speed: 7.5ms preprocess, 157.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10 cars, 1 motorcycle, 2 trucks, 3 traffic lights, 210.0ms\n",
      "Speed: 3.4ms preprocess, 210.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 100.0ms\n",
      "Speed: 3.0ms preprocess, 100.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14 cars, 1 motorcycle, 2 trucks, 3 traffic lights, 121.5ms\n",
      "Speed: 3.2ms preprocess, 121.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.1ms\n",
      "Speed: 2.0ms preprocess, 85.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14 cars, 1 motorcycle, 3 trucks, 3 traffic lights, 91.5ms\n",
      "Speed: 1.0ms preprocess, 91.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.4ms\n",
      "Speed: 1.5ms preprocess, 89.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11 cars, 1 motorcycle, 2 trucks, 3 traffic lights, 103.0ms\n",
      "Speed: 2.9ms preprocess, 103.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 97.8ms\n",
      "Speed: 2.3ms preprocess, 97.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13 cars, 1 motorcycle, 3 trucks, 2 traffic lights, 101.5ms\n",
      "Speed: 2.3ms preprocess, 101.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 109.3ms\n",
      "Speed: 2.0ms preprocess, 109.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 14 cars, 1 motorcycle, 2 trucks, 2 traffic lights, 107.8ms\n",
      "Speed: 2.2ms preprocess, 107.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 90.4ms\n",
      "Speed: 3.1ms preprocess, 90.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14 cars, 2 motorcycles, 3 trucks, 3 traffic lights, 145.7ms\n",
      "Speed: 2.0ms preprocess, 145.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 102.2ms\n",
      "Speed: 2.0ms preprocess, 102.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14 cars, 2 motorcycles, 1 truck, 3 traffic lights, 117.2ms\n",
      "Speed: 2.1ms preprocess, 117.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 matriculas, 109.2ms\n",
      "Speed: 2.1ms preprocess, 109.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12 cars, 1 motorcycle, 1 truck, 3 traffic lights, 105.5ms\n",
      "Speed: 3.0ms preprocess, 105.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 108.2ms\n",
      "Speed: 2.4ms preprocess, 108.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14 cars, 1 motorcycle, 1 truck, 3 traffic lights, 111.6ms\n",
      "Speed: 2.9ms preprocess, 111.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 111.2ms\n",
      "Speed: 3.9ms preprocess, 111.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 13 cars, 1 motorcycle, 1 truck, 3 traffic lights, 1 stop sign, 99.7ms\n",
      "Speed: 3.9ms preprocess, 99.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 92.2ms\n",
      "Speed: 2.5ms preprocess, 92.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14 cars, 1 motorcycle, 1 truck, 2 traffic lights, 1 stop sign, 97.7ms\n",
      "Speed: 3.1ms preprocess, 97.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 matricula, 90.6ms\n",
      "Speed: 11.5ms preprocess, 90.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Eric\\Desktop\\vc-5\\VC_P5\\P5\\VC_P5.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/VC_P5/P5/VC_P5.ipynb#X34sZmlsZQ%3D%3D?line=184'>185</a>\u001b[0m results[frame_nmr] \u001b[39m=\u001b[39m {}\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/VC_P5/P5/VC_P5.ipynb#X34sZmlsZQ%3D%3D?line=185'>186</a>\u001b[0m \u001b[39m# detect vehicles\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/VC_P5/P5/VC_P5.ipynb#X34sZmlsZQ%3D%3D?line=186'>187</a>\u001b[0m detections \u001b[39m=\u001b[39m coco_model(frame)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/VC_P5/P5/VC_P5.ipynb#X34sZmlsZQ%3D%3D?line=187'>188</a>\u001b[0m detections_ \u001b[39m=\u001b[39m []\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Eric/Desktop/vc-5/VC_P5/P5/VC_P5.ipynb#X34sZmlsZQ%3D%3D?line=188'>189</a>\u001b[0m \u001b[39mfor\u001b[39;00m detection \u001b[39min\u001b[39;00m detections\u001b[39m.\u001b[39mboxes\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mtolist():\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\ultralytics\\engine\\model.py:101\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, source\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, stream\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    100\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calls the 'predict' function with given arguments to perform object detection.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(source, stream, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\ultralytics\\engine\\model.py:242\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[39mif\u001b[39;00m prompts \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor, \u001b[39m'\u001b[39m\u001b[39mset_prompts\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 242\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mpredict_cli(source\u001b[39m=\u001b[39msource) \u001b[39mif\u001b[39;00m is_cli \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor(source\u001b[39m=\u001b[39;49msource, stream\u001b[39m=\u001b[39;49mstream)\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:196\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_inference(source, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    195\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_inference(source, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[39m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[39m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:259\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[39m# Inference\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39mwith\u001b[39;00m profilers[\u001b[39m1\u001b[39m]:\n\u001b[1;32m--> 259\u001b[0m     preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference(im, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    261\u001b[0m \u001b[39m# Postprocess\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[39mwith\u001b[39;00m profilers[\u001b[39m2\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:135\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    133\u001b[0m visualize \u001b[39m=\u001b[39m increment_path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_dir \u001b[39m/\u001b[39m Path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mstem,\n\u001b[0;32m    134\u001b[0m                            mkdir\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mvisualize \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_type\u001b[39m.\u001b[39mtensor) \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(im, augment\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49maugment, visualize\u001b[39m=\u001b[39;49mvisualize)\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py:347\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize)\u001b[0m\n\u001b[0;32m    344\u001b[0m     im \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)  \u001b[39m# torch BCHW to numpy BHWC shape(1,320,192,3)\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpt \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnn_module:  \u001b[39m# PyTorch\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(im, augment\u001b[39m=\u001b[39maugment, visualize\u001b[39m=\u001b[39mvisualize) \u001b[39mif\u001b[39;00m augment \u001b[39mor\u001b[39;00m visualize \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(im)\n\u001b[0;32m    348\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjit:  \u001b[39m# TorchScript\u001b[39;00m\n\u001b[0;32m    349\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(im)\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:42\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):  \u001b[39m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 42\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:59\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mif\u001b[39;00m augment:\n\u001b[0;32m     58\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict_augment(x)\n\u001b[1;32m---> 59\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_once(x, profile, visualize)\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:79\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m profile:\n\u001b[0;32m     78\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m---> 79\u001b[0m x \u001b[39m=\u001b[39m m(x)  \u001b[39m# run\u001b[39;00m\n\u001b[0;32m     80\u001b[0m y\u001b[39m.\u001b[39mappend(x \u001b[39mif\u001b[39;00m m\u001b[39m.\u001b[39mi \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)  \u001b[39m# save output\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:203\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    202\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv1(x)\u001b[39m.\u001b[39mchunk(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m--> 203\u001b[0m y\u001b[39m.\u001b[39mextend(m(y[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm)\n\u001b[0;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(torch\u001b[39m.\u001b[39mcat(y, \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:203\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    202\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv1(x)\u001b[39m.\u001b[39mchunk(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m--> 203\u001b[0m y\u001b[39m.\u001b[39mextend(m(y[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm)\n\u001b[0;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(torch\u001b[39m.\u001b[39mcat(y, \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:311\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    310\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"'forward()' applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 311\u001b[0m     \u001b[39mreturn\u001b[39;00m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv1(x)) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv1(x))\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:40\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_fuse\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     39\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x))\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\Eric\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import string\n",
    "import easyocr\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from sort.sort import *\n",
    "\n",
    "# Initialize the OCR reader\n",
    "reader = easyocr.Reader(['es'], gpu=False)\n",
    "\n",
    "# Mapping dictionaries for character conversion\n",
    "dict_char_to_int = {'O': '0',\n",
    "                    'I': '1',\n",
    "                    'J': '3',\n",
    "                    'A': '4',\n",
    "                    'G': '6',\n",
    "                    'S': '5'}\n",
    "\n",
    "dict_int_to_char = {'0': 'O',\n",
    "                    '1': 'I',\n",
    "                    '3': 'J',\n",
    "                    '4': 'A',\n",
    "                    '6': 'G',\n",
    "                    '5': 'S'}\n",
    "\n",
    "\n",
    "def write_csv(results, output_path):\n",
    "    \"\"\"\n",
    "    Write the results to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        results (dict): Dictionary containing the results.\n",
    "        output_path (str): Path to the output CSV file.\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write('{},{},{},{},{},{},{}\\n'.format('frame_nmr', 'car_id', 'car_bbox',\n",
    "                                                'license_plate_bbox', 'license_plate_bbox_score', 'license_number',\n",
    "                                                'license_number_score'))\n",
    "\n",
    "        for frame_nmr in results.keys():\n",
    "            for car_id in results[frame_nmr].keys():\n",
    "                print(results[frame_nmr][car_id])\n",
    "                if 'car' in results[frame_nmr][car_id].keys() and \\\n",
    "                   'license_plate' in results[frame_nmr][car_id].keys() and \\\n",
    "                   'text' in results[frame_nmr][car_id]['license_plate'].keys():\n",
    "                    f.write('{},{},{},{},{},{},{}\\n'.format(frame_nmr,\n",
    "                                                            car_id,\n",
    "                                                            '[{} {} {} {}]'.format(\n",
    "                                                                results[frame_nmr][car_id]['car']['bbox'][0],\n",
    "                                                                results[frame_nmr][car_id]['car']['bbox'][1],\n",
    "                                                                results[frame_nmr][car_id]['car']['bbox'][2],\n",
    "                                                                results[frame_nmr][car_id]['car']['bbox'][3]),\n",
    "                                                            '[{} {} {} {}]'.format(\n",
    "                                                                results[frame_nmr][car_id]['license_plate']['bbox'][0],\n",
    "                                                                results[frame_nmr][car_id]['license_plate']['bbox'][1],\n",
    "                                                                results[frame_nmr][car_id]['license_plate']['bbox'][2],\n",
    "                                                                results[frame_nmr][car_id]['license_plate']['bbox'][3]),\n",
    "                                                            results[frame_nmr][car_id]['license_plate']['bbox_score'],\n",
    "                                                            results[frame_nmr][car_id]['license_plate']['text'],\n",
    "                                                            results[frame_nmr][car_id]['license_plate']['text_score'])\n",
    "                            )\n",
    "        f.close()\n",
    "\n",
    "\n",
    "def license_complies_format(text):\n",
    "    \"\"\"\n",
    "    Check if the license plate text complies with the required format.\n",
    "\n",
    "    Args:\n",
    "        text (str): License plate text.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the license plate complies with the format, False otherwise.\n",
    "    \"\"\"\n",
    "    if len(text) != 7:\n",
    "        return False\n",
    "\n",
    "    if (text[0] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[0] in dict_char_to_int.keys()) and \\\n",
    "       (text[1] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[1] in dict_char_to_int.keys()) and \\\n",
    "       (text[2] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[2] in dict_char_to_int.keys()) and \\\n",
    "       (text[3] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[3] in dict_char_to_int.keys()) and \\\n",
    "       (text[4] in string.ascii_uppercase or text[4] in dict_int_to_char.keys()) and \\\n",
    "       (text[5] in string.ascii_uppercase or text[5] in dict_int_to_char.keys()) and \\\n",
    "       (text[6] in string.ascii_uppercase or text[6] in dict_int_to_char.keys()):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def format_license(text):\n",
    "    \"\"\"\n",
    "    Format the license plate text by converting characters using the mapping dictionaries.\n",
    "\n",
    "    Args:\n",
    "        text (str): License plate text.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted license plate text.\n",
    "    \"\"\"\n",
    "    license_plate_ = ''\n",
    "    mapping = {0: dict_int_to_char, 1: dict_int_to_char, 4: dict_int_to_char, 5: dict_int_to_char, 6: dict_int_to_char,\n",
    "               2: dict_char_to_int, 3: dict_char_to_int}\n",
    "    for j in [0, 1, 2, 3, 4, 5, 6]:\n",
    "        if text[j] in mapping[j].keys():\n",
    "            license_plate_ += mapping[j][text[j]]\n",
    "        else:\n",
    "            license_plate_ += text[j]\n",
    "\n",
    "    return license_plate_\n",
    "\n",
    "\n",
    "def read_license_plate(license_plate_crop):\n",
    "    \"\"\"\n",
    "    Read the license plate text from the given cropped image.\n",
    "\n",
    "    Args:\n",
    "        license_plate_crop (PIL.Image.Image): Cropped image containing the license plate.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing the formatted license plate text and its confidence score.\n",
    "    \"\"\"\n",
    "\n",
    "    detections = reader.readtext(license_plate_crop)\n",
    "\n",
    "    for detection in detections:\n",
    "        bbox, text, score = detection\n",
    "\n",
    "        text = text.upper().replace(' ', '')\n",
    "\n",
    "        if license_complies_format(text):\n",
    "            return format_license(text), score\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def get_car(license_plate, vehicle_track_ids):\n",
    "    \"\"\"\n",
    "    Retrieve the vehicle coordinates and ID based on the license plate coordinates.\n",
    "\n",
    "    Args:\n",
    "        license_plate (tuple): Tuple containing the coordinates of the license plate (x1, y1, x2, y2, score, class_id).\n",
    "        vehicle_track_ids (list): List of vehicle track IDs and their corresponding coordinates.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing the vehicle coordinates (x1, y1, x2, y2) and ID.\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2, score, class_id = license_plate\n",
    "\n",
    "    foundIt = False\n",
    "    for j in range(len(vehicle_track_ids)):\n",
    "        xcar1, ycar1, xcar2, ycar2, car_id = vehicle_track_ids[j]\n",
    "\n",
    "        if x1 > xcar1 and y1 > ycar1 and x2 < xcar2 and y2 < ycar2:\n",
    "            car_indx = j\n",
    "            foundIt = True\n",
    "            break\n",
    "\n",
    "    if foundIt:\n",
    "        return vehicle_track_ids[car_indx]\n",
    "\n",
    "    return -1, -1, -1, -1, -1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "mot_tracker = Sort()\n",
    "\n",
    "# load models\n",
    "coco_model = YOLO('yolov8n.pt')\n",
    "license_plate_detector = YOLO('best.pt')\n",
    "\n",
    "# load video\n",
    "cap = cv2.VideoCapture('prueba.mp4')\n",
    "\n",
    "vehicles = [2, 3, 5, 7]\n",
    "\n",
    "# read frames\n",
    "frame_nmr = -1\n",
    "ret = True\n",
    "while ret:\n",
    "    frame_nmr += 1\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        results[frame_nmr] = {}\n",
    "        # detect vehicles\n",
    "        detections = coco_model(frame)[0]\n",
    "        detections_ = []\n",
    "        for detection in detections.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = detection\n",
    "            if int(class_id) in vehicles:\n",
    "                detections_.append([x1, y1, x2, y2, score])\n",
    "\n",
    "        # track vehicles\n",
    "        track_ids = mot_tracker.update(np.asarray(detections_))\n",
    "\n",
    "        # detect license plates\n",
    "        license_plates = license_plate_detector(frame)[0]\n",
    "        for license_plate in license_plates.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = license_plate\n",
    "\n",
    "            # assign license plate to car\n",
    "            xcar1, ycar1, xcar2, ycar2, car_id = get_car(license_plate, track_ids)\n",
    "\n",
    "            if car_id != -1:\n",
    "\n",
    "                # crop license plate\n",
    "                license_plate_crop = frame[int(y1):int(y2), int(x1): int(x2), :]\n",
    "\n",
    "                # process license plate\n",
    "                license_plate_crop_gray = cv2.cvtColor(license_plate_crop, cv2.COLOR_BGR2GRAY)\n",
    "                _, license_plate_crop_thresh = cv2.threshold(license_plate_crop_gray, 64, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "                # read license plate number\n",
    "                license_plate_text, license_plate_text_score = read_license_plate(license_plate_crop_thresh)\n",
    "\n",
    "                if license_plate_text is not None:\n",
    "                    results[frame_nmr][car_id] = {'car': {'bbox': [xcar1, ycar1, xcar2, ycar2]},\n",
    "                                                  'license_plate': {'bbox': [x1, y1, x2, y2],\n",
    "                                                                    'text': license_plate_text,\n",
    "                                                                    'bbox_score': score,\n",
    "                                                                    'text_score': license_plate_text_score}}\n",
    "\n",
    "# write results\n",
    "write_csv(results, './test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('yolov7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54711ba1bddc392d48ca20e80feaa9b2e23d43069aa8b98ed16355091034ff6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
